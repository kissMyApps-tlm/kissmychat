{
  "01-ai/yi-1.5-34b-chat": {
    "description": "零一万物 — це остання версія відкритої доопрацьованої моделі з 34 мільярдами параметрів, яка підтримує різні сценарії діалогу, використовуючи високоякісні навчальні дані, що відповідають людським уподобанням."
  },
  "01-ai/yi-1.5-9b-chat": {
    "description": "零一万物 — це остання версія відкритої доопрацьованої моделі з 9 мільярдами параметрів, яка підтримує різні сценарії діалогу, використовуючи високоякісні навчальні дані, що відповідають людським уподобанням."
  },
  "360/deepseek-r1": {
    "description": "【Версія 360】DeepSeek-R1 використовує технології посиленого навчання на етапі пост-навчання у великих масштабах, значно покращуючи здатності моделі до виведення при наявності лише невеликої кількості розмічених даних. У задачах математики, коду та природної мови його продуктивність порівнянна з офіційною версією OpenAI o1."
  },
  "360gpt-pro": {
    "description": "360GPT Pro, як важливий член серії моделей AI від 360, задовольняє різноманітні застосування обробки тексту з високою ефективністю, підтримує розуміння довгих текстів та багатораундові діалоги."
  },
  "360gpt-pro-trans": {
    "description": "Модель, призначена для перекладу, глибоко налаштована та оптимізована, з видатними результатами перекладу."
  },
  "360gpt-turbo": {
    "description": "360GPT Turbo пропонує потужні обчислювальні та діалогові можливості, володіє видатним розумінням семантики та ефективністю генерації, що робить його ідеальним рішенням для інтелектуальних помічників для підприємств та розробників."
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8K акцентує увагу на семантичній безпеці та відповідальності, спеціально розроблений для застосувань з високими вимогами до безпеки контенту, забезпечуючи точність та надійність користувацького досвіду."
  },
  "360gpt2-o1": {
    "description": "360gpt2-o1 використовує дерево пошуку для побудови ланцюгів міркувань та вводить механізм рефлексії, навчаючись за допомогою посиленого навчання, модель має здатність до саморефлексії та виправлення помилок."
  },
  "360gpt2-pro": {
    "description": "360GPT2 Pro — це просунута модель обробки природної мови, випущена компанією 360, що володіє видатними здібностями до генерації та розуміння тексту, особливо в області генерації та творчості, здатна обробляти складні мовні перетворення та ролеві завдання."
  },
  "360zhinao2-o1": {
    "description": "Модель 360zhinao2-o1 використовує дерево пошуку для побудови ланцюжка міркувань та включає механізм рефлексії, навчаючись за допомогою посиленого навчання, що дозволяє моделі самостійно рефлексувати та виправляти помилки."
  },
  "4.0Ultra": {
    "description": "Spark4.0 Ultra — це найпотужніша версія в серії великих моделей Xinghuo, яка, оновивши мережеві пошукові зв'язки, покращує розуміння та узагальнення текстового контенту. Це всебічне рішення для підвищення продуктивності в офісі та точного реагування на запити, що є провідним інтелектуальним продуктом в галузі."
  },
  "AnimeSharp": {
    "description": "AnimeSharp (також відомий як «4x‑AnimeSharp») — це відкрита модель надвисокої роздільної здатності, розроблена Kim2091 на основі архітектури ESRGAN, орієнтована на збільшення та покращення зображень в аніме-стилі. У лютому 2022 року модель була перейменована з «4x-TextSharpV1»; спочатку вона також застосовувалася для текстових зображень, але була значно оптимізована для аніме-контенту."
  },
  "Baichuan2-Turbo": {
    "description": "Використовує технології покращеного пошуку для повного зв'язку між великою моделлю та галузевими знаннями, а також знаннями з мережі. Підтримує завантаження різних документів, таких як PDF та Word, а також введення URL, забезпечуючи своєчасне та повне отримання інформації з точними та професійними результатами."
  },
  "Baichuan3-Turbo": {
    "description": "Оптимізований для високочастотних корпоративних сценаріїв, значно покращує результати та пропонує високу вартість. Порівняно з моделлю Baichuan2, створення контенту збільшилося на 20%, відповіді на запитання на 17%, а здібності ролевої взаємодії на 40%. Загальна ефективність краща, ніж у GPT3.5."
  },
  "Baichuan3-Turbo-128k": {
    "description": "Має 128K наддовге контекстне вікно, оптимізоване для високочастотних корпоративних сценаріїв, значно покращує результати та пропонує високу вартість. Порівняно з моделлю Baichuan2, створення контенту збільшилося на 20%, відповіді на запитання на 17%, а здібності ролевої взаємодії на 40%. Загальна ефективність краща, ніж у GPT3.5."
  },
  "Baichuan4": {
    "description": "Модель має найкращі можливості в країні, перевершуючи закордонні моделі в завданнях на знання, довгі тексти та генерацію контенту. Також володіє передовими мультимодальними можливостями та показує відмінні результати в декількох авторитетних тестах."
  },
  "Baichuan4-Air": {
    "description": "Модель має найкращі в країні можливості, перевершуючи закордонні моделі в завданнях китайською мовою, таких як енциклопедичні знання, довгі тексти та генерація контенту. Також володіє передовими мультимодальними можливостями та демонструє відмінні результати в декількох авторитетних оціночних тестах."
  },
  "Baichuan4-Turbo": {
    "description": "Модель має найкращі в країні можливості, перевершуючи закордонні моделі в завданнях китайською мовою, таких як енциклопедичні знання, довгі тексти та генерація контенту. Також володіє передовими мультимодальними можливостями та демонструє відмінні результати в декількох авторитетних оціночних тестах."
  },
  "ByteDance-Seed/Seed-OSS-36B-Instruct": {
    "description": "Seed-OSS — це серія відкритих великих мовних моделей, розроблених командою Seed компанії ByteDance, спеціально створених для потужної обробки довгих контекстів, міркувань, агентів та універсальних можливостей. Модель Seed-OSS-36B-Instruct з цієї серії має 36 мільярдів параметрів та є моделлю з донастроюванням за інструкціями, що спочатку підтримує наддовгі контексти, що дозволяє їй обробляти величезні документи або складні кодові бази за один раз. Ця модель спеціально оптимізована для міркувань, генерації коду та завдань агентів (наприклад, використання інструментів), при цьому зберігаючи збалансовані та видатні універсальні здібності. Однією з ключових особливостей моделі є функція «Бюджет міркувань» (Thinking Budget), що дозволяє користувачам гнучко регулювати довжину міркувань за необхідності, що ефективно підвищує продуктивність у реальних застосуваннях."
  },
  "DeepSeek-R1": {
    "description": "Сучасна ефективна LLM, що спеціалізується на логічному висновку, математиці та програмуванні."
  },
  "DeepSeek-R1-Distill-Llama-70B": {
    "description": "DeepSeek R1 — більша та розумніша модель у наборі DeepSeek, була дистильована в архітектуру Llama 70B. На основі бенчмарків та людської оцінки ця модель розумніша, ніж оригінальна Llama 70B, особливо в задачах, що вимагають математичної та фактичної точності."
  },
  "DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "Модель DeepSeek-R1, заснована на Qwen2.5-Math-1.5B, оптимізує продуктивність виведення за допомогою посиленого навчання та даних холодного старту, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "DeepSeek-R1-Distill-Qwen-14B": {
    "description": "Модель DeepSeek-R1, заснована на Qwen2.5-14B, оптимізує продуктивність виведення за допомогою посиленого навчання та даних холодного старту, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "DeepSeek-R1-Distill-Qwen-32B": {
    "description": "Серія DeepSeek-R1 оптимізує продуктивність виведення за допомогою посиленого навчання та даних холодного старту, оновлюючи стандарт багатозадачності у відкритих моделях, перевершуючи рівень OpenAI-o1-mini."
  },
  "DeepSeek-R1-Distill-Qwen-7B": {
    "description": "Модель DeepSeek-R1, заснована на Qwen2.5-Math-7B, оптимізує продуктивність виведення за допомогою посиленого навчання та даних холодного старту, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "DeepSeek-V3": {
    "description": "DeepSeek-V3 — це модель MoE, розроблена компанією DeepSeek. Результати DeepSeek-V3 у кількох оцінках перевершують інші відкриті моделі, такі як Qwen2.5-72B та Llama-3.1-405B, і за продуктивністю не поступаються світовим провідним закритим моделям GPT-4o та Claude-3.5-Sonnet."
  },
  "DeepSeek-V3-1": {
    "description": "DeepSeek V3.1: модель наступного покоління для виведення, покращена для складних міркувань та ланцюгового мислення, підходить для завдань, що вимагають глибокого аналізу."
  },
  "DeepSeek-V3-Fast": {
    "description": "Постачальник моделі: платформа sophnet. DeepSeek V3 Fast — це високошвидкісна версія DeepSeek V3 0324 з високою пропускною здатністю (TPS), повністю не квантована, з покращеними можливостями коду та математики, що забезпечує швидшу реакцію!"
  },
  "DeepSeek-V3.1": {
    "description": "DeepSeek-V3.1 — режим без міркувань; DeepSeek-V3.1 — нова гібридна модель міркувань від DeepSeek, що підтримує два режими: з міркуваннями та без. Порівняно з DeepSeek-R1-0528, ефективність міркувань вища. Після пост-тренування значно покращено використання інструментів агентом та виконання завдань агентів."
  },
  "DeepSeek-V3.1-Fast": {
    "description": "DeepSeek V3.1 Fast — високопродуктивна версія DeepSeek V3.1 з високою пропускною здатністю (TPS). Гібридний режим міркувань: зі зміною шаблону чату одна модель може одночасно підтримувати режими з міркуваннями та без. Більш інтелектуальний виклик інструментів: завдяки пост-тренуванню значно покращено роботу моделі з інструментами та виконання агентських завдань."
  },
  "DeepSeek-V3.1-Think": {
    "description": "DeepSeek-V3.1 — режим з міркуваннями; DeepSeek-V3.1 — нова гібридна модель міркувань від DeepSeek, що підтримує два режими: з міркуваннями та без. Порівняно з DeepSeek-R1-0528, ефективність міркувань вища. Після пост-тренування значно покращено використання інструментів агентом та виконання завдань агентів."
  },
  "DeepSeek-V3.2-Exp": {
    "description": "DeepSeek V3.2 — це остання універсальна велика модель від DeepSeek, що підтримує гібридну архітектуру виведення та володіє покращеними можливостями агента."
  },
  "DeepSeek-V3.2-Exp-Think": {
    "description": "Режим міркування DeepSeek V3.2. Перед виведенням остаточної відповіді модель спочатку генерує ланцюжок міркувань для підвищення точності підсумкового результату."
  },
  "Doubao-lite-128k": {
    "description": "Doubao-lite має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтам більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 128k."
  },
  "Doubao-lite-32k": {
    "description": "Doubao-lite має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтам більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 32k."
  },
  "Doubao-lite-4k": {
    "description": "Doubao-lite має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтам більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 4k."
  },
  "Doubao-pro-128k": {
    "description": "Основна модель з найкращою продуктивністю, що підходить для вирішення складних завдань. Відмінно справляється з питаннями-відповідями, резюмуванням, творчим написанням, класифікацією тексту, ролевими іграми та іншими сценаріями. Підтримує виведення та донавчання з контекстним вікном у 128k."
  },
  "Doubao-pro-32k": {
    "description": "Основна модель з найкращою продуктивністю, що підходить для вирішення складних завдань. Відмінно справляється з питаннями-відповідями, резюмуванням, творчим написанням, класифікацією тексту, ролевими іграми та іншими сценаріями. Підтримує виведення та донавчання з контекстним вікном у 32k."
  },
  "Doubao-pro-4k": {
    "description": "Основна модель з найкращою продуктивністю, що підходить для вирішення складних завдань. Відмінно справляється з питаннями-відповідями, резюмуванням, творчим написанням, класифікацією тексту, ролевими іграми та іншими сценаріями. Підтримує виведення та донавчання з контекстним вікном у 4k."
  },
  "DreamO": {
    "description": "DreamO — це відкрита модель генерації зображень, розроблена спільно ByteDance та Пекінським університетом, призначена для підтримки багатозадачної генерації зображень в єдиній архітектурі. Вона використовує ефективний метод комбінованого моделювання, що дозволяє створювати високо узгоджені та кастомізовані зображення на основі заданих користувачем умов, таких як ідентичність, об'єкт, стиль та фон."
  },
  "ERNIE-3.5-128K": {
    "description": "Флагманська великомасштабна мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними можливостями, здатна задовольнити більшість вимог до діалогових відповідей, генерації контенту та сценаріїв використання плагінів; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях."
  },
  "ERNIE-3.5-8K": {
    "description": "Флагманська великомасштабна мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними можливостями, здатна задовольнити більшість вимог до діалогових відповідей, генерації контенту та сценаріїв використання плагінів; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях."
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "Флагманська великомасштабна мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними можливостями, здатна задовольнити більшість вимог до діалогових відповідей, генерації контенту та сценаріїв використання плагінів; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях."
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "Флагманська надвеликомасштабна мовна модель, розроблена Baidu, яка порівняно з ERNIE 3.5 забезпечує повне оновлення можливостей моделі та широко застосовується в складних завданнях у різних областях; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях."
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "Флагманська надвеликомасштабна мовна модель, розроблена Baidu, яка порівняно з ERNIE 3.5 забезпечує повне оновлення можливостей моделі та широко застосовується в складних завданнях у різних областях; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях."
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "Флагманська надвеликомасштабна мовна модель, розроблена Baidu, демонструє відмінні результати та добре підходить для складних завдань у різних областях; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи своєчасність відповідей. Порівняно з ERNIE 4.0 має кращі показники продуктивності."
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "Флагманська надвеликомасштабна мовна модель, розроблена Baidu, що демонструє відмінні результати в комплексній ефективності, широко застосовується в складних завданнях у різних областях; підтримує автоматичну інтеграцію з плагіном пошуку Baidu, забезпечуючи актуальність інформації у відповідях. Порівняно з ERNIE 4.0, вона демонструє кращі показники продуктивності."
  },
  "ERNIE-Character-8K": {
    "description": "Спеціалізована мовна модель, розроблена Baidu для вертикальних сценаріїв, підходить для застосування в іграх (NPC), діалогах служби підтримки, ролевих іграх та інших сценаріях, що володіє яскраво вираженим та узгодженим стилем персонажів, високою здатністю слідувати інструкціям та відмінною продуктивністю виведення."
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "Легковагова мовна модель, розроблена Baidu, яка поєднує в собі відмінні результати моделі та продуктивність виведення, перевершуючи ERNIE Lite, підходить для використання в системах з низькою обчислювальною потужністю."
  },
  "ERNIE-Speed-128K": {
    "description": "Нова високопродуктивна мовна модель, розроблена Baidu у 2024 році, що володіє видатними універсальними можливостями, підходить для використання як базова модель для тонкого налаштування, краще справляючись із завданнями в специфічних сценаріях, при цьому володіючи відмінною продуктивністю виведення."
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "Нова високопродуктивна мовна модель, розроблена Baidu у 2024 році, що володіє видатними універсальними можливостями, перевершуючи ERNIE Speed, підходить для використання як базова модель для тонкого налаштування, краще справляючись із завданнями в специфічних сценаріях, при цьому володіючи відмінною продуктивністю виведення."
  },
  "FLUX-1.1-pro": {
    "description": "FLUX.1.1 Pro"
  },
  "FLUX.1-Kontext-dev": {
    "description": "FLUX.1-Kontext-dev — мультимодальна модель генерації та редагування зображень, розроблена Black Forest Labs на основі архітектури Rectified Flow Transformer з масштабом 12 мільярдів параметрів. Модель спеціалізується на генерації, реконструкції, покращенні та редагуванні зображень з урахуванням заданого контексту. Вона поєднує переваги контрольованої генерації дифузійних моделей та контекстного моделювання Transformer, забезпечуючи високоякісний вивід та широке застосування в задачах відновлення, доповнення та реконструкції візуальних сцен."
  },
  "FLUX.1-Kontext-pro": {
    "description": "FLUX.1 Kontext [pro]"
  },
  "FLUX.1-dev": {
    "description": "FLUX.1-dev — це відкрита мультимодальна мовна модель (Multimodal Language Model, MLLM), розроблена Black Forest Labs та оптимізована для завдань, пов'язаних із зображеннями та текстом. Вона об'єднує можливості розуміння та генерації зображень і тексту, побудована на основі передової великої мовної моделі (наприклад, Mistral-7B) та використовує ретельно розроблений візуальний кодувальник та багатоступеневе інструкційне донастроювання для спільної обробки зображень та тексту, а також складного виведення."
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B) — це інноваційна модель, що підходить для багатообласних застосувань та складних завдань."
  },
  "HelloMeme": {
    "description": "HelloMeme — це AI-інструмент, який автоматично створює меми, анімовані зображення або короткі відео на основі наданих вами картинок або дій. Для роботи не потрібні навички малювання чи програмування — достатньо підготувати референсне зображення, і інструмент допоможе створити привабливий, забавний та стилістично єдиний контент."
  },
  "HiDream-I1-Full": {
    "description": "HiDream-E1-Full — це відкрита мультимодальна модель редагування зображень, випущена HiDream.ai, заснована на передовій архітектурі Diffusion Transformer та володіє потужними можливостями розуміння мови (вбудований LLaMA 3.1-8B-Instruct). Модель підтримує генерацію зображень, перенесення стилю, локальне редагування та перемальовування контенту за природними мовними інструкціями, демонструючи видатні здібності в розумінні та виконанні текстово-графічних завдань."
  },
  "HunyuanDiT-v1.2-Diffusers-Distilled": {
    "description": "hunyuandit-v1.2-distilled — це полегшена модель генерації зображень з тексту, оптимізована за допомогою дистиляції для швидкої генерації високоякісних зображень, особливо підходить для умов з обмеженими ресурсами та завдань реального часу."
  },
  "InstantCharacter": {
    "description": "InstantCharacter — персоналізована модель генерації персонажів без необхідності донавчання, випущена командою Tencent AI у 2025 році. Модель забезпечує високу точність та узгодженість персонажів у різних сценах, дозволяючи створювати моделі персонажів на основі однієї референсної фотографії та гнучко переносити їх у різні стилі, пози та фони."
  },
  "InternVL2-8B": {
    "description": "InternVL2-8B — це потужна візуально-мовна модель, що підтримує багатомодальну обробку зображень та тексту, здатна точно розпізнавати вміст зображень та генерувати відповідні описи або відповіді."
  },
  "InternVL2.5-26B": {
    "description": "InternVL2.5-26B — це потужна візуально-мовна модель, що підтримує багатомодальну обробку зображень та тексту, здатна точно розпізнавати вміст зображень та генерувати відповідні описи або відповіді."
  },
  "Kolors": {
    "description": "Kolors — модель генерації зображень з тексту, розроблена командою Kolors компанії Kuaishou. Навчена на мільярдах параметрів, вона демонструє значні переваги у візуальній якості, розумінні китайської семантики та рендерингу тексту."
  },
  "Kwai-Kolors/Kolors": {
    "description": "Kolors — масштабна модель генерації зображень з тексту на основі латентного дифузійного процесу, розроблена командою Kolors компанії Kuaishou. Навчена на мільярдах пар текст-зображення, модель демонструє видатні результати у візуальній якості, точності складної семантики та рендерингу китайських та англійських символів. Вона підтримує введення китайською та англійською мовами та особливо добре справляється з розумінням та генерацією специфічного китайського контенту."
  },
  "Llama-3.2-11B-Vision-Instruct": {
    "description": "Відмінні здібності до візуального виведення на зображеннях високої роздільної здатності, підходять для застосувань візуального розуміння."
  },
  "Llama-3.2-90B-Vision-Instruct\t": {
    "description": "Передові здібності до візуального виведення, підходять для застосувань візуального розуміння."
  },
  "Meta-Llama-3-3-70B-Instruct": {
    "description": "Llama 3.3 70B: універсальна модель Transformer, що підходить для діалогів та генеративних завдань."
  },
  "Meta-Llama-3.1-405B-Instruct": {
    "description": "Текстова модель Llama 3.1 з оптимізацією під інструкції, розроблена для багатомовних діалогових випадків, показує відмінні результати порівняно з багатьма доступними відкритими та закритими чат-моделями на загальноприйнятих галузевих бенчмарках."
  },
  "Meta-Llama-3.1-70B-Instruct": {
    "description": "Текстова модель Llama 3.1 з оптимізацією під інструкції, розроблена для багатомовних діалогових випадків, показує відмінні результати порівняно з багатьма доступними відкритими та закритими чат-моделями на загальноприйнятих галузевих бенчмарках."
  },
  "Meta-Llama-3.1-8B-Instruct": {
    "description": "Текстова модель Llama 3.1 з оптимізацією під інструкції, розроблена для багатомовних діалогових випадків, показує відмінні результати порівняно з багатьма доступними відкритими та закритими чат-моделями на загальноприйнятих галузевих бенчмарках."
  },
  "Meta-Llama-3.2-1B-Instruct": {
    "description": "Сучасна передова компактна мовна модель з видатними здібностями до розуміння мови, логічного висновку та генерації тексту."
  },
  "Meta-Llama-3.2-3B-Instruct": {
    "description": "Сучасна передова компактна мовна модель з видатними здібностями до розуміння мови, логічного висновку та генерації тексту."
  },
  "Meta-Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3 — це найсучасніша багатомовна відкрита мовна модель із серії Llama, яка дозволяє отримати продуктивність, зіставну з 405B моделями, за вкрай низькою ціною. Заснована на структурі Transformer та покращена за допомогою контрольованого донастроювання (SFT) та навчання з підкріпленням на основі людського зворотного зв'язку (RLHF) для підвищення корисності та безпеки. Її версія з оптимізацією під інструкції спеціально розроблена для багатомовних діалогів та показує кращі результати порівняно з багатьма відкритими та закритими чат-моделями на кількох галузевих бенчмарках. Дата закінчення знань — грудень 2023 року."
  },
  "Meta-Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "description": "Llama 4 Maverick: великомасштабна модель на основі Mixture-of-Experts, що забезпечує ефективну стратегію активації експертів для чудової продуктивності при виведенні."
  },
  "MiniMax-M1": {
    "description": "Абсолютно нова власна модель виведення. Світовий лідер: 80K ланцюгів мислення x 1M входів, ефективність порівнянна з провідними закордонними моделями."
  },
  "MiniMax-Text-01": {
    "description": "У серії моделей MiniMax-01 ми зробили сміливі інновації: вперше у великомасштабному масштабі реалізований лінійний механізм уваги, традиційна архітектура Transformer більше не є єдиним вибором. Обсяг параметрів цієї моделі досягає 456 мільярдів, з яких 45,9 мільярда активуються за один раз. Комплексна продуктивність моделі порівнянна з провідними закордонними моделями, при цьому вона може ефективно обробляти контекст довжиною до 4 мільйонів токенів, що у 32 рази більше, ніж у GPT-4o, та у 20 разів більше, ніж у Claude-3.5-Sonnet."
  },
  "MiniMaxAI/MiniMax-M1-80k": {
    "description": "MiniMax-M1 — це масштабна модель виведення з гібридною увагою та відкритими вагами, що містить 456 мільярдів параметрів, при цьому кожен токен активує близько 45,9 мільярда параметрів. Модель спочатку підтримує наддовгий контекст до 1 мільйона токенів та завдяки механізму блискавичної уваги заощаджує 75% обчислювальних операцій з плаваючою точкою в задачах генерації на 100 тисяч токенів порівняно з DeepSeek R1. Крім того, MiniMax-M1 використовує архітектуру MoE (змішані експерти), поєднуючи алгоритм CISPO та ефективне навчання з підкріпленням з гібридною увагою, досягаючи провідних у галузі показників при виведенні на довгих входах та в реальних сценаріях програмної інженерії."
  },
  "Moonshot-Kimi-K2-Instruct": {
    "description": "Загальна чисельність параметрів — 1 трильйон, активованих параметрів — 32 мільярди. Серед немислячих моделей досягає передових результатів в області актуальних знань, математики та програмування, особливо ефективна для універсальних агентських завдань. Модель ретельно оптимізована для агентських завдань, здатна не тільки відповідати на запитання, а й робити дії. Ідеально підходить для імпровізаційного, універсального спілкування та агентських сценаріїв, будучи моделлю рефлекторного рівня без необхідності тривалого обмірковування."
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) — це високоточна модель команд, що підходить для складних обчислень."
  },
  "OmniConsistency": {
    "description": "OmniConsistency підвищує узгодженість стилю та узагальнюючу здатність у задачах перетворення зображень (Image-to-Image) за рахунок впровадження масштабних Diffusion Transformers (DiTs) та парних стилізованих даних, запобігаючи деградації стилю."
  },
  "Phi-3-medium-128k-instruct": {
    "description": "Та сама модель Phi-3-medium, але з більшим розміром контексту для RAG або кількох підказок."
  },
  "Phi-3-medium-4k-instruct": {
    "description": "Модель з 14B параметрами, що демонструє кращу якість, ніж Phi-3-mini, з акцентом на високоякісні, насичені міркуваннями дані."
  },
  "Phi-3-mini-128k-instruct": {
    "description": "Та сама модель Phi-3-mini, але з більшим розміром контексту для RAG або кількох підказок."
  },
  "Phi-3-mini-4k-instruct": {
    "description": "Найменша модель у сімействі Phi-3. Оптимізована як для якості, так і для низької затримки."
  },
  "Phi-3-small-128k-instruct": {
    "description": "Та сама модель Phi-3-small, але з більшим розміром контексту для RAG або кількох підказок."
  },
  "Phi-3-small-8k-instruct": {
    "description": "Модель з 7B параметрами, що демонструє кращу якість, ніж Phi-3-mini, з акцентом на високоякісні, насичені міркуваннями дані."
  },
  "Phi-3.5-mini-instruct": {
    "description": "Оновлена версія моделі Phi-3-mini."
  },
  "Phi-3.5-vision-instrust": {
    "description": "Оновлена версія моделі Phi-3-vision."
  },
  "Pro/Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-7B-Instruct — це мовна модель з донавчанням на інструкціях у серії Qwen2, з параметрами 7B. Ця модель заснована на архітектурі Transformer та використовує такі технології, як функція активації SwiGLU, зміщення уваги QKV та груповий запит уваги. Вона може обробляти великі обсяги вхідних даних. Ця модель показує відмінні результати в розумінні мови, генерації, багатомовних здібностях, кодуванні, математиці та висновках у різних бенчмарках, перевершуючи більшість відкритих моделей та демонструючи конкурентоспроможність з пропрієтарними моделями в деяких завданнях. Qwen2-7B-Instruct показує значне покращення продуктивності в кількох оцінках порівняно з Qwen1.5-7B-Chat."
  },
  "Pro/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct — це одна з останніх мовних моделей, випущених Alibaba Cloud. Ця 7B модель значно покращила здібності в області кодування та математики. Модель також підтримує безліч мов, охоплюючи понад 29 мов, включаючи китайську та англійську. Вона значно покращила виконання інструкцій, розуміння структурованих даних та генерацію структурованих вихідних даних (особливо JSON)."
  },
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct — це остання версія серії мовних моделей, специфічних для коду, випущена Alibaba Cloud. Ця модель значно покращила здібності генерації коду, виведення та виправлення на основі Qwen2.5, навчаючись на 5.5 трильйонах токенів. Вона не тільки посилила кодування, але й зберегла переваги в математиці та загальних здібностях. Модель надає більш повну основу для практичних застосувань, таких як інтелектуальні агенти коду."
  },
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct": {
    "description": "Qwen2.5-VL — це новий член сімейства Qwen, що володіє потужними можливостями візуального розуміння. Може аналізувати текст, діаграми та компонування в зображеннях, розуміти довгі відео та фіксувати події. Здатна до логічних міркувань, роботи з інструментами, підтримує локалізацію об'єктів у різних форматах та генерацію структурованих виводів. Оптимізована для розуміння відео з динамічною роздільною здатністю та частотою кадрів, а також покращена ефективність візуального кодувальника."
  },
  "Pro/THUDM/GLM-4.1V-9B-Thinking": {
    "description": "GLM-4.1V-9B-Thinking — це відкрита візуально-мовна модель (VLM), спільно випущена Zhipu AI та лабораторією KEG Університету Цінхуа, спеціально розроблена для вирішення складних мультимодальних когнітивних завдань. Модель заснована на базовій моделі GLM-4-9B-0414 та значно покращує міжмодальні здібності міркування та стабільність за рахунок впровадження механізму міркування «ланцюжок мислення» (Chain-of-Thought) та використання методів навчання з підкріпленням."
  },
  "Pro/THUDM/glm-4-9b-chat": {
    "description": "GLM-4-9B-Chat — це відкрита версія попередньо навченої моделі із серії GLM-4, випущена Zhizhu AI. Ця модель показує відмінні результати в семантиці, математиці, висновках, коді та знаннях. Окрім підтримки багаторазових діалогів, GLM-4-9B-Chat також володіє просунутими функціями, такими як веб-браузинг, виконання коду, виклик користувацьких інструментів (Function Call) та виведення довгих текстів. Модель підтримує 26 мов, включаючи китайську, англійську, японську, корейську та німецьку. У кількох бенчмарках GLM-4-9B-Chat демонструє відмінні результати, такі як AlignBench-v2, MT-Bench, MMLU та C-Eval. Ця модель підтримує максимальну довжину контексту 128K та підходить для академічних досліджень та комерційних застосувань."
  },
  "Pro/deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1 — це модель виведення, керована навчанням з підкріпленням (RL), яка вирішує проблеми повторюваності та читабельності в моделі. Перед RL DeepSeek-R1 вводить дані холодного старту, що додатково оптимізує продуктивність виведення. Вона показує зіставні результати з OpenAI-o1 у математичних, кодових та завданнях виведення та покращує загальну ефективність завдяки ретельно продуманим методам навчання."
  },
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "description": "DeepSeek-R1-Distill-Qwen-7B — це модель, отримана методом дистиляції знань на основі Qwen2.5-Math-7B. Модель була доопрацьована з використанням 800 тисяч відібраних зразків, згенерованих DeepSeek-R1, та демонструє видатні здібності до логічного міркування. Показує відмінні результати в різних тестах: точність 92,8% на MATH-500, прохідний бал 55,5% на AIME 2024 та оцінку 1189 на CodeForces, що підтверджує її високі математичні та програмістські можливості для моделі масштабу 7B."
  },
  "Pro/deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3 — це мовна модель з 6710 мільярдами параметрів, що використовує архітектуру змішаних експертів (MoE) та багатофункціональну увагу (MLA), у поєднанні зі стратегією балансування навантаження без допоміжних втрат, що оптимізує ефективність виведення та навчання. Після попереднього навчання на 14.8 трильйонах високоякісних токенів та подальшого контрольованого донастроювання та навчання з підкріпленням, DeepSeek-V3 перевершує інші відкриті моделі та наближається до провідних закритих моделей."
  },
  "Pro/deepseek-ai/DeepSeek-V3.1": {
    "description": "DeepSeek-V3.1 — гібридна велика мовна модель, випущена DeepSeek AI, яка включає безліч важливих покращень порівняно з попередніми версіями. Головною інновацією моделі є інтеграція режимів «мислення» (Thinking Mode) та «без мислення» (Non-thinking Mode), які користувач може гнучко перемикати, змінюючи шаблони діалогу для різних завдань. Завдяки спеціалізованій пост-тренувальній оптимізації V3.1 значно покращила продуктивність при виклику інструментів та виконанні завдань агента, забезпечуючи кращу підтримку зовнішніх пошукових інструментів та виконання багатоетапних складних завдань. Модель заснована на DeepSeek-V3.1-Base та донавчена з використанням двоетапного розширення довгих текстів, що значно збільшило обсяг тренувальних даних та покращило роботу з довгими документами та великими обсягами коду. Як відкрита модель, DeepSeek-V3.1 демонструє зіставні з провідними закритими моделями результати в кодуванні, математиці та міркуваннях, а завдяки архітектурі з експертами (MoE) зберігає величезну ємність моделі при ефективному зниженні витрат на виведення."
  },
  "Pro/deepseek-ai/DeepSeek-V3.1-Terminus": {
    "description": "DeepSeek-V3.1-Terminus — оновлена версія моделі V3.1 від DeepSeek, позиціонована як гібридна велика мовна модель з агентськими функціями. У цьому оновленні, зберігаючи колишні можливості моделі, акцент зроблено на виправленні проблем, виявлених користувачами, та підвищенні стабільності. Значно покращена мовна узгодженість, зменшено змішування китайської та англійської мов, а також поява аномальних символів. Модель інтегрує режими «міркування» (Thinking Mode) та «без міркування» (Non-thinking Mode), які користувачі можуть гнучко перемикати через шаблони чату для різних завдань. Важливим покращенням є посилення продуктивності кодового агента (Code Agent) та пошукового агента (Search Agent), що підвищує надійність при виклику інструментів та виконанні багатоетапних складних завдань."
  },
  "Pro/moonshotai/Kimi-K2-Instruct-0905": {
    "description": "Kimi K2-Instruct-0905 — це остання та найпотужніша версія Kimi K2. Це передова мовна модель з архітектурою змішаних експертів (MoE), що володіє загальним числом параметрів в 1 трильйон та 32 мільярдами активних параметрів. Основні характеристики моделі включають: покращений інтелект кодуючих агентів, що демонструє значний приріст продуктивності на відкритих бенчмарках та в реальних завданнях кодування агентів; удосконалений досвід фронтенд-кодування, з покращеннями як в естетиці, так і в практичності фронтенд-програмування."
  },
  "QwQ-32B-Preview": {
    "description": "QwQ-32B-Preview — це інноваційна модель обробки природної мови, здатна ефективно обробляти складні завдання генерації діалогів та розуміння контексту."
  },
  "Qwen/QVQ-72B-Preview": {
    "description": "QVQ-72B-Preview — це дослідницька модель, розроблена командою Qwen, зосереджена на здібностях візуального виведення, що володіє унікальними перевагами в розумінні складних сцен та вирішенні візуально пов'язаних математичних завдань."
  },
  "Qwen/QwQ-32B": {
    "description": "QwQ — це модель виведення із серії Qwen. На відміну від традиційних моделей, налаштованих на інструкції, QwQ володіє здібностями до мислення та міркування, що дозволяє значно покращити продуктивність у завданнях нижнього рівня, особливо при вирішенні складних проблем. QwQ-32B — це середня модель виведення, яка демонструє конкурентоспроможні результати в порівнянні з найсучаснішими моделями виведення (такими як DeepSeek-R1, o1-mini). Ця модель використовує технології RoPE, SwiGLU, RMSNorm та Attention QKV bias, має 64-шарову архітектуру та 40 голів уваги Q (в архітектурі GQA KV становить 8)."
  },
  "Qwen/QwQ-32B-Preview": {
    "description": "QwQ-32B-Preview — це остання експериментальна дослідницька модель Qwen, зосереджена на підвищенні можливостей виведення ШІ. Досліджуючи складні механізми, такі як змішування мов та рекурсивні висновки, основні переваги включають потужні аналітичні здібності, математичні та програмні навички. Водночас існують проблеми з перемиканням мов, циклом виведення, міркуваннями безпеки та відмінностями в інших здібностях."
  },
  "Qwen/Qwen-Image": {
    "description": "Qwen-Image — это базовая модель генерации изображений, разработанная командой Tongyi Qianwen компании Alibaba, содержащая 20 миллиардов параметров. Модель достигла значительных успехов в сложной текстовой визуализации и точном редактировании изображений, особенно хорошо справляется с генерацией изображений с высококачественным текстом на китайском и английском языках. Qwen-Image способна обрабатывать многострочные макеты и текст на уровне абзацев, сохраняя при этом согласованность верстки и контекстную гармонию при генерации изображений. Помимо выдающихся возможностей визуализации текста, модель поддерживает широкий спектр художественных стилей — от фотореализма до аниме-эстетики, гибко адаптируясь к различным творческим задачам. Кроме того, она обладает мощными возможностями редактирования и понимания изображений, поддерживает перенос стиля, добавление и удаление объектов, улучшение деталей, редактирование текста и даже управление позами человека, стремясь стать универсальной интеллектуальной моделью для визуального творчества и обработки, объединяющей язык, макет и изображение."
  },
  "Qwen/Qwen-Image-Edit-2509": {
    "description": "Qwen-Image-Edit-2509 — это последняя версия модели редактирования изображений Qwen-Image, выпущенная командой Tongyi Qianwen компании Alibaba. Эта модель была глубоко обучена на основе 20-миллиардной модели Qwen-Image, успешно расширив её уникальные возможности текстовой визуализации в область редактирования изображений, обеспечивая точное редактирование текста на изображениях. Qwen-Image-Edit использует инновационную архитектуру, в которой входное изображение одновременно подаётся в Qwen2.5-VL (для управления визуальной семантикой) и VAE Encoder (для управления визуальным внешним видом), что обеспечивает двойную возможность редактирования как по смыслу, так и по внешнему виду. Это означает, что модель поддерживает не только локальное редактирование внешнего вида, такое как добавление, удаление или изменение элементов, но и высокоуровневое семантическое редактирование, требующее сохранения смысловой целостности, например, для IP-контента или переноса стиля. Модель демонстрирует передовые (SOTA) результаты на множестве открытых бенчмарков, делая её мощной базовой моделью для редактирования изображений."
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen2 — це передова універсальна мовна модель, що підтримує безліч типів команд."
  },
  "Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-72B-Instruct — це мовна модель з донавчанням на інструкціях у серії Qwen2, з параметрами 72B. Ця модель заснована на архітектурі Transformer та використовує такі технології, як функція активації SwiGLU, зміщення уваги QKV та груповий запит уваги. Вона може обробляти великі обсяги вхідних даних. Ця модель показує відмінні результати в розумінні мови, генерації, багатомовних здібностях, кодуванні, математиці та висновках у різних бенчмарках, перевершуючи більшість відкритих моделей та демонструючи конкурентоспроможність з пропрієтарними моделями в деяких завданнях."
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VL - це остання версія моделі Qwen-VL, яка досягла передових результатів у тестуванні візуального розуміння."
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5 — це нова серія великих мовних моделей, призначена для оптимізації обробки інструктивних завдань."
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5 — це нова серія великих мовних моделей, призначена для оптимізації обробки інструктивних завдань."
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "description": "Велика мовна модель, розроблена командою Alibaba Cloud Tongyi Qianwen."
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5 - це нова серія великих мовних моделей з покращеними здібностями розуміння та генерації."
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5 - це нова серія великих мовних моделей, націлена на оптимізацію обробки завдань з інструкціями."
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5 — це нова серія великих мовних моделей, призначена для оптимізації обробки інструктивних завдань."
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5 - це нова серія великих мовних моделей, націлена на оптимізацію обробки завдань з інструкціями."
  },
  "Qwen/Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder зосереджений на написанні коду."
  },
  "Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct — це остання версія серії мовних моделей, специфічних для коду, випущена Alibaba Cloud. Ця модель значно покращила здібності генерації коду, виведення та виправлення на основі Qwen2.5, навчаючись на 5.5 трильйонах токенів. Вона не тільки посилила кодування, але й зберегла переваги в математиці та загальних здібностях. Модель надає більш повну основу для практичних застосувань, таких як інтелектуальні агенти коду."
  },
  "Qwen/Qwen2.5-VL-32B-Instruct": {
    "description": "Qwen2.5-VL-32B-Instruct — це мультимодальна мовна модель, розроблена командою Tongyi Qianwen, яка є частиною серії Qwen2.5-VL. Модель не тільки чудово розпізнає звичайні об'єкти, а й аналізує текст, діаграми, іконки, графіки та композицію в зображеннях. Вона може функціонувати як візуальний агент, здатний до логічних міркувань та динамічного управління інструментами, включаючи роботу з комп'ютерами та мобільними пристроями. Крім того, модель точно визначає місцезнаходження об'єктів на зображеннях та генерує структуровані виводи для документів, таких як рахунки та таблиці. Порівняно з попередньою версією Qwen2-VL, дана модель демонструє покращені математичні здібності та навички вирішення завдань завдяки навчанню з підкріпленням, а також більш природний стиль відповідей, що відповідає людським уподобанням."
  },
  "Qwen/Qwen2.5-VL-72B-Instruct": {
    "description": "Qwen2.5-VL — це візуально-мовна модель із серії Qwen2.5. Модель демонструє значні покращення в різних аспектах: має сильніші здібності до візуального розуміння, може розпізнавати звичайні об'єкти, аналізувати текст, діаграми та макети; як візуальний агент здатна міркувати та динамічно направляти використання інструментів; підтримує розуміння довгих відео тривалістю понад 1 годину з можливістю виділення ключових подій; може точно локалізувати об'єкти на зображенні, генеруючи обмежувальні рамки або точки; підтримує генерацію структурованого виводу, що особливо корисно для сканованих даних, таких як рахунки-фактури та таблиці."
  },
  "Qwen/Qwen3-14B": {
    "description": "Qwen3 — це нова генерація моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі за кількома ключовими напрямками, включаючи міркування, загальні завдання, агентські функції та багатомовність, а також підтримує перемикання режимів міркування."
  },
  "Qwen/Qwen3-235B-A22B": {
    "description": "Qwen3 — це нова генерація моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі за кількома ключовими напрямками, включаючи міркування, загальні завдання, агентські функції та багатомовність, а також підтримує перемикання режимів міркування."
  },
  "Qwen/Qwen3-235B-A22B-Instruct-2507": {
    "description": "Qwen3-235B-A22B-Instruct-2507 — флагманська модель серії Qwen3 з архітектурою змішаних експертів (MoE), розроблена командою Alibaba Cloud Tongyi Qianwen. Модель містить 235 мільярдів параметрів, з яких при кожному виведенні активується 22 мільярди. Це оновлена версія Qwen3-235B-A22B у немислячому режимі, з покращеннями у слідуванні інструкціям, логічному висновку, розумінні тексту, математиці, науці, програмуванні та використанні інструментів. Модель розширює покриття багатомовних знань та краще узгоджується з користувацькими перевагами в суб'єктивних та відкритих завданнях, забезпечуючи більш корисний та якісний текст."
  },
  "Qwen/Qwen3-235B-A22B-Thinking-2507": {
    "description": "Qwen3-235B-A22B-Thinking-2507 — велика мовна модель серії Qwen3, розроблена командою Alibaba Tongyi Qianwen, орієнтована на складні завдання міркування. Модель побудована на архітектурі змішаних експертів (MoE) із загальним числом параметрів 235 мільярдів та активацією близько 22 мільярдів параметрів на токен, що забезпечує високу продуктивність при ефективному використанні ресурсів. Як спеціалізована «мисляча» модель, вона демонструє видатні результати в логічному висновку, математиці, науці, програмуванні та академічних тестах, досягаючи топових показників серед відкритих моделей. Модель також покращує універсальні здібності, такі як слідування інструкціям, використання інструментів та генерація тексту, та нативно підтримує контекст довжиною до 256K токенів, що робить її ідеальною для глибокого аналізу та обробки довгих документів."
  },
  "Qwen/Qwen3-30B-A3B": {
    "description": "Qwen3 — це нова генерація моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі за кількома ключовими напрямками, включаючи міркування, загальні завдання, агентські функції та багатомовність, а також підтримує перемикання режимів міркування."
  },
  "Qwen/Qwen3-30B-A3B-Instruct-2507": {
    "description": "Qwen3-30B-A3B-Instruct-2507 — це оновлена версія моделі Qwen3-30B-A3B у режимі без міркувань. Це модель з гібридними експертами (MoE), що має загалом 30,5 мільярда параметрів та 3,3 мільярда активних параметрів. Модель отримала ключові покращення в багатьох аспектах, включаючи значне підвищення здатності слідувати інструкціям, логічного мислення, розуміння тексту, математики, науки, програмування та використання інструментів. Крім того, вона досягла істотного прогресу в покритті багатомовних рідкісних знань та краще узгоджується з перевагами користувачів у суб'єктивних та відкритих завданнях, що дозволяє генерувати більш корисні відповіді та тексти високої якості. Також покращена здатність до розуміння довгих текстів — тепер до 256K. Ця модель підтримує лише режим без міркувань і не генерує теги <think></think> у виведенні."
  },
  "Qwen/Qwen3-30B-A3B-Thinking-2507": {
    "description": "Qwen3-30B-A3B-Thinking-2507 — це новітня модель «мислення» в серії Qwen3, випущена командою Tongyi Qianwen компанії Alibaba. Будучи гібридною експертною (MoE) моделлю із загальним числом параметрів 30,5 млрд та 3,3 млрд активних параметрів, вона орієнтована на підвищення здатності вирішувати складні завдання. Модель демонструє помітне покращення результатів за академічними бенчмарками в областях логічного міркування, математики, природничих наук, програмування та завдань, що вимагають людської експертизи. Також суттєво посилені її універсальні здібності: слідування інструкціям, використання інструментів, генерація тексту та узгодження з людськими уподобаннями. Модель спочатку підтримує розуміння довгого контексту до 256K токенів і може масштабуватися до 1 млн токенів. Ця версія спеціально розроблена в «режимі мислення» для вирішення вкрай складних завдань за допомогою докладного покрокового міркування; її можливості в ролі агента також знаходяться на високому рівні."
  },
  "Qwen/Qwen3-32B": {
    "description": "Qwen3 — це нова генерація моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі за кількома ключовими напрямками, включаючи міркування, загальні завдання, агентські функції та багатомовність, а також підтримує перемикання режимів міркування."
  },
  "Qwen/Qwen3-8B": {
    "description": "Qwen3 — це нова генерація моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі за кількома ключовими напрямками, включаючи міркування, загальні завдання, агентські функції та багатомовність, а також підтримує перемикання режимів міркування."
  },
  "Qwen/Qwen3-Coder-30B-A3B-Instruct": {
    "description": "Qwen3-Coder-30B-A3B-Instruct — це модель для роботи з кодом із серії Qwen3, розроблена командою Tongyi Qianwen компанії Alibaba. Будучи оптимізованою та полегшеною моделлю, вона зберігає високу продуктивність та ефективність, при цьому орієнтована на покращення обробки коду. Модель демонструє помітні переваги серед відкритих моделей у вирішенні складних завдань, таких як агентне програмування (Agentic Coding), автоматизація дій у браузері та виклики зовнішніх інструментів. Вона спочатку підтримує довгий контекст до 256K токенів і може масштабуватися до 1M токенів, що дозволяє краще розуміти та обробляти кодові бази. Крім того, модель забезпечує потужну підтримку агентного кодування для платформ на зразок Qwen Code та CLINE та включає спеціалізований формат виклику функцій."
  },
  "Qwen/Qwen3-Coder-480B-A35B-Instruct": {
    "description": "Qwen3-Coder-480B-A35B-Instruct — модель для роботи з кодом, випущена Alibaba, що володіє на сьогоднішній день одними з найвиразніших агентних (agentic) можливостей. Це модель змішаних експертів (Mixture-of-Experts, MoE) із сумарно 4800亿 параметрів та 350亿 активних параметрів (приблизно 480 млрд та 35 млрд відповідно), що забезпечує баланс між ефективністю та продуктивністю. Модель спочатку підтримує довжину контексту 256K (≈260 000) токенів та може бути розширена до 1 000 000 токенів за допомогою методів екстраполяції, таких як YaRN, що дозволяє їй працювати з великими репозиторіями коду та вирішувати складні програмні завдання. Qwen3-Coder спроектована для агентних робочих процесів кодування: вона не тільки генерує код, а й здатна автономно взаємодіяти з інструментами та середовищами розробки для вирішення складних завдань. У ряді бенчмарків з кодування та агентних завдань модель демонструє провідні результати серед відкритих моделей, а її продуктивність зіставна з такими передовими рішеннями, як Claude Sonnet 4."
  },
  "Qwen/Qwen3-Next-80B-A3B-Instruct": {
    "description": "Qwen3-Next-80B-A3B-Instruct — це наступного покоління базова модель, випущена командою Alibaba Tongyi Qianwen. Вона заснована на новій архітектурі Qwen3-Next та призначена для досягнення максимальної ефективності навчання та виведення. Модель використовує інноваційний гібридний механізм уваги (Gated DeltaNet та Gated Attention), високорозріджену структуру змішаних експертів (MoE) та безліч оптимізацій стабільності навчання. Як розріджена модель із загальним числом параметрів 80 мільярдів, при виведенні активується всього близько 3 мільярдів параметрів, що значно знижує обчислювальні витрати. При обробці завдань з довгим контекстом більше 32K токенів пропускна здатність виведення перевищує модель Qwen3-32B більш ніж у 10 разів. Ця модель є версією з інструктивним донастроюванням, призначеною для універсальних завдань та не підтримує режим ланцюжка мислення (Thinking). За продуктивністю вона зіставна з флагманською моделлю Tongyi Qianwen Qwen3-235B в деяких бенчмарках, особливо демонструючи явні переваги в завданнях з дуже довгим контекстом."
  },
  "Qwen/Qwen3-Next-80B-A3B-Thinking": {
    "description": "Qwen3-Next-80B-A3B-Thinking — це наступного покоління базова модель, випущена командою Alibaba Tongyi Qianwen, спеціально розроблена для складних завдань міркування. Вона заснована на інноваційній архітектурі Qwen3-Next, яка об'єднує гібридний механізм уваги (Gated DeltaNet та Gated Attention) та високорозріджену структуру змішаних експертів (MoE), спрямовану на максимальну ефективність навчання та виведення. Як розріджена модель із загальним числом параметрів 80 мільярдів, при виведенні активується близько 3 мільярдів параметрів, що значно знижує обчислювальні витрати. При обробці завдань з довгим контекстом більше 32K токенів пропускна здатність виведення перевищує модель Qwen3-32B більш ніж у 10 разів. Ця версія «Thinking» оптимізована для виконання складних багатоетапних завдань, таких як математичні докази, синтез коду, логічний аналіз та планування, і за замовчуванням виводить процес міркування в структурованій формі «ланцюжка мислення». За продуктивністю вона не тільки перевершує дорожчі моделі, такі як Qwen3-32B-Thinking, а й випереджає Gemini-2.5-Flash-Thinking в кількох бенчмарках."
  },
  "Qwen/Qwen3-VL-8B-Instruct": {
    "description": "Qwen3-VL-8B-Instruct — это модель визуально-языкового понимания из серии Qwen3, разработанная на основе Qwen3-8B-Instruct и обученная на большом объёме данных, содержащих изображения и тексты. Она хорошо справляется с задачами общего визуального понимания, визуально-ориентированного диалога и распознавания многоязычного текста на изображениях. Подходит для сценариев визуального вопросно-ответного взаимодействия, описания изображений, следования мультимодальным инструкциям и вызова инструментов."
  },
  "Qwen/Qwen3-VL-8B-Thinking": {
    "description": "Qwen3-VL-8B-Thinking — это версия визуального мышления из серии Qwen3, оптимизированная для сложных многошаговых задач рассуждения. По умолчанию она генерирует цепочку размышлений (thinking chain) перед ответом, чтобы повысить точность вывода. Подходит для сценариев, требующих глубокого анализа, таких как визуальные вопросы и ответы, а также детальный обзор и анализ содержимого изображений."
  },
  "Qwen2-72B-Instruct": {
    "description": "Qwen2 — це остання серія моделей Qwen, що підтримує контекст до 128k. Порівняно з поточними найкращими відкритими моделями, Qwen2-72B значно перевершує провідні моделі за багатьма аспектами, включаючи розуміння природної мови, знання, код, математику та багатомовність."
  },
  "Qwen2-7B-Instruct": {
    "description": "Qwen2 — це остання серія моделей Qwen, здатна перевершувати найкращі відкриті моделі зіставного розміру та навіть більші моделі. Qwen2 7B демонструє значні переваги в кількох тестах, особливо в розумінні коду та китайської мови."
  },
  "Qwen2-VL-72B": {
    "description": "Qwen2-VL-72B — це потужна модель візуальної мови, що підтримує багатомодальну обробку зображень та тексту, здатна точно розпізнавати вміст зображень та генерувати відповідні описи або відповіді."
  },
  "Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5-14B-Instruct — це мовна модель з 14 мільярдами параметрів, з відмінними показниками продуктивності, оптимізована для китайського та багатомовного контексту, підтримує інтелектуальні відповіді, генерацію контенту та інші застосування."
  },
  "Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5-32B-Instruct — це мовна модель з 32 мільярдами параметрів, з збалансованими показниками продуктивності, оптимізована для китайського та багатомовного контексту, підтримує інтелектуальні відповіді, генерацію контенту та інші застосування."
  },
  "Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-Instruct підтримує контекст до 16k, генеруючи довгі тексти понад 8K. Підтримує виклики функцій та безшовну взаємодію із зовнішніми системами, що значно підвищує гнучкість та масштабованість. Знання моделі значно збільшені, а здібності в кодуванні та математиці значно покращені, підтримує понад 29 мов."
  },
  "Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct — це мовна модель з 7 мільярдами параметрів, що підтримує виклики функцій та безшовну взаємодію із зовнішніми системами, що значно підвищує гнучкість та масштабованість. Оптимізована для китайського та багатомовного контексту, підтримує інтелектуальні відповіді, генерацію контенту та інші застосування."
  },
  "Qwen2.5-Coder-14B-Instruct": {
    "description": "Qwen2.5-Coder-14B-Instruct — це модель програмування на основі масштабного попереднього навчання, що володіє потужними здібностями до розуміння та генерації коду, здатна ефективно вирішувати різні завдання програмування, особливо підходить для інтелектуального написання коду, автоматизації скриптів та відповідей на програмні питання."
  },
  "Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder-32B-Instruct — це велика мовна модель, спеціально розроблена для генерації коду, розуміння коду та ефективних сценаріїв розробки, з передовим масштабом параметрів 32B, здатна задовольнити різноманітні потреби програмування."
  },
  "Qwen3-235B": {
    "description": "Qwen3-235B-A22B — модель MoE (гібридних експертів), яка впровадила «гібридний режим міркувань», що дозволяє користувачам безшовно перемикатися між режимами «міркування» та «без міркувань». Підтримує розуміння та міркування на 119 мовах та діалектах, володіє потужними можливостями виклику інструментів. За сукупністю здібностей, коду, математики, багатомовності, знань та міркувань модель конкурує з провідними сучасними великими моделями на ринку, такими як DeepSeek R1, OpenAI o1, o3-mini, Grok 3 та Google Gemini 2.5 Pro."
  },
  "Qwen3-235B-A22B-Instruct-2507-FP8": {
    "description": "Qwen3 235B A22B Instruct 2507: модель, оптимізована для просунутих міркувань та діалогових інструкцій, з гібридною експертною архітектурою для підтримання ефективності виведення при великій кількості параметрів."
  },
  "Qwen3-32B": {
    "description": "Qwen3-32B — щільна модель (Dense Model), що впровадила «гібридний режим міркувань», що дозволяє користувачам безшовно перемикатися між режимами «міркування» та «без міркувань». Завдяки покращенням архітектури моделі, збільшенню обсягу навчальних даних та більш ефективним методам навчання, загальна продуктивність зіставна з Qwen2.5-72B."
  },
  "SenseChat": {
    "description": "Базова версія моделі (V4), довжина контексту 4K, має потужні універсальні можливості."
  },
  "SenseChat-128K": {
    "description": "Базова версія моделі (V4), довжина контексту 128K, демонструє відмінні результати в завданнях розуміння та генерації довгих текстів."
  },
  "SenseChat-32K": {
    "description": "Базова версія моделі (V4), довжина контексту 32K, гнучко застосовується в різних сценаріях."
  },
  "SenseChat-5": {
    "description": "Остання версія моделі (V5.5), довжина контексту 128K, значно покращені здібності в математичному міркуванні, англійських діалогах, слідуванні інструкціям та розумінні довгих текстів, зіставні з GPT-4o."
  },
  "SenseChat-5-1202": {
    "description": "Заснована на версії V5.5, з помітними покращеннями за кількома напрямками: базові навички китайською та англійською, чат, знання в природничих та гуманітарних науках, письмо, математична логіка, контроль довжини тексту."
  },
  "SenseChat-5-Cantonese": {
    "description": "Довжина контексту 32K, перевершує GPT-4 у розумінні діалогів кантонською, зіставний з GPT-4 Turbo у таких областях, як знання, міркування, математика та написання коду."
  },
  "SenseChat-5-beta": {
    "description": "Частково перевершує продуктивність SenseCat-5-1202"
  },
  "SenseChat-Character": {
    "description": "Стандартна версія моделі, довжина контексту 8K, висока швидкість відгуку."
  },
  "SenseChat-Character-Pro": {
    "description": "Розширена версія моделі, довжина контексту 32K, всеосяжні покращення можливостей, підтримує діалоги китайською та англійською мовами."
  },
  "SenseChat-Turbo": {
    "description": "Підходить для швидкої відповіді на запитання та сценаріїв тонкого налаштування моделі."
  },
  "SenseChat-Turbo-1202": {
    "description": "Це остання легковесна версія моделі, яка досягає понад 90% можливостей повної моделі та значно знижує витрати на виведення."
  },
  "SenseChat-Vision": {
    "description": "Остання версія моделі (V5.5) підтримує введення кількох зображень, повністю реалізує оптимізацію базових можливостей моделі та значно покращила розпізнавання властивостей об'єктів, просторові відносини, розпізнавання подій, розуміння сцен, розпізнавання емоцій, логічне міркування та розуміння тексту."
  },
  "SenseNova-V6-5-Pro": {
    "description": "Завдяки всебічному оновленню мультимодальних, мовних та міркувальних даних, а також оптимізації стратегій навчання, нова модель значно покращила мультимодальні міркування та здатність слідувати універсальним інструкціям. Підтримує контекстне вікно до 128k та демонструє видатні результати в спеціалізованих завданнях, таких як OCR та розпізнавання туристичних IP."
  },
  "SenseNova-V6-5-Turbo": {
    "description": "Завдяки всебічному оновленню мультимодальних, мовних та міркувальних даних, а також оптимізації стратегій навчання, нова модель значно покращила мультимодальні міркування та здатність слідувати універсальним інструкціям. Підтримує контекстне вікно до 128k та демонструє видатні результати в спеціалізованих завданнях, таких як OCR та розпізнавання туристичних IP."
  },
  "SenseNova-V6-Pro": {
    "description": "Реалізує рідну єдність можливостей зображень, тексту та відео, долаючи традиційні обмеження роздільних мультимодальних систем, завоювавши подвійне чемпіонство в оцінках OpenCompass та SuperCLUE."
  },
  "SenseNova-V6-Reasoner": {
    "description": "Враховує візуальне та мовне глибоке міркування, реалізує повільне мислення та глибоке міркування, демонструючи повний процес мисленнєвого ланцюжка."
  },
  "SenseNova-V6-Turbo": {
    "description": "Реалізує рідну єдність можливостей зображень, тексту та відео, долаючи традиційні обмеження роздільних мультимодальних систем, значно випереджаючи в ключових аспектах, таких як базові мультимодальні та мовні здібності, поєднуючи літературну та наукову освіту, багаторазово займаючи позиції першої групи в різних оцінках як у країні, так і за кордоном."
  },
  "Skylark2-lite-8k": {
    "description": "Модель другого покоління Skylark (云雀), модель Skylark2-lite має високу швидкість відгуку, підходить для сценаріїв з високими вимогами до оперативності, чутливих до вартості та з не такими високими вимогами до точності моделі. Довжина контекстного вікна становить 8k."
  },
  "Skylark2-pro-32k": {
    "description": "Модель другого покоління Skylark (云雀), версія Skylark2-pro має високу точність моделі, підходить для більш складних сценаріїв генерації тексту, таких як написання спеціалізованої документації, створення романів, високоякісний переклад тощо. Довжина контекстного вікна становить 32k."
  },
  "Skylark2-pro-4k": {
    "description": "Модель другого покоління Skylark (云雀), модель Skylark2-pro має високу точність, підходить для більш складних сценаріїв генерації тексту, таких як спеціалізована документація, створення романів, високоякісний переклад тощо. Довжина контекстного вікна становить 4k."
  },
  "Skylark2-pro-character-4k": {
    "description": "Модель другого покоління Skylark (云雀), модель Skylark2-pro-character демонструє видатні здібності до ролевих взаємодій та чатів, вміє грати різні ролі залежно від вимог користувача, що робить спілкування природним та плавним. Підходить для розробки чат-ботів, віртуальних помічників та онлайн-сервісів з високою швидкістю відгуку."
  },
  "Skylark2-pro-turbo-8k": {
    "description": "Модель другого покоління Skylark (云雀), модель Skylark2-pro-turbo-8k забезпечує швидшу обробку та знижені витрати, довжина контекстного вікна становить 8k."
  },
  "THUDM/GLM-4-32B-0414": {
    "description": "GLM-4-32B-0414 — це нове покоління відкритої моделі серії GLM з 32 мільярдами параметрів. Ця модель може змагатися з серією GPT від OpenAI та серією V3/R1 від DeepSeek."
  },
  "THUDM/GLM-4-9B-0414": {
    "description": "GLM-4-9B-0414 — це компактна модель серії GLM з 9 мільярдами параметрів. Ця модель успадкувала технічні характеристики серії GLM-4-32B, але пропонує легші варіанти розгортання. Незважаючи на менший розмір, GLM-4-9B-0414 все ще демонструє відмінні здібності в завданнях генерації коду, веб-дизайну, генерації графіки SVG та написання на основі пошуку."
  },
  "THUDM/GLM-4.1V-9B-Thinking": {
    "description": "GLM-4.1V-9B-Thinking — це відкрита візуально-мовна модель (VLM), спільно випущена Zhipu AI та лабораторією KEG Університету Цінхуа, спеціально розроблена для вирішення складних мультимодальних когнітивних завдань. Модель заснована на базовій моделі GLM-4-9B-0414 та значно покращує міжмодальні здібності міркування та стабільність за рахунок впровадження механізму міркування «ланцюжок мислення» (Chain-of-Thought) та використання методів навчання з підкріпленням."
  },
  "THUDM/GLM-Z1-32B-0414": {
    "description": "GLM-Z1-32B-0414 — це модель виведення з глибокими міркуваннями. Ця модель заснована на GLM-4-32B-0414 та була розроблена за допомогою холодного старту та розширеного посиленого навчання, а також була додатково навчена в завданнях математики, коду та логіки. Порівняно з базовою моделлю, GLM-Z1-32B-0414 значно покращила математичні здібності та здібності до вирішення складних завдань."
  },
  "THUDM/GLM-Z1-9B-0414": {
    "description": "GLM-Z1-9B-0414 — це компактна модель серії GLM з 9 мільярдами параметрів, але при цьому демонструє дивовижні здібності, зберігаючи традиції відкритого вихідного коду. Незважаючи на менший розмір, ця модель все ще показує відмінні результати в математичному висновку та загальних завданнях, її загальна продуктивність знаходиться на провідному рівні серед моделей відкритого вихідного коду аналогічного розміру."
  },
  "THUDM/GLM-Z1-Rumination-32B-0414": {
    "description": "GLM-Z1-Rumination-32B-0414 — це модель глибокого виведення з міркуваннями (порівнянна з Deep Research від OpenAI). На відміну від типових моделей глибокого мислення, модель міркувань використовує більш тривалий час глибокого мислення для вирішення більш відкритих та складних завдань."
  },
  "THUDM/glm-4-9b-chat": {
    "description": "GLM-4 9B — це відкрита версія, що забезпечує оптимізований діалоговий досвід для застосунків."
  },
  "Tongyi-Zhiwen/QwenLong-L1-32B": {
    "description": "QwenLong-L1-32B — перша великомасштабна модель міркувань з довгим контекстом (LRM), навчена з використанням навчання з підкріпленням, оптимізована для завдань міркувань з довгим текстом. Модель реалізує стабільний перехід від короткого до довгого контексту через прогресивне розширення контексту в рамках навчання з підкріпленням. У семи бенчмарках з питань з довгим контекстом QwenLong-L1-32B перевершила флагманські моделі OpenAI-o3-mini та Qwen3-235B-A22B, демонструючи продуктивність, зіставну з Claude-3.7-Sonnet-Thinking. Особливо добре справляється зі складними завданнями математичного, логічного та багатоетапного міркування."
  },
  "Yi-34B-Chat": {
    "description": "Yi-1.5-34B, зберігаючи видатні універсальні мовні здібності оригінальної серії моделей, значно покращила математичну логіку та здібності до кодування завдяки інкрементальному навчанню на 500 мільярдів високоякісних токенів."
  },
  "abab5.5-chat": {
    "description": "Орієнтований на виробничі сценарії, підтримує обробку складних завдань та ефективну генерацію тексту, підходить для професійних застосувань."
  },
  "abab5.5s-chat": {
    "description": "Спеціально розроблений для діалогів китайською мовою, забезпечуючи високоякісну генерацію діалогів китайською, підходить для різних застосувань."
  },
  "abab6.5g-chat": {
    "description": "Спеціально розроблений для багатомовних діалогів, підтримує високоякісну генерацію діалогів англійською та іншими мовами."
  },
  "abab6.5s-chat": {
    "description": "Підходить для широкого спектру завдань обробки природної мови, включаючи генерацію тексту, діалогові системи тощо."
  },
  "abab6.5t-chat": {
    "description": "Оптимізований для діалогів китайською мовою, забезпечуючи плавну генерацію діалогів, що відповідає китайським мовним звичкам."
  },
  "accounts/fireworks/models/deepseek-r1": {
    "description": "DeepSeek-R1 — це передова велика мовна модель, оптимізована за допомогою навчання з підкріпленням та холодних стартових даних, що володіє видатними показниками виведення, математики та програмування."
  },
  "accounts/fireworks/models/deepseek-v3": {
    "description": "Потужна мовна модель Mixture-of-Experts (MoE) від Deepseek із загальною кількістю параметрів 671B, що активує 37B параметрів на кожен токен."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "Модель Llama 3 70B для команд, спеціально оптимізована для багатомовних діалогів та розуміння природної мови, перевершує більшість конкурентних моделей."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "Модель Llama 3 8B для команд, оптимізована для діалогів та багатомовних завдань, демонструє видатні та ефективні результати."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "Модель Llama 3 8B для команд (HF версія), результати якої збігаються з офіційною реалізацією, має високу узгодженість та сумісність між платформами."
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "Модель Llama 3.1 405B для команд, що володіє величезною кількістю параметрів, підходить для складних завдань та сценаріїв з високим навантаженням."
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "Модель Llama 3.1 70B для команд, що забезпечує видатні можливості розуміння та генерації природної мови, є ідеальним вибором для діалогових та аналітичних завдань."
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "Модель Llama 3.1 8B для команд, оптимізована для багатомовних діалогів, здатна перевершувати більшість відкритих та закритих моделей за загальними галузевими стандартами."
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "Модель Meta з 11B параметрами, оптимізована для виведення зображень. Ця модель призначена для візуального розпізнавання, виведення зображень, опису зображень та відповіді на загальні питання щодо зображень. Ця модель здатна розуміти візуальні дані, такі як графіки та діаграми, та долати розрив між візуальним та мовним розумінням, генеруючи текстові описи деталей зображень."
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "Модель Llama 3.2 3B для інструкцій - це компактна багатомовна модель, запущена Meta. Ця модель призначена для підвищення ефективності та забезпечує значне покращення в затримці та вартості порівняно з більшими моделями. Приклади використання моделі включають запити, переоформлення підказок та допомогу в написанні."
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "Модель Meta з 90B параметрами, оптимізована для виведення зображень. Ця модель призначена для візуального розпізнавання, виведення зображень, опису зображень та відповіді на загальні питання щодо зображень. Ця модель здатна розуміти візуальні дані, такі як графіки та діаграми, та долати розрив між візуальним та мовним розумінням, генеруючи текстові описи деталей зображень."
  },
  "accounts/fireworks/models/llama-v3p3-70b-instruct": {
    "description": "Llama 3.3 70B Instruct — це оновлена версія Llama 3.1 70B від грудня. Ця модель покращена на основі Llama 3.1 70B (випущеної в липні 2024 року), з посиленою підтримкою викликів інструментів, багатомовного тексту, математичних та програмних можливостей. Модель досягла провідних у галузі показників в області виведення, математики та дотримання інструкцій, забезпечуючи продуктивність, зіставну з 3.1 405B, при цьому володіючи значними перевагами за швидкістю та вартістю."
  },
  "accounts/fireworks/models/mistral-small-24b-instruct-2501": {
    "description": "Модель з 24B параметрами, що володіє передовими можливостями, зіставними з більшими моделями."
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "Mixtral MoE 8x22B для команд, з великою кількістю параметрів та архітектурою з кількома експертами, всебічно підтримує ефективну обробку складних завдань."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "Mixtral MoE 8x7B для команд, архітектура з кількома експертами забезпечує ефективне виконання та слідування командам."
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "Модель MythoMax L2 13B, що використовує нові технології об'єднання, добре підходить для оповідання та ролевих ігор."
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "Phi 3 Vision для команд, легковесна мультимодальна модель, здатна обробляти складну візуальну та текстову інформацію, володіючи високою здатністю до виведення."
  },
  "accounts/fireworks/models/qwen-qwq-32b-preview": {
    "description": "Модель QwQ — це експериментальна дослідницька модель, розроблена командою Qwen, зосереджена на покращенні можливостей виведення ШІ."
  },
  "accounts/fireworks/models/qwen2-vl-72b-instruct": {
    "description": "72B версія моделі Qwen-VL — це результат останньої ітерації Alibaba, що представляє собою інновації майже за рік."
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5 - це серія мовних моделей, що містить тільки декодери, розроблена командою Qwen від Alibaba Cloud. Ці моделі пропонуються в різних розмірах: 0.5B, 1.5B, 3B, 7B, 14B, 32B та 72B, з варіантами базової та інструкційної версії."
  },
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
    "description": "Qwen2.5 Coder 32B Instruct — це остання версія серії мовних моделей, специфічних для коду, випущена Alibaba Cloud. Ця модель значно покращила здібності генерації коду, виведення та виправлення на основі Qwen2.5, навчаючись на 5.5 трильйонах токенів. Вона не тільки посилила кодування, але й зберегла переваги в математиці та загальних здібностях. Модель надає більш повну основу для практичних застосувань, таких як інтелектуальні агенти коду."
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "Модель Yi-Large, що володіє видатними можливостями обробки кількох мов, підходить для різних завдань генерації та розуміння мови."
  },
  "ai21-jamba-1.5-large": {
    "description": "Багатомовна модель з 398B параметрами (94B активних), що пропонує контекстне вікно довжиною 256K, виклики функцій, структурований вивід та засноване на фактах генерування."
  },
  "ai21-jamba-1.5-mini": {
    "description": "Багатомовна модель з 52B параметрами (12B активних), що пропонує контекстне вікно довжиною 256K, виклики функцій, структурований вивід та засноване на фактах генерування."
  },
  "ai21-labs/AI21-Jamba-1.5-Large": {
    "description": "Багатомовна модель з 398 млрд параметрів (94 млрд активних), що надає вікно контексту довжиною 256K, виклики функцій, структурований вивід та генерацію на основі фактів."
  },
  "ai21-labs/AI21-Jamba-1.5-Mini": {
    "description": "Багатомовна модель з 52 млрд параметрів (12 млрд активних), що надає вікно контексту довжиною 256K, виклики функцій, структурований вивід та генерацію на основі фактів."
  },
  "alibaba/qwen-3-14b": {
    "description": "Qwen3 — це новітнє покоління великомасштабних мовних моделей серії Qwen, що пропонує повний набір щільних та змішаних експертних (MoE) моделей. Завдяки обширному навчанню Qwen3 демонструє проривні досягнення в області виведення, слідування інструкціям, агентних можливостей та підтримки кількох мов."
  },
  "alibaba/qwen-3-235b": {
    "description": "Qwen3 — це новітнє покоління великомасштабних мовних моделей серії Qwen, що пропонує повний набір щільних та змішаних експертних (MoE) моделей. Завдяки обширному навчанню Qwen3 демонструє проривні досягнення в області виведення, слідування інструкціям, агентних можливостей та підтримки кількох мов."
  },
  "alibaba/qwen-3-30b": {
    "description": "Qwen3 — це новітнє покоління великомасштабних мовних моделей серії Qwen, що пропонує повний набір щільних та змішаних експертних (MoE) моделей. Завдяки обширному навчанню Qwen3 демонструє проривні досягнення в області виведення, слідування інструкціям, агентних можливостей та підтримки кількох мов."
  },
  "alibaba/qwen-3-32b": {
    "description": "Qwen3 — це новітнє покоління великомасштабних мовних моделей серії Qwen, що пропонує повний набір щільних та змішаних експертних (MoE) моделей. Завдяки обширному навчанню Qwen3 демонструє проривні досягнення в області виведення, слідування інструкціям, агентних можливостей та підтримки кількох мов."
  },
  "alibaba/qwen3-coder": {
    "description": "Qwen3-Coder-480B-A35B-Instruct — самий агентно-орієнтований кодовий модель серії Qwen, демонструючи видатні результати в агентному кодуванні, використанні браузера агентом та інших базових завданнях кодування, зіставні з Claude Sonnet."
  },
  "amazon/nova-lite": {
    "description": "Дуже недорога мультимодальна модель з надзвичайно високою швидкістю обробки зображень, відео та текстових даних."
  },
  "amazon/nova-micro": {
    "description": "Тільки текстова модель, що забезпечує мінімальну затримку відгуку за дуже низької вартості."
  },
  "amazon/nova-pro": {
    "description": "Високопродуктивна мультимодальна модель з оптимальним поєднанням точності, швидкості та вартості, що підходить для широкого спектру завдань."
  },
  "amazon/titan-embed-text-v2": {
    "description": "Amazon Titan Text Embeddings V2 — легка та ефективна багатомовна модель вбудовування з підтримкою розмірностей 1024, 512 та 256."
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnet встановлює нові галузеві стандарти, перевершуючи моделі конкурентів та Claude 3 Opus, демонструючи відмінні результати в широкому спектрі оцінок, при цьому володіючи швидкістю та вартістю наших моделей середнього рівня."
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet встановив нові стандарти в галузі, перевершивши моделі конкурентів та Claude 3 Opus, продемонструвавши відмінні результати у широкомасштабних оцінках, при цьому володіючи швидкістю та вартістю наших моделей середнього рівня."
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 Haiku — це найшвидша та компактна модель від Anthropic, що забезпечує майже миттєву швидкість відповіді. Вона може швидко відповідати на прості запити. Клієнти зможуть створити безшовний AI-досвід, що імітує людську взаємодію. Claude 3 Haiku може обробляти зображення та повертати текстовий вивід, маючи контекстне вікно в 200K."
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 Opus — це найпотужніша AI-модель від Anthropic, що володіє передовими характеристиками в області високо складних завдань. Вона може обробляти відкриті підказки та невидимі сценарії, демонструючи відмінну плавність та людське розуміння. Claude 3 Opus демонструє передові можливості генеративного AI. Claude 3 Opus може обробляти зображення та повертати текстовий вивід, маючи контекстне вікно в 200K."
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "Claude 3 Sonnet від Anthropic досягає ідеального балансу між інтелектом та швидкістю — особливо підходить для корпоративних робочих навантажень. Він пропонує максимальну корисність за ціною, нижчою за конкурентів, та розроблений як надійний, високоміцний основний механізм для масштабованих AI-розгортань. Claude 3 Sonnet може обробляти зображення та повертати текстовий вивід, маючи контекстне вікно в 200K."
  },
  "anthropic.claude-instant-v1": {
    "description": "Швидка, економічна та все ще дуже потужна модель, здатна обробляти широкий спектр завдань, включаючи повсякденні діалоги, текстовий аналіз, резюме та питання до документів."
  },
  "anthropic.claude-v2": {
    "description": "Модель Anthropic демонструє високі здібності в широкому спектрі завдань, від складних діалогів та генерації креативного контенту до детального слідування інструкціям."
  },
  "anthropic.claude-v2:1": {
    "description": "Оновлена версія Claude 2, що володіє подвійним контекстним вікном та покращеннями в надійності, рівні галюцинацій та точності на основі доказів у довгих документах та контексті RAG."
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 Haiku — найшвидша модель Anthropic на сьогоднішній день, розроблена для корпоративних навантажень зі зазвичай довгими підказками. Haiku швидко аналізує великі обсяги документів, таких як квартальні звіти, контракти або судові справи, при цьому вартість удвічі нижча, ніж у інших моделей з аналогічним рівнем продуктивності."
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opus — найінтелектуальніша модель Anthropic з лідируючою на ринку продуктивністю в складних завданнях. Вона демонструє видатну плавність та людиноподібне розуміння при роботі з відкритими підказками та новими сценаріями."
  },
  "anthropic/claude-3.5-haiku": {
    "description": "Claude 3.5 Haiku — наступне покоління нашої найшвидшої моделі. При швидкості, зіставній з Claude 3 Haiku, вона покращена за всіма навичками та перевершує нашого попереднього найбільшого Claude 3 Opus у багатьох інтелектуальних тестах."
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 Sonnet досягає ідеального балансу між інтелектом та швидкістю, особливо для корпоративних навантажень. Порівняно з аналогами, він забезпечує потужну продуктивність при менших витратах та розроблений для високої надійності в масштабних розгортаннях ШІ."
  },
  "anthropic/claude-3.7-sonnet": {
    "description": "Claude 3.7 Sonnet — перша гібридна модель виведення та найінтелектуальніша модель Anthropic на сьогоднішній день. Вона забезпечує передові можливості в кодуванні, генерації контенту, аналізі даних та плануванні, побудована на базі програмних та обчислювальних здібностей попередника Claude 3.5 Sonnet."
  },
  "anthropic/claude-opus-4": {
    "description": "Claude Opus 4 — найпотужніша модель Anthropic та найкращий у світі кодовий модель, що лідирує в SWE-bench (72,5%) та Terminal-bench (43,2%). Забезпечує стійку продуктивність для тривалих завдань, що вимагають зосередженості та тисяч кроків, здатна працювати безперервно протягом кількох годин, значно розширюючи можливості ШІ-агентів."
  },
  "anthropic/claude-opus-4.1": {
    "description": "Claude Opus 4.1 — готова до використання альтернатива Opus 4, що забезпечує видатну продуктивність та точність для реальних завдань кодування та агентних операцій. Opus 4.1 підвищує передові показники кодування до 74,5% в SWE-bench Verified та з більшою ретельністю та увагою до деталей вирішує складні багатоетапні завдання."
  },
  "anthropic/claude-sonnet-4": {
    "description": "Claude Sonnet 4 значно покращений порівняно з Sonnet 3.7, демонструючи видатні результати в кодуванні з передовим показником 72,7% в SWE-bench. Модель збалансована за продуктивністю та ефективністю, підходить для внутрішніх та зовнішніх сценаріїв та забезпечує більшу керованість завдяки розширеним можливостям контролю."
  },
  "anthropic/claude-sonnet-4.5": {
    "description": "Claude Sonnet 4.5 — найінтелектуальніша модель Anthropic на сьогоднішній день."
  },
  "ascend-tribe/pangu-pro-moe": {
    "description": "Pangu-Pro-MoE 72B-A16B — це розріджена велика мовна модель з 72 мільярдами параметрів та 16 мільярдами активних параметрів, заснована на архітектурі групового змішаного експерта (MoGE). У фазі вибору експертів експерти групуються, і токен активує рівну кількість експертів у кожній групі, що забезпечує баланс навантаження між експертами та значно підвищує ефективність розгортання моделі на платформі Ascend."
  },
  "aya": {
    "description": "Aya 23 — це багатомовна модель, випущена Cohere, що підтримує 23 мови, забезпечуючи зручність для багатомовних застосунків."
  },
  "aya:35b": {
    "description": "Aya 23 — це багатомовна модель, випущена Cohere, що підтримує 23 мови, забезпечуючи зручність для багатомовних застосунків."
  },
  "azure-DeepSeek-R1-0528": {
    "description": "Розгорнуто та надано Microsoft; модель DeepSeek R1 отримала невелике оновлення версії, поточна версія — DeepSeek-R1-0528. В останньому оновленні DeepSeek R1 значно покращив глибину виведення та обчислювальні можливості за рахунок збільшення обчислювальних ресурсів та впровадження алгоритмічних оптимізацій на етапі донавчання. Ця модель демонструє відмінні результати в тестах з математики, програмування та загальної логіки, а її загальна продуктивність близька до провідних моделей, таких як O3 та Gemini 2.5 Pro."
  },
  "baichuan-m2-32b": {
    "description": "Baichuan M2 32B — це гібридна модель експертів, розроблена компанією Baichuan Intelligence, що володіє потужними можливостями логічного висновку."
  },
  "baichuan/baichuan2-13b-chat": {
    "description": "Baichuan-13B — це відкрита комерційна велика мовна модель з 13 мільярдами параметрів, розроблена Baichuan Intelligence, яка показала кращі результати серед моделей того ж розміру на авторитетних бенчмарках китайською та англійською мовами."
  },
  "baidu/ERNIE-4.5-300B-A47B": {
    "description": "ERNIE-4.5-300B-A47B — велика мовна модель, розроблена компанією Baidu на основі архітектури змішаних експертів (MoE). Загальний об'єм параметрів моделі становить 300 мільярдів, однак при виведенні активується лише 47 мільярдів параметрів на токен, що забезпечує високу продуктивність при оптимальній обчислювальній ефективності. Як одна з ключових моделей серії ERNIE 4.5, вона демонструє видатні здібності в завданнях розуміння тексту, генерації, міркування та програмування. Модель використовує інноваційний метод попереднього навчання з мультимодальним гетерогенним MoE, об'єднуючи текстові та візуальні модальності, що значно підвищує її універсальні можливості, особливо у слідуванні інструкціям та запам'ятовуванні знань про світ."
  },
  "c4ai-aya-expanse-32b": {
    "description": "Aya Expanse — це високопродуктивна багатомовна модель 32B, створена для того, щоб кинути виклик продуктивності одномовних моделей за допомогою інновацій в області налаштування за інструкціями, арбітражу даних, навчання уподобанням та об'єднання моделей. Вона підтримує 23 мови."
  },
  "c4ai-aya-expanse-8b": {
    "description": "Aya Expanse — це високопродуктивна багатомовна модель 8B, створена для того, щоб кинути виклик продуктивності одномовних моделей за допомогою інновацій в області налаштування за інструкціями, арбітражу даних, навчання уподобанням та об'єднання моделей. Вона підтримує 23 мови."
  },
  "c4ai-aya-vision-32b": {
    "description": "Aya Vision — це передова мультимодальна модель, яка демонструє відмінні результати за кількома ключовими бенчмарками в області мовних, текстових та візуальних можливостей. Ця версія з 32 мільярдами параметрів зосереджена на передових багатомовних результатах."
  },
  "c4ai-aya-vision-8b": {
    "description": "Aya Vision — це передова мультимодальна модель, яка демонструє відмінні результати за кількома ключовими бенчмарками в області мовних, текстових та візуальних можливостей. Ця версія з 8 мільярдами параметрів зосереджена на низькій затримці та оптимальній продуктивності."
  },
  "charglm-3": {
    "description": "CharGLM-3 розроблений для ролевих ігор та емоційного супроводу, підтримує наддовгу багаторазову пам'ять та персоналізовані діалоги, має широке застосування."
  },
  "charglm-4": {
    "description": "CharGLM-4 розроблений для ролевих ігор та емоційного супроводу, підтримує наддовгу багаторазову пам'ять та персоналізовані діалоги, має широке застосування."
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4o — це динамічна модель, яка оновлюється в реальному часі, щоб залишатися актуальною. Вона поєднує в собі потужне розуміння мови та генерацію, підходячи для масштабних застосунків, включаючи обслуговування клієнтів, освіту та технічну підтримку."
  },
  "claude-2.0": {
    "description": "Claude 2 пропонує ключові покращення для бізнесу, включаючи провідні в галузі 200K токенів контексту, значне зниження частоти галюцинацій моделі, системні підказки та нову тестову функцію: виклик інструментів."
  },
  "claude-2.1": {
    "description": "Claude 2 пропонує ключові покращення для бізнесу, включаючи провідні в галузі 200K токенів контексту, значне зниження частоти галюцинацій моделі, системні підказки та нову тестову функцію: виклик інструментів."
  },
  "claude-3-5-haiku-20241022": {
    "description": "Claude 3.5 Haiku — це найшвидша наступна модель від Anthropic. Порівняно з Claude 3 Haiku, Claude 3.5 Haiku продемонструвала покращення у всіх навичках та перевершила попередню найбільшу модель Claude 3 Opus у багатьох інтелектуальних тестах."
  },
  "claude-3-5-haiku-latest": {
    "description": "Claude 3.5 Haiku забезпечує швидку реакцію, підходить для легких завдань."
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnet пропонує можливості, що перевершують Opus, та швидкість, швидшу за Sonnet, при цьому зберігаючи ту саму ціну. Sonnet особливо гарний у програмуванні, науці про дані, візуальній обробці та завданнях агентів."
  },
  "claude-3-5-sonnet-20241022": {
    "description": "Claude 3.5 Sonnet пропонує можливості, що перевищують Opus, та швидкість, що перевищує Sonnet, при цьому зберігаючи ту саму ціну. Sonnet особливо гарний у програмуванні, даних, візуальній обробці та агентних завданнях."
  },
  "claude-3-7-sonnet-20250219": {
    "description": "Claude 3.7 Sonnet — це найпотужніша модель від Anthropic, що володіє передовими характеристиками в області високо складних завдань. Вона може обробляти відкриті підказки та невидимі сценарії, демонструючи відмінну плавність та людське розуміння. Claude 3.7 Sonnet демонструє передові можливості генеративного AI. Claude 3.7 Sonnet може обробляти зображення та повертати текстовий вивід, маючи контекстне вікно в 200K."
  },
  "claude-3-7-sonnet-latest": {
    "description": "Claude 3.7 Sonnet — новітня та найпотужніша модель Anthropic для обробки високо складних завдань. Вона демонструє видатні показники в продуктивності, інтелекті, плавності та розумінні."
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haiku — це найшвидша та компактна модель від Anthropic, призначена для досягнення майже миттєвих відповідей. Вона володіє швидкою та точною спрямованою продуктивністю."
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opus — це найпотужніша модель від Anthropic для обробки висококомплексних завдань. Вона демонструє видатні результати за продуктивністю, інтелектом, плавністтю та розумінням."
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnet забезпечує ідеальний баланс між інтелектом та швидкістю для корпоративних робочих навантажень. Він пропонує максимальну корисність за нижчою ціною, надійний та підходить для масштабного розгортання."
  },
  "claude-haiku-4-5-20251001": {
    "description": "Claude Haiku 4.5 — найшвидша та інтелектуальна модель Haiku від Anthropic, що володіє блискавичною швидкістю та розширеними можливостями міркування."
  },
  "claude-opus-4-1-20250805": {
    "description": "Claude Opus 4.1 — новітня та найпотужніша модель Anthropic для вирішення високо складних завдань. Вона чудово проявляє себе в продуктивності, інтелекті, плавності та розумінні."
  },
  "claude-opus-4-1-20250805-thinking": {
    "description": "Claude Opus 4.1 — модель мислення, здатна демонструвати просунутий процес міркувань."
  },
  "claude-opus-4-20250514": {
    "description": "Claude Opus 4 — це найпотужніша модель Anthropic для вирішення висококомплексних завдань. Вона чудово проявляє себе в продуктивності, інтелекті, плавності та розумінні."
  },
  "claude-sonnet-4-20250514": {
    "description": "Claude Sonnet 4 може генерувати майже миттєві відповіді або тривалі покрокові міркування, які користувач може ясно бачити."
  },
  "claude-sonnet-4-20250514-thinking": {
    "description": "Модель мислення Claude Sonnet 4 здатна генерувати майже миттєві відповіді або тривалі покрокові міркування, які користувач може ясно бачити."
  },
  "claude-sonnet-4-5-20250929": {
    "description": "Claude Sonnet 4.5 — найінтелектуальніша модель Anthropic на сьогоднішній день."
  },
  "codegeex-4": {
    "description": "CodeGeeX-4 — це потужний AI помічник з програмування, що підтримує інтелектуальні відповіді та автозаповнення коду на різних мовах програмування, підвищуючи ефективність розробки."
  },
  "codegeex4-all-9b": {
    "description": "CodeGeeX4-ALL-9B — це багатомовна модель генерації коду, що підтримує повний спектр функцій, включаючи автозаповнення та генерацію коду, інтерпретатор коду, веб-пошук, виклики функцій та питання по коду на рівні репозиторію, охоплюючи різні сценарії розробки програмного забезпечення. Це одна з найкращих моделей генерації коду з кількістю параметрів менше 10B."
  },
  "codegemma": {
    "description": "CodeGemma — це легковесна мовна модель, спеціально розроблена для різних завдань програмування, що підтримує швидку ітерацію та інтеграцію."
  },
  "codegemma:2b": {
    "description": "CodeGemma — це легковесна мовна модель, спеціально розроблена для різних завдань програмування, що підтримує швидку ітерацію та інтеграцію."
  },
  "codellama": {
    "description": "Code Llama — це LLM, зосереджена на генерації та обговоренні коду, що підтримує широкий спектр мов програмування, підходить для середовища розробників."
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "description": "Code Llama — це LLM, зосереджена на генерації та обговоренні коду, з підтримкою широкого спектру мов програмування, підходяща для середовища розробників."
  },
  "codellama:13b": {
    "description": "Code Llama — це LLM, зосереджена на генерації та обговоренні коду, що підтримує широкий спектр мов програмування, підходить для середовища розробників."
  },
  "codellama:34b": {
    "description": "Code Llama — це LLM, зосереджена на генерації та обговоренні коду, що підтримує широкий спектр мов програмування, підходить для середовища розробників."
  },
  "codellama:70b": {
    "description": "Code Llama — це LLM, зосереджена на генерації та обговоренні коду, що підтримує широкий спектр мов програмування, підходить для середовища розробників."
  },
  "codeqwen": {
    "description": "CodeQwen1.5 — це великомасштабна мовна модель, навчена на великому обсязі кодових даних, спеціально розроблена для вирішення складних завдань програмування."
  },
  "codestral": {
    "description": "Codestral — це перша модель коду від Mistral AI, що забезпечує відмінну підтримку для завдань генерації коду."
  },
  "codestral-latest": {
    "description": "Codestral — це передова генеративна модель, зосереджена на генерації коду, оптимізована для проміжного заповнення та завдань доповнення коду."
  },
  "codex-mini-latest": {
    "description": "codex-mini-latest — це доопрацьована версія o4-mini, спеціально призначена для Codex CLI. Для прямого використання через API ми рекомендуємо починати з gpt-4.1."
  },
  "cogview-4": {
    "description": "CogView-4 — це перша в історії Zhipu відкрита модель текст-в-зображення, що підтримує генерацію китайських ієрогліфів. Вона значно покращена в розумінні семантики, якості генерації зображень та здатності створювати тексти китайською та англійською мовами. Модель підтримує двомовне введення будь-якої довжини та може генерувати зображення з будь-якою роздільною здатністю в заданих межах."
  },
  "cohere-command-r": {
    "description": "Command R — це масштабована генеративна модель, націлена на RAG та використання інструментів для забезпечення AI на рівні виробництва для підприємств."
  },
  "cohere-command-r-plus": {
    "description": "Command R+ — це модель, оптимізована для RAG, призначена для вирішення завдань корпоративного рівня."
  },
  "cohere/Cohere-command-r": {
    "description": "Command R — масштабована генеративна модель, розроблена для використання з RAG та інструментами, що дозволяє компаніям впроваджувати AI промислового рівня."
  },
  "cohere/Cohere-command-r-plus": {
    "description": "Command R+ — передова оптимізована модель для RAG, призначена для корпоративних робочих навантажень."
  },
  "cohere/command-a": {
    "description": "Command A — найпродуктивніша модель Cohere на сьогоднішній день, відмінно справляється з використанням інструментів, агентними завданнями, генерацією з підтримкою пошуку (RAG) та багатомовними сценаріями. Контекстна довжина Command A становить 256K, модель працює на двох GPU та забезпечує на 150% більшу пропускну здатність порівняно з Command R+ 08-2024."
  },
  "cohere/command-r": {
    "description": "Command R — великомасштабна мовна модель, оптимізована для діалогової взаємодії та завдань з довгим контекстом. Вона належить до категорії «масштабованих» моделей, забезпечуючи баланс між високою продуктивністю та точністю, дозволяючи компаніям перейти від прототипів до промислового використання."
  },
  "cohere/command-r-plus": {
    "description": "Command R+ — остання великомасштабна мовна модель Cohere, оптимізована для діалогової взаємодії та завдань з довгим контекстом. Мета — видатна продуктивність, що дозволяє компаніям перейти від прототипів до промислового використання."
  },
  "cohere/embed-v4.0": {
    "description": "Модель, що дозволяє класифікувати текст, зображення або змішаний контент або перетворювати їх на векторні представлення (ембеддинги)."
  },
  "comfyui/flux-dev": {
    "description": "FLUX.1 Dev — высококачественная модель генерации изображений по тексту, генерирует за 10–50 шагов, подходит для создания художественных и креативных работ"
  },
  "comfyui/flux-kontext-dev": {
    "description": "FLUX.1 Kontext-dev — модель редактирования изображений, поддерживает изменение существующих изображений по текстовым инструкциям, включая локальные правки и перенос стиля"
  },
  "comfyui/flux-krea-dev": {
    "description": "FLUX.1 Krea-dev — безопасная модель генерации изображений по тексту, разработана в сотрудничестве с Krea, оснащена встроенной системой фильтрации контента"
  },
  "comfyui/flux-schnell": {
    "description": "FLUX.1 Schnell — сверхбыстрая модель генерации изображений по тексту, создает качественные изображения за 1–4 шага, идеально подходит для приложений в реальном времени и быстрого прототипирования"
  },
  "comfyui/stable-diffusion-15": {
    "description": "Stable Diffusion 1.5 — классическая модель генерации изображений по тексту с разрешением 512x512, подходит для быстрого прототипирования и творческих экспериментов"
  },
  "comfyui/stable-diffusion-35": {
    "description": "Stable Diffusion 3.5 — модель нового поколения для генерации изображений по тексту, доступна в версиях Large и Medium, требует внешнего файла кодировщика CLIP, обеспечивает высокое качество изображений и точное соответствие подсказкам"
  },
  "comfyui/stable-diffusion-35-inclclip": {
    "description": "Stable Diffusion 3.5 с встроенными кодировщиками CLIP/T5, не требует внешних файлов кодировщика, подходит для моделей типа sd3.5_medium_incl_clips, потребляет меньше ресурсов"
  },
  "comfyui/stable-diffusion-custom": {
    "description": "Пользовательская модель генерации изображений SD, имя файла модели должно быть custom_sd_lobe.safetensors, при наличии VAE используйте custom_sd_vae_lobe.safetensors, файлы моделей необходимо разместить в соответствующей папке согласно требованиям Comfy"
  },
  "comfyui/stable-diffusion-custom-refiner": {
    "description": "Пользовательская модель SDXL для преобразования изображений, имя файла модели должно быть custom_sd_lobe.safetensors, при наличии VAE используйте custom_sd_vae_lobe.safetensors, файлы моделей необходимо разместить в соответствующей папке согласно требованиям Comfy"
  },
  "comfyui/stable-diffusion-refiner": {
    "description": "Модель SDXL для преобразования изображений, выполняет высококачественное преобразование изображений на основе входного изображения, поддерживает перенос стиля, восстановление изображений и креативные трансформации"
  },
  "comfyui/stable-diffusion-xl": {
    "description": "Модель SDXL для генерации изображений по тексту, поддерживает высокое разрешение 1024x1024, обеспечивает улучшенное качество изображений и детализацию"
  },
  "command": {
    "description": "Діалогова модель, що слідує інструкціям, яка демонструє високу якість та надійність у мовних завданнях, а також має довшу довжину контексту порівняно з нашою базовою генеративною моделлю."
  },
  "command-a-03-2025": {
    "description": "Команда A — це наша найпотужніша модель на сьогоднішній день, яка демонструє відмінні результати у використанні інструментів, агентіруванні, покращеній генерації за допомогою пошуку (RAG) та багатомовних застосунках. Команда A має довжину контексту 256K та може працювати всього на двох GPU, а продуктивність збільшилася на 150% порівняно з Command R+ 08-2024."
  },
  "command-light": {
    "description": "Більш компактна та швидка версія Command, майже настільки ж потужна, але швидша."
  },
  "command-light-nightly": {
    "description": "Щоб скоротити часові інтервали між основними випусками, ми представили нічну версію моделі Command. Для серії command-light ця версія називається command-light-nightly. Зверніть увагу, що command-light-nightly — це найновіша, експериментальна та (можливо) нестабільна версія. Нічні версії регулярно оновлюються без попереднього повідомлення, тому їх не рекомендується використовувати у виробничому середовищі."
  },
  "command-nightly": {
    "description": "Щоб скоротити часові інтервали між основними випусками, ми представили нічну версію моделі Command. Для серії Command ця версія називається command-nightly. Зверніть увагу, що command-nightly — це найновіша, експериментальна та (можливо) нестабільна версія. Нічні версії регулярно оновлюються без попереднього повідомлення, тому їх не рекомендується використовувати у виробничому середовищі."
  },
  "command-r": {
    "description": "Command R — це LLM, оптимізована для діалогів та завдань з довгим контекстом, особливо підходить для динамічної взаємодії та управління знаннями."
  },
  "command-r-03-2024": {
    "description": "Команда R — це діалогова модель, що слідує інструкціям, яка демонструє вищу якість та надійність у мовних завданнях, а також має довшу довжину контексту порівняно з попередніми моделями. Вона може використовуватися для складних робочих процесів, таких як генерація коду, покращена генерація за допомогою пошуку (RAG), використання інструментів та агентірування."
  },
  "command-r-08-2024": {
    "description": "command-r-08-2024 — це оновлена версія моделі Command R, випущена у серпні 2024 року."
  },
  "command-r-plus": {
    "description": "Command R+ — це високопродуктивна велика мовна модель, спеціально розроблена для реальних бізнес-сценаріїв та складних застосунків."
  },
  "command-r-plus-04-2024": {
    "description": "Команда R+ — це діалогова модель, що слідує інструкціям, яка демонструє вищу якість та надійність у мовних завданнях, а також має довшу довжину контексту порівняно з попередніми моделями. Вона найкраще підходить для складних робочих процесів RAG та багаторазового використання інструментів."
  },
  "command-r-plus-08-2024": {
    "description": "Command R+ — це діалогова модель, що слідує інструкціям, яка демонструє вищу якість та надійність у мовних завданнях, а також має довшу довжину контексту порівняно з попередніми моделями. Вона найбільш підходить для складних робочих процесів RAG та багатоетапного використання інструментів."
  },
  "command-r7b-12-2024": {
    "description": "command-r7b-12-2024 — це компактна та ефективна оновлена версія, випущена у грудні 2024 року. Вона демонструє відмінні результати в завданнях, що вимагають складного міркування та багаторазової обробки, таких як RAG, використання інструментів та агентірування."
  },
  "computer-use-preview": {
    "description": "Модель computer-use-preview спеціально розроблена для «інструментів використання комп'ютера» та навчена розуміти та виконувати завдання, пов'язані з комп'ютером."
  },
  "dall-e-2": {
    "description": "Друга генерація моделі DALL·E, що підтримує більш реалістичну та точну генерацію зображень з роздільною здатністю в 4 рази вищою, ніж у першої генерації."
  },
  "dall-e-3": {
    "description": "Остання модель DALL·E, випущена в листопаді 2023 року. Підтримує більш реалістичну та точну генерацію зображень з сильнішою деталізацією."
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instruct пропонує високу надійність в обробці команд, підтримуючи застосування в різних галузях."
  },
  "deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1 — це модель виведення, керована методом навчання з підкріпленням (RL), яка вирішує проблеми повторюваності та читабельності моделі. Перед застосуванням RL DeepSeek-R1 вводить дані холодного старту, що додатково оптимізує продуктивність виведення. Вона показує зіставні результати з OpenAI-o1 у математичних, кодових та завданнях виведення, а також покращує загальну ефективність завдяки ретельно розробленим методам навчання."
  },
  "deepseek-ai/DeepSeek-R1-0528": {
    "description": "DeepSeek R1 значно покращив глибину міркувань та висновків, використовуючи збільшені обчислювальні ресурси та алгоритмічні оптимізації в процесі донавчання. Модель демонструє відмінні результати в різних бенчмарках, включаючи математику, програмування та загальну логіку. Загальна продуктивність тепер близька до провідних моделей, таких як O3 та Gemini 2.5 Pro."
  },
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B": {
    "description": "DeepSeek-R1-0528-Qwen3-8B — модель, отримана шляхом дистиляції ланцюжків міркувань з DeepSeek-R1-0528 у Qwen3 8B Base. Ця модель досягла передових результатів (SOTA) серед відкритих моделей, перевершивши Qwen3 8B на 10% у тесті AIME 2024 та досягнувши рівня продуктивності Qwen3-235B-thinking. Модель демонструє відмінні результати в математичному міркуванні, програмуванні та загальній логіці, має архітектуру, аналогічну Qwen3-8B, але використовує токенізатор DeepSeek-R1-0528."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "description": "Модель DeepSeek-R1, дистильована за допомогою посиленого навчання та даних холодного старту, оптимізує продуктивність виведення, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "Модель DeepSeek-R1, дистильована за допомогою посиленого навчання та даних холодного старту, оптимізує продуктивність виведення, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
    "description": "Модель DeepSeek-R1, дистильована за допомогою посиленого навчання та даних холодного старту, оптимізує продуктивність виведення, оновлюючи стандарт багатозадачності у відкритих моделях."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "description": "DeepSeek-R1-Distill-Qwen-32B — це модель, отримана за допомогою дистиляції на основі Qwen2.5-32B. Ця модель була донавчена на 800000 відібраних зразків, згенерованих DeepSeek-R1, та демонструє видатну продуктивність у таких областях, як математика, програмування та логіка. Вона показала відмінні результати в кількох бенчмарках, включаючи AIME 2024, MATH-500 та GPQA Diamond, досягнувши 94.3% точності на MATH-500, демонструючи потужні здібності математичного висновку."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "description": "DeepSeek-R1-Distill-Qwen-7B — це модель, отримана за допомогою дистиляції на основі Qwen2.5-Math-7B. Ця модель була донавчена на 800000 відібраних зразків, згенерованих DeepSeek-R1, та демонструє відмінні здібності висновку. Вона показала видатні результати в кількох бенчмарках, включаючи 92.8% точності на MATH-500, 55.5% прохідний рівень на AIME 2024 та 1189 балів на CodeForces, демонструючи сильні математичні та програмні здібності для моделі обсягом 7B."
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5 об'єднує відмінні риси попередніх версій, покращуючи загальні та кодувальні здібності."
  },
  "deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3 — це мовна модель змішаних експертів (MoE) з 6710 мільярдами параметрів, що використовує багатоголову потенційну увагу (MLA) та архітектуру DeepSeekMoE, у поєднанні зі стратегією балансування навантаження без допоміжних втрат, що оптимізує ефективність виведення та навчання. Після попереднього навчання на 14,8 трильйонах високоякісних токенів та подальшої супервізійної донастройки та навчання з підкріпленням, DeepSeek-V3 перевершує інші відкриті моделі та наближається до провідних закритих моделей."
  },
  "deepseek-ai/DeepSeek-V3.1": {
    "description": "DeepSeek-V3.1 — гібридна велика мовна модель, випущена DeepSeek AI, яка включає безліч важливих покращень порівняно з попередніми версіями. Головною інновацією моделі є інтеграція режимів «мислення» (Thinking Mode) та «без мислення» (Non-thinking Mode), які користувач може гнучко перемикати, змінюючи шаблони діалогу для різних завдань. Завдяки спеціалізованій пост-тренувальній оптимізації V3.1 значно покращила продуктивність при виклику інструментів та виконанні завдань агента, забезпечуючи кращу підтримку зовнішніх пошукових інструментів та виконання багатоетапних складних завдань. Модель заснована на DeepSeek-V3.1-Base та донавчена з використанням двоетапного розширення довгих текстів, що значно збільшило обсяг тренувальних даних та покращило роботу з довгими документами та великими обсягами коду. Як відкрита модель, DeepSeek-V3.1 демонструє зіставні з провідними закритими моделями результати в кодуванні, математиці та міркуваннях, а завдяки архітектурі з експертами (MoE) зберігає величезну ємність моделі при ефективному зниженні витрат на виведення."
  },
  "deepseek-ai/DeepSeek-V3.1-Terminus": {
    "description": "DeepSeek-V3.1-Terminus — оновлена версія моделі V3.1 від DeepSeek, позиціонована як гібридна велика мовна модель з агентськими функціями. У цьому оновленні, зберігаючи колишні можливості моделі, акцент зроблено на виправленні проблем, виявлених користувачами, та підвищенні стабільності. Значно покращена мовна узгодженість, зменшено змішування китайської та англійської мов, а також поява аномальних символів. Модель інтегрує режими «міркування» (Thinking Mode) та «без міркування» (Non-thinking Mode), які користувачі можуть гнучко перемикати через шаблони чату для різних завдань. Важливим покращенням є посилення продуктивності кодового агента (Code Agent) та пошукового агента (Search Agent), що підвищує надійність при виклику інструментів та виконанні багатоетапних складних завдань."
  },
  "deepseek-ai/DeepSeek-V3.2-Exp": {
    "description": "Модель DeepSeek V3.2 Exp являє собою гібридну архітектуру для міркувань, що підтримує як режим міркувань, так і нерефлексивний режим."
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek 67B — це передова модель, навчена для висококомплексних діалогів."
  },
  "deepseek-ai/deepseek-r1": {
    "description": "Сучасна ефективна LLM, що спеціалізується на міркуваннях, математиці та програмуванні."
  },
  "deepseek-ai/deepseek-v3.1": {
    "description": "DeepSeek V3.1: модель наступного покоління для виведення, покращена для складних міркувань та ланцюжків мислення, підходить для завдань, що вимагають глибокого аналізу."
  },
  "deepseek-ai/deepseek-v3.1-terminus": {
    "description": "DeepSeek V3.1: модель нового покоління для просунутого міркування, покращує здібності до складного аналізу та логічних ланцюжків, ідеально підходить для завдань, що вимагають глибокого аналізу."
  },
  "deepseek-ai/deepseek-vl2": {
    "description": "DeepSeek-VL2 — це модель візуальної мови, розроблена на основі DeepSeekMoE-27B, що використовує архітектуру MoE з розрідженою активацією, яка демонструє видатну продуктивність при активації всього 4,5 мільярда параметрів. Ця модель показує відмінні результати в таких завданнях, як візуальні питання та відповіді, оптичне розпізнавання символів, розуміння документів/таблиць/графіків та візуальна локалізація."
  },
  "deepseek-chat": {
    "description": "Нова відкрита модель, що об'єднує загальні та кодові можливості, не тільки зберігає загальні діалогові здібності оригінальної моделі Chat та потужні можливості обробки коду моделі Coder, а й краще узгоджується з людськими уподобаннями. Крім того, DeepSeek-V2.5 значно покращила продуктивність у таких завданнях, як написання текстів та слідування інструкціям."
  },
  "deepseek-coder-33B-instruct": {
    "description": "DeepSeek Coder 33B — це модель мовного кодування, навчена на 20 трильйонах даних, з яких 87% становлять код, а 13% — китайська та англійська мови. Модель використовує розмір вікна 16K та завдання заповнення пропусків, надаючи функції автозаповнення коду та заповнення фрагментів на рівні проектів."
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2 — це відкрита змішана експертна модель коду, що показує відмінні результати в завданнях коду, зіставна з GPT4-Turbo."
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2 — це відкрита змішана експертна модель коду, що показує відмінні результати в завданнях коду, зіставна з GPT4-Turbo."
  },
  "deepseek-r1": {
    "description": "DeepSeek-R1 — це модель виведення, керована методом навчання з підкріпленням (RL), яка вирішує проблеми повторюваності та читабельності моделі. Перед застосуванням RL DeepSeek-R1 вводить дані холодного старту, що додатково оптимізує продуктивність виведення. Вона показує зіставні результати з OpenAI-o1 у математичних, кодових та завданнях виведення, а також покращує загальну ефективність завдяки ретельно розробленим методам навчання."
  },
  "deepseek-r1-0528": {
    "description": "Модель повної потужності з 685 мільярдами параметрів, випущена 28 травня 2025 року. DeepSeek-R1 широко використовує методи навчання з підкріпленням на етапі донавчання, що значно покращує здібності моделі до міркування при мінімальній кількості розмічених даних. Висока продуктивність та сильні можливості в задачах математики, програмування та природно-мовного виведення."
  },
  "deepseek-r1-70b-fast-online": {
    "description": "DeepSeek R1 70B швидка версія, що підтримує онлайн-пошук у реальному часі, забезпечуючи швидшу швидкість відгуку при збереженні продуктивності моделі."
  },
  "deepseek-r1-70b-online": {
    "description": "DeepSeek R1 70B стандартна версія, що підтримує онлайн-пошук у реальному часі, підходить для діалогів та текстових завдань, що вимагають актуальної інформації."
  },
  "deepseek-r1-distill-llama": {
    "description": "deepseek-r1-distill-llama — це модель, отримана шляхом дистиляції з DeepSeek-R1 на основі Llama."
  },
  "deepseek-r1-distill-llama-70b": {
    "description": "DeepSeek R1 — більша та розумніша модель у наборі DeepSeek, була дистильована в архітектуру Llama 70B. На основі бенчмарків та ручної оцінки ця модель розумніша, особливо в завданнях, що вимагають математичної та фактичної точності."
  },
  "deepseek-r1-distill-llama-8b": {
    "description": "Моделі серії DeepSeek-R1-Distill були отримані за допомогою технології дистиляції знань, донастроюючи зразки, згенеровані DeepSeek-R1, на відкритих моделях, таких як Qwen та Llama."
  },
  "deepseek-r1-distill-qianfan-llama-70b": {
    "description": "Випущена 14 лютого 2025 року, дистильована модель, розроблена командою Qianfan на основі Llama3_70B (створена з використанням Meta Llama), у дистильовані дані також були додані матеріали Qianfan."
  },
  "deepseek-r1-distill-qianfan-llama-8b": {
    "description": "Випущена 14 лютого 2025 року, дистильована модель, розроблена командою Qianfan на основі Llama3_8B (створена з використанням Meta Llama), у дистильовані дані також були додані матеріали Qianfan."
  },
  "deepseek-r1-distill-qwen": {
    "description": "deepseek-r1-distill-qwen — це модель, отримана методом дистиляції з DeepSeek-R1 на основі Qwen."
  },
  "deepseek-r1-distill-qwen-1.5b": {
    "description": "Моделі серії DeepSeek-R1-Distill були отримані за допомогою технології дистиляції знань, донастроюючи зразки, згенеровані DeepSeek-R1, на відкритих моделях, таких як Qwen та Llama."
  },
  "deepseek-r1-distill-qwen-14b": {
    "description": "Моделі серії DeepSeek-R1-Distill були отримані за допомогою технології дистиляції знань, донастроюючи зразки, згенеровані DeepSeek-R1, на відкритих моделях, таких як Qwen та Llama."
  },
  "deepseek-r1-distill-qwen-32b": {
    "description": "Моделі серії DeepSeek-R1-Distill були отримані за допомогою технології дистиляції знань, донастроюючи зразки, згенеровані DeepSeek-R1, на відкритих моделях, таких як Qwen та Llama."
  },
  "deepseek-r1-distill-qwen-7b": {
    "description": "Моделі серії DeepSeek-R1-Distill були отримані за допомогою технології дистиляції знань, донастроюючи зразки, згенеровані DeepSeek-R1, на відкритих моделях, таких як Qwen та Llama."
  },
  "deepseek-r1-fast-online": {
    "description": "DeepSeek R1 повна швидка версія, що підтримує онлайн-пошук у реальному часі, об'єднуючи потужні можливості 671B параметрів та швидшу швидкість відгуку."
  },
  "deepseek-r1-online": {
    "description": "DeepSeek R1 повна версія, що має 671B параметрів, підтримує онлайн-пошук у реальному часі, володіє потужнішими здібностями розуміння та генерації."
  },
  "deepseek-reasoner": {
    "description": "Режим міркування DeepSeek V3.2. Перед виведенням остаточної відповіді модель спочатку генерує ланцюжок міркувань для підвищення точності підсумкового результату."
  },
  "deepseek-v2": {
    "description": "DeepSeek V2 — це ефективна мовна модель Mixture-of-Experts, що підходить для економічно ефективних потреб обробки."
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236B — це модель коду DeepSeek, що забезпечує потужні можливості генерації коду."
  },
  "deepseek-v3": {
    "description": "DeepSeek-V3 — це модель MoE, розроблена компанією Hangzhou DeepSeek AI Technology Research Co., Ltd., яка показує видатні результати в кількох тестах та займає перше місце серед відкритих моделей у основних рейтингах. V3 порівняно з моделлю V2.5 збільшила швидкість генерації в 3 рази, забезпечуючи користувачам швидше та плавнішше використання."
  },
  "deepseek-v3-0324": {
    "description": "DeepSeek-V3-0324 — це модель MoE з 671 мільярдом параметрів, що володіє видатними здібностями в програмуванні та технічних навичках, розумінні контексту та обробці довгих текстів."
  },
  "deepseek-v3.1": {
    "description": "DeepSeek-V3.1 — нова гібридна модель міркувань від DeepSeek, що підтримує два режими міркувань: з міркуваннями та без міркувань, з вищою ефективністю міркувань порівняно з DeepSeek-R1-0528. Після пост-тренувальної оптимізації значно покращена робота з інструментами агента та виконання завдань інтелектуального агента. Підтримує контекстне вікно до 128k та максимальну довжину виведення до 64k токенів."
  },
  "deepseek-v3.1-terminus": {
    "description": "DeepSeek-V3.1-Terminus — це оптимізована версія великої мовної моделі від DeepSeek, спеціально адаптована для роботи на кінцевих пристроях."
  },
  "deepseek-v3.1:671b": {
    "description": "DeepSeek V3.1: модель наступного покоління для виведення, покращена для складних міркувань та ланцюжків мислення, підходить для завдань, що вимагають глибокого аналізу."
  },
  "deepseek-v3.2-exp": {
    "description": "deepseek-v3.2-exp впроваджує механізм розрідженої уваги, спрямований на підвищення ефективності навчання та виведення при обробці довгих текстів, при цьому вартість нижча, ніж у deepseek-v3.1."
  },
  "deepseek/deepseek-chat-v3-0324": {
    "description": "DeepSeek V3 — це експертна змішана модель з 685B параметрами, яка є останньою ітерацією флагманської серії чат-моделей команди DeepSeek.\n\nВона успадкувала модель [DeepSeek V3](/deepseek/deepseek-chat-v3) та демонструє відмінні результати в різних завданнях."
  },
  "deepseek/deepseek-chat-v3-0324:free": {
    "description": "DeepSeek V3 — це експертна змішана модель з 685B параметрами, яка є останньою ітерацією флагманської серії чат-моделей команди DeepSeek.\n\nВона успадкувала модель [DeepSeek V3](/deepseek/deepseek-chat-v3) та демонструє відмінні результати в різних завданнях."
  },
  "deepseek/deepseek-chat-v3.1": {
    "description": "DeepSeek-V3.1 — велика гібридна модель міркувань з підтримкою довгого контексту до 128K та ефективним перемиканням режимів, що демонструє видатну продуктивність та швидкість при виклику інструментів, генерації коду та виконанні складних завдань міркувань."
  },
  "deepseek/deepseek-r1": {
    "description": "Модель DeepSeek R1 отримала невелике оновлення до версії DeepSeek-R1-0528. В останньому оновленні DeepSeek R1 значно покращила глибину та якість виведення за рахунок збільшення обчислювальних ресурсів та впровадження алгоритмічних оптимізацій після навчання. Модель демонструє відмінні результати в математиці, програмуванні та загальній логіці, наближаючись за продуктивністю до лідерів, таких як O3 та Gemini 2.5 Pro."
  },
  "deepseek/deepseek-r1-0528": {
    "description": "DeepSeek-R1 значно покращив здатність моделі до міркування при мінімальній кількості розмічених даних. Перед виведенням остаточної відповіді модель спочатку генерує ланцюжок міркувань для підвищення точності відповіді."
  },
  "deepseek/deepseek-r1-0528:free": {
    "description": "DeepSeek-R1 значно покращив здатність моделі до міркування при мінімальній кількості розмічених даних. Перед виведенням остаточної відповіді модель спочатку генерує ланцюжок міркувань для підвищення точності відповіді."
  },
  "deepseek/deepseek-r1-distill-llama-70b": {
    "description": "DeepSeek-R1-Distill-Llama-70B — дистильована та більш ефективна версія моделі Llama 70B. Вона зберігає високу продуктивність у завданнях генерації тексту при знижених обчислювальних витратах для зручності розгортання та досліджень. Обслуговується на апаратурі Groq з використанням їх спеціалізованих мовних процесорних блоків (LPU) для швидкої та ефективної роботи."
  },
  "deepseek/deepseek-r1-distill-llama-8b": {
    "description": "DeepSeek R1 Distill Llama 8B — це дистильована велика мовна модель на основі Llama-3.1-8B-Instruct, навчена з використанням вихідних даних DeepSeek R1."
  },
  "deepseek/deepseek-r1-distill-qwen-14b": {
    "description": "DeepSeek R1 Distill Qwen 14B — це дистильована велика мовна модель на основі Qwen 2.5 14B, навчена з використанням вихідних даних DeepSeek R1. Ця модель перевершила o1-mini від OpenAI в кількох бенчмарках, досягнувши останніх досягнень в області щільних моделей (state-of-the-art). Ось деякі результати бенчмарків:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nРейтинг CodeForces: 1481\nЦя модель, доопрацьована на основі вихідних даних DeepSeek R1, демонструє конкурентоспроможну продуктивність, зіставну з більшими передовими моделями."
  },
  "deepseek/deepseek-r1-distill-qwen-32b": {
    "description": "DeepSeek R1 Distill Qwen 32B — це дистильована велика мовна модель на основі Qwen 2.5 32B, навчена з використанням вихідних даних DeepSeek R1. Ця модель перевершила o1-mini від OpenAI в кількох бенчмарках, досягнувши останніх досягнень в області щільних моделей (state-of-the-art). Ось деякі результати бенчмарків:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nРейтинг CodeForces: 1691\nЦя модель, доопрацьована на основі вихідних даних DeepSeek R1, демонструє конкурентоспроможну продуктивність, зіставну з більшими передовими моделями."
  },
  "deepseek/deepseek-r1/community": {
    "description": "DeepSeek R1 — це остання версія відкритої моделі, випущеної командою DeepSeek, що володіє видатними можливостями виведення, особливо в математичних, програмних та логічних завданнях, досягаючи рівня, зіставного з моделлю o1 від OpenAI."
  },
  "deepseek/deepseek-r1:free": {
    "description": "DeepSeek-R1 значно покращила здібності моделі до міркування при наявності лише дуже обмежених розмічених даних. Перед тим як надати остаточну відповідь, модель спочатку виводить ланцюжок роздумів, щоб підвищити точність остаточної відповіді."
  },
  "deepseek/deepseek-v3": {
    "description": "Швидка універсальна великомасштабна мовна модель з покращеними можливостями виведення."
  },
  "deepseek/deepseek-v3.1-base": {
    "description": "DeepSeek V3.1 Base — покращена версія моделі DeepSeek V3."
  },
  "deepseek/deepseek-v3/community": {
    "description": "DeepSeek-V3 досяг значного прориву в швидкості виведення порівняно з попередніми моделями. Вона займає перше місце серед відкритих моделей та може змагатися з найсучаснішими закритими моделями в світі. DeepSeek-V3 використовує архітектури багатоголової потенційної уваги (MLA) та DeepSeekMoE, які були повністю перевірені в DeepSeek-V2. Крім того, DeepSeek-V3 впровадила допоміжну безубиткову стратегію для балансування навантаження та встановила цілі навчання для багатомаркерного прогнозування для досягнення вищої продуктивності."
  },
  "deepseek_r1": {
    "description": "DeepSeek-R1 — це модель виведення, керована посиленим навчанням (RL), яка вирішує проблеми повторюваності та читабельності в моделі. Перед RL DeepSeek-R1 вводить дані холодного старту, що додатково оптимізує продуктивність виведення. Вона демонструє зіставні результати з OpenAI-o1 у завданнях математики, коду та виведення, і завдяки ретельно розробленим методам навчання покращує загальні результати."
  },
  "deepseek_r1_distill_llama_70b": {
    "description": "DeepSeek-R1-Distill-Llama-70B — це модель, отримана на основі Llama-3.3-70B-Instruct через дистиляцію навчання. Ця модель є частиною серії DeepSeek-R1 та демонструє відмінні результати в математиці, програмуванні та виведенні, використовуючи зразки, згенеровані DeepSeek-R1, для донавчання."
  },
  "deepseek_r1_distill_qwen_14b": {
    "description": "DeepSeek-R1-Distill-Qwen-14B — це модель, отримана на основі Qwen2.5-14B через дистиляцію знань. Ця модель була донавчена на 800000 відібраних зразків, згенерованих DeepSeek-R1, демонструючи відмінні здібності до виведення."
  },
  "deepseek_r1_distill_qwen_32b": {
    "description": "DeepSeek-R1-Distill-Qwen-32B — це модель, отримана на основі Qwen2.5-32B через дистиляцію знань. Ця модель була донавчена на 800000 відібраних зразків, згенерованих DeepSeek-R1, демонструючи видатні результати в різних областях, включаючи математику, програмування та виведення."
  },
  "doubao-1.5-lite-32k": {
    "description": "Doubao-1.5-lite - абсолютно нове покоління легкої моделі, з максимальною швидкістю відгуку, результати та затримка досягають світового рівня."
  },
  "doubao-1.5-pro-256k": {
    "description": "Doubao-1.5-pro-256k заснований на повністю оновленій версії Doubao-1.5-Pro, із загальним покращенням на 10%. Підтримує виведення на 256k контекстних вікон, максимальна довжина виведення становить 12k токенів. Вища продуктивність, більше вікно, відмінне співвідношення ціна-якість, підходить для ширшого спектру застосувань."
  },
  "doubao-1.5-pro-32k": {
    "description": "Doubao-1.5-pro - абсолютно нове покоління основної моделі, з повністю оновленою продуктивністю, видатними результатами в області знань, коду, логіки та інших аспектів."
  },
  "doubao-1.5-thinking-pro": {
    "description": "Doubao-1.5 — це нова модель глибокого мислення, яка демонструє видатні результати в таких професійних областях, як математика, програмування, наукове мислення, а також в універсальних завданнях креативного письма. Вона досягає або наближається до рівня першої групи в галузі на кількох авторитетних бенчмарках, таких як AIME 2024, Codeforces, GPQA. Підтримує контекстне вікно 128k та виведення 16k."
  },
  "doubao-1.5-thinking-pro-m": {
    "description": "Нова глибока модель мислення Doubao-1.5 (версія m оснащена нативною мультимодальною глибокою здатністю виведення), демонструє видатні результати в професійних областях, таких як математика, програмування, наукове міркування, а також у творчому письмі та універсальних завданнях. Досягла або наблизилася до першого рівня в галузі за низкою авторитетних бенчмарків, включаючи AIME 2024, Codeforces, GPQA. Підтримує контекстне вікно 128k та виведення до 16k."
  },
  "doubao-1.5-thinking-vision-pro": {
    "description": "Нова візуальна модель глибокого мислення з посиленими універсальними мультимодальними можливостями розуміння та виведення, що досягла SOTA результатів у 37 з 59 відкритих бенчмарків."
  },
  "doubao-1.5-ui-tars": {
    "description": "Doubao-1.5-UI-TARS — нативна модель агента, орієнтована на взаємодію з графічним інтерфейсом користувача (GUI). Забезпечує безшовну взаємодію з GUI через сприйняття, міркування та дії, імітуючи людські здібності."
  },
  "doubao-1.5-vision-lite": {
    "description": "Doubao-1.5-vision-lite — це нова вдосконалена мультимодальна модель, що підтримує розпізнавання зображень з будь-якою роздільною здатністю та екстремальним співвідношенням сторін, покращуючи здібності до візуального виведення, розпізнавання документів, розуміння детальної інформації та дотримання інструкцій. Підтримує контекстне вікно 128k, максимальна довжина виведення становить 16k токенів."
  },
  "doubao-1.5-vision-pro": {
    "description": "Повністю оновлена мультимодальна велика модель Doubao-1.5-vision-pro, що підтримує розпізнавання зображень з будь-якою роздільною здатністю та екстремальними співвідношеннями сторін, покращена візуальна логіка, розпізнавання документів, розуміння деталей та слідування інструкціям."
  },
  "doubao-1.5-vision-pro-32k": {
    "description": "Повністю оновлена мультимодальна велика модель Doubao-1.5-vision-pro, що підтримує розпізнавання зображень з будь-якою роздільною здатністю та екстремальними співвідношеннями сторін, покращена візуальна логіка, розпізнавання документів, розуміння деталей та слідування інструкціям."
  },
  "doubao-lite-128k": {
    "description": "Має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтами більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 128k."
  },
  "doubao-lite-32k": {
    "description": "Має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтами більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 32k."
  },
  "doubao-lite-4k": {
    "description": "Має виняткову швидкість відгуку та найкраще співвідношення ціна-якість, надаючи клієнтами більш гнучкі варіанти для різних сценаріїв. Підтримує виведення та донавчання з контекстним вікном у 4k."
  },
  "doubao-pro-256k": {
    "description": "Основна модель з найкращою продуктивністю, що підходить для вирішення складних завдань. Відмінно справляється з питаннями-відповідями, резюмуванням, творчим написанням, класифікацією тексту, ролевими іграми та іншими сценаріями. Підтримує виведення та донавчання з контекстним вікном у 256k."
  },
  "doubao-pro-32k": {
    "description": "Основна модель з найкращою продуктивністю, що підходить для вирішення складних завдань. Відмінно справляється з питаннями-відповідями, резюмуванням, творчим написанням, класифікацією тексту, ролевими іграми та іншими сценаріями. Підтримує виведення та донавчання з контекстним вікном у 32k."
  },
  "doubao-seed-1.6": {
    "description": "Doubao-Seed-1.6 — нова мультимодальна модель глибокого мислення, що підтримує три режими мислення: auto, thinking та non-thinking. У режимі non-thinking продуктивність моделі значно вища порівняно з Doubao-1.5-pro/250115. Підтримує контекстне вікно розміром 256k та максимальну довжину виведення до 16k токенів."
  },
  "doubao-seed-1.6-flash": {
    "description": "Doubao-Seed-1.6-flash — мультимодальна модель глибокого мислення з екстремально високою швидкістю виведення, TPOT займає всього 10 мс; підтримує розуміння тексту та візуальних даних, текстове розуміння перевершує попередню lite-версію, візуальне розуміння зіставне з pro-серією конкурентів. Підтримує контекстне вікно 256k та максимальну довжину виведення до 16k токенів."
  },
  "doubao-seed-1.6-lite": {
    "description": "Doubao-Seed-1.6-lite — нова мультимодальна модель глибокого мислення з регульованим рівнем міркування (reasoning effort): Minimal, Low, Medium, High. Забезпечує відмінне співвідношення ціна-якість та є оптимальним вибором для типових завдань. Підтримує контекстне вікно до 256k."
  },
  "doubao-seed-1.6-thinking": {
    "description": "Модель Doubao-Seed-1.6-thinking значно покращена в плані мислення, порівняно з Doubao-1.5-thinking-pro додатково підвищено базові здібності в програмуванні, математиці та логічному міркуванні, підтримується візуальне розуміння. Підтримує контекстне вікно 256k та максимальну довжину виведення до 16k токенів."
  },
  "doubao-seed-1.6-vision": {
    "description": "Doubao-Seed-1.6-vision — модель глибокого візуального роздуму, що демонструє сильніші універсальні мультимодальні здібності розуміння та міркування в таких сценаріях, як освіта, перевірка зображень, інспекції та безпека, а також AI-пошук та відповіді на запитання. Підтримує вікно контексту до 256k та максимальну довжину виведення до 64k токенів."
  },
  "doubao-seededit-3-0-i2i-250628": {
    "description": "Модель генерації зображень Doubao розроблена командою Seed компанії ByteDance, підтримує введення тексту та зображень, забезпечуючи висококонтрольований та якісний досвід генерації зображень. Підтримує редагування зображень за допомогою текстових команд, розмір зображення від 512 до 1536 пікселів."
  },
  "doubao-seedream-3-0-t2i-250415": {
    "description": "Модель генерації зображень Seedream 3.0 розроблена командою Seed компанії ByteDance, підтримує введення тексту та зображень, забезпечуючи висококонтрольований та якісний досвід генерації зображень. Генерація зображень на основі текстових підказок."
  },
  "doubao-seedream-4-0-250828": {
    "description": "Модель генерації зображень Seedream 4.0 розроблена командою Seed компанії ByteDance, підтримує введення тексту та зображень, забезпечуючи висококонтрольований та якісний досвід генерації зображень. Генерація зображень на основі текстових підказок."
  },
  "doubao-vision-lite-32k": {
    "description": "Модель Doubao-vision — мультимодальна велика модель від Doubao, що володіє потужними можливостями розуміння та виведення по зображеннях, а також точним розумінням інструкцій. Модель демонструє високу продуктивність у завданнях вилучення інформації з зображень та текстів, а також у завданнях виведення на основі зображень, що дозволяє застосовувати її в більш складних та широких візуальних питаннях."
  },
  "doubao-vision-pro-32k": {
    "description": "Модель Doubao-vision — мультимодальна велика модель від Doubao, що володіє потужними можливостями розуміння та виведення по зображеннях, а також точним розумінням інструкцій. Модель демонструє високу продуктивність у завданнях вилучення інформації з зображень та текстів, а також у завданнях виведення на основі зображень, що дозволяє застосовувати її в більш складних та широких візуальних питаннях."
  },
  "emohaa": {
    "description": "Emohaa — це психологічна модель, що володіє професійними консультаційними здібностями, допомагаючи користувачам розуміти емоційні проблеми."
  },
  "ernie-3.5-128k": {
    "description": "Флагманська велика мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними здібностями, здатна задовольнити вимоги більшості сценаріїв діалогів, генерації контенту та застосування плагінів; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації."
  },
  "ernie-3.5-8k": {
    "description": "Флагманська велика мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними здібностями, здатна задовольнити вимоги більшості сценаріїв діалогів, генерації контенту та застосування плагінів; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації."
  },
  "ernie-3.5-8k-preview": {
    "description": "Флагманська велика мовна модель, розроблена Baidu, що охоплює величезні обсяги китайських та англійських текстів, володіє потужними універсальними здібностями, здатна задовольнити вимоги більшості сценаріїв діалогів, генерації контенту та застосування плагінів; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації."
  },
  "ernie-4.0-8k-latest": {
    "description": "Флагманська надвелика мовна модель, розроблена Baidu, порівняно з ERNIE 3.5 демонструє повне оновлення можливостей моделі, широко застосовна в складних задачах різних областей; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації."
  },
  "ernie-4.0-8k-preview": {
    "description": "Флагманська надвелика мовна модель, розроблена Baidu, порівняно з ERNIE 3.5 демонструє повне оновлення можливостей моделі, широко застосовна в складних задачах різних областей; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації."
  },
  "ernie-4.0-turbo-128k": {
    "description": "Флагманська надвелика мовна модель, розроблена Baidu, демонструє відмінні результати в комплексних задачах, широко застосовна в різних областях; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації. Порівняно з ERNIE 4.0, вона показує кращі результати."
  },
  "ernie-4.0-turbo-8k-latest": {
    "description": "Флагманська надвелика мовна модель, розроблена Baidu, демонструє відмінні результати в комплексних задачах, широко застосовна в різних областях; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації. Порівняно з ERNIE 4.0, вона показує кращі результати."
  },
  "ernie-4.0-turbo-8k-preview": {
    "description": "Флагманська надвелика мовна модель, розроблена Baidu, демонструє відмінні результати в комплексних задачах, широко застосовна в різних областях; підтримує автоматичне підключення до плагіна пошуку Baidu, забезпечуючи актуальність інформації. Порівняно з ERNIE 4.0, вона показує кращі результати."
  },
  "ernie-4.5-21b-a3b": {
    "description": "ERNIE 4.5 21B A3B — це гібридна модель експертів від Baidu Wenxin, що володіє потужними можливостями логічного висновку та підтримки кількох мов."
  },
  "ernie-4.5-300b-a47b": {
    "description": "ERNIE 4.5 300B A47B — це надмасштабна гібридна модель експертів від Baidu Wenxin з видатними можливостями логічного висновку."
  },
  "ernie-4.5-8k-preview": {
    "description": "Модель Ernie 4.5 — це нове покоління оригінальної мультимодальної базової моделі, розробленої Baidu, яка досягає спільної оптимізації через спільне моделювання кількох модальностей, володіючи відмінними здібностями до мультимодального розуміння; володіє більш досконалими мовними здібностями, покращеними здібностями до розуміння, генерації, логіки та пам'яті, а також значно покращеними здібностями до усунення галюцинацій, логічного висновку та кодування."
  },
  "ernie-4.5-turbo-128k": {
    "description": "Модель ERNIE 4.5 Turbo значно покращила свої здібності в області усунення галюцинацій, логічного висновку та програмування. Порівняно з ERNIE 4.5, вона швидша та дешевша. Здібності моделі значно покращені, що краще задовольняє потреби в обробці багаторазових довгих історій діалогів та завданнях розуміння довгих документів."
  },
  "ernie-4.5-turbo-32k": {
    "description": "Модель ERNIE 4.5 Turbo також значно покращила свої здібності в області усунення галюцинацій, логічного висновку та програмування. Порівняно з ERNIE 4.5, вона швидша та дешевша. Здібності в текстовій творчості та питаннях і відповідях значно зросли. Довжина виведення та затримка цілих речень збільшилися порівняно з ERNIE 4.5."
  },
  "ernie-4.5-turbo-vl-32k": {
    "description": "Нова версія великої моделі ERNIE з помітним покращенням у розумінні зображень, творчості, перекладі та програмуванні, вперше підтримує довжину контексту 32K, затримка першого токена значно знижена."
  },
  "ernie-char-8k": {
    "description": "Спеціалізована велика мовна модель, розроблена Baidu, що підходить для застосування в ігрових NPC, діалогах служби підтримки, ролевих іграх та інших сценаріях, з більш яскравим та послідовним стилем персонажів, більш високою здатністю слідувати інструкціям та кращою продуктивністю виведення."
  },
  "ernie-char-fiction-8k": {
    "description": "Спеціалізована велика мовна модель, розроблена Baidu, що підходить для застосування в ігрових NPC, діалогах служби підтримки, ролевих іграх та інших сценаріях, з більш яскравим та послідовним стилем персонажів, більш високою здатністю слідувати інструкціям та кращою продуктивністю виведення."
  },
  "ernie-irag-edit": {
    "description": "Власна модель редагування зображень ERNIE iRAG від Baidu підтримує операції видалення об'єктів (erase), перемальовування (repaint) та варіацій (variation) на основі зображень."
  },
  "ernie-lite-8k": {
    "description": "ERNIE Lite — це легковесна велика мовна модель, розроблена Baidu, яка поєднує в собі відмінні результати моделі та продуктивність виведення, підходить для використання на AI-прискорювачах з низькою обчислювальною потужністю."
  },
  "ernie-lite-pro-128k": {
    "description": "Легковесна велика мовна модель, розроблена Baidu, яка поєднує в собі відмінні результати моделі та продуктивність виведення, перевершуючи ERNIE Lite, підходить для використання на AI-прискорювачах з низькою обчислювальною потужністю."
  },
  "ernie-novel-8k": {
    "description": "Універсальна велика мовна модель, розроблена Baidu, що володіє явними перевагами в здатності продовжувати написання романів, також може використовуватися в сценаріях коротких п'єс та фільмів."
  },
  "ernie-speed-128k": {
    "description": "Нова високопродуктивна велика мовна модель, розроблена Baidu у 2024 році, що володіє видатними універсальними здібностями, підходить для використання як базова модель для тонкого налаштування, краще справляючись з проблемами конкретних сценаріїв, при цьому володіючи відмінною продуктивністю виведення."
  },
  "ernie-speed-pro-128k": {
    "description": "Нова високопродуктивна велика мовна модель, розроблена Baidu у 2024 році, що володіє видатними універсальними здібностями, перевершуючи ERNIE Speed, підходить для використання як базова модель для тонкого налаштування, краще справляючись з проблемами конкретних сценаріїв, при цьому володіючи відмінною продуктивністю виведення."
  },
  "ernie-tiny-8k": {
    "description": "ERNIE Tiny — це надвисокопродуктивна велика мовна модель, вартість розгортання та тонкого налаштування якої є найнижчою серед моделей серії Wenxin."
  },
  "ernie-x1-32k": {
    "description": "Має сильніші здібності до розуміння, планування, рефлексії та еволюції. Як більш універсальна модель глибокого мислення, ERNIE-X1 поєднує в собі точність, креативність та літературний стиль, особливо добре проявляючи себе в китайських питаннях та відповідях, літературній творчості, написанні текстів, повсякденних діалогах, логічному висновку, складних обчисленнях та викликах інструментів."
  },
  "ernie-x1-32k-preview": {
    "description": "Модель Ernie X1 володіє сильнішими здібностями до розуміння, планування, рефлексії та еволюції. Як більш універсальна модель глибокого мислення, Ernie X1 поєднує в собі точність, креативність та літературний стиль, особливо виділяючись в області питань та відповідей китайською мовою, літературної творчості, написання текстів, повсякденних діалогів, логічного висновку, складних обчислень та виклику інструментів."
  },
  "ernie-x1-turbo-32k": {
    "description": "Модель має кращі результати та продуктивність порівняно з ERNIE-X1-32K."
  },
  "fal-ai/bytedance/seedream/v4": {
    "description": "Модель генерації зображень Seedream 4.0 розроблена командою Seed компанії ByteDance, підтримує введення тексту та зображень, забезпечуючи висококонтрольований та якісний досвід генерації зображень. Генерація зображень на основі текстових підказок."
  },
  "fal-ai/flux-kontext/dev": {
    "description": "Модель FLUX.1, орієнтована на завдання редагування зображень, підтримує введення тексту та зображень."
  },
  "fal-ai/flux-pro/kontext": {
    "description": "FLUX.1 Kontext [pro] здатний обробляти текст та еталонні зображення як вхідні дані, забезпечуючи безшовне цілеспрямоване локальне редагування та складні трансформації всієї сцени."
  },
  "fal-ai/flux/krea": {
    "description": "Flux Krea [dev] — модель генерації зображень з естетичними уподобаннями, спрямована на створення більш реалістичних та природних зображень."
  },
  "fal-ai/flux/schnell": {
    "description": "FLUX.1 [schnell] — модель генерації зображень з 12 мільярдами параметрів, орієнтована на швидку генерацію високоякісних зображень."
  },
  "fal-ai/hunyuan-image/v3": {
    "description": "Потужна нативна мультимодальна модель генерації зображень"
  },
  "fal-ai/imagen4/preview": {
    "description": "Високоякісна модель генерації зображень від Google."
  },
  "fal-ai/nano-banana": {
    "description": "Nano Banana — найновіша, найшвидша та найефективніша нативна мультимодальна модель Google, що дозволяє створювати та редагувати зображення через діалог."
  },
  "fal-ai/qwen-image": {
    "description": "Потужна модель генерації зображень від команди Qwen з вражаючими можливостями генерації китайського тексту та різноманітними візуальними стилями."
  },
  "fal-ai/qwen-image-edit": {
    "description": "Професійна модель редагування зображень від команди Qwen, що підтримує семантичне та візуальне редагування, точне редагування китайських та англійських текстів, а також перетворення стилів, обертання об'єктів та інші високоякісні операції."
  },
  "flux-1-schnell": {
    "description": "Виправлений потоковий трансформер з 12 мільярдами параметрів, здатний генерувати зображення на основі текстових описів."
  },
  "flux-dev": {
    "description": "FLUX.1 [dev] — відкрита модель з вагами та оптимізаціями для некомерційного використання. Забезпечує якість зображень та слідування інструкціям, близькі до професійної версії FLUX, при вищій ефективності роботи та кращому використанні ресурсів порівняно з моделями того ж розміру."
  },
  "flux-kontext-max": {
    "description": "Передова генерація та редагування зображень з урахуванням контексту — поєднання тексту та зображень для отримання точних та узгоджених результатів."
  },
  "flux-kontext-pro": {
    "description": "Передова контекстна генерація та редагування зображень — об'єднання тексту та зображень для отримання точних та послідовних результатів."
  },
  "flux-merged": {
    "description": "Модель FLUX.1-merged об'єднує глибокі особливості, досліджені у фазі розробки «DEV», та переваги високої швидкості виконання, представлені в «Schnell». Це дозволяє розширити межі продуктивності моделі та збільшити її застосовність."
  },
  "flux-pro": {
    "description": "Преміальна комерційна модель ШІ для генерації зображень — неперевершена якість зображень та різноманітність вихідних результатів."
  },
  "flux-pro-1.1": {
    "description": "Удосконалена професійна модель ШІ для генерації зображень — забезпечує чудову якість зображень та точне слідування підказкам."
  },
  "flux-pro-1.1-ultra": {
    "description": "Генерація зображень ШІ ультрависокої роздільної здатності — підтримує вивід 4 мегапікселів, генерує надчіткі зображення менш ніж за 10 секунд."
  },
  "flux-schnell": {
    "description": "FLUX.1 [schnell] — найпередовіша відкрита модель з малою кількістю кроків генерації, що перевершує конкурентів і навіть такі потужні не дистильовані моделі, як Midjourney v6.0 та DALL·E 3 (HD). Модель спеціально донастроєна для збереження всього різноманіття вихідних даних, досягнутого на етапі попереднього навчання. Порівняно із сучасними топовими моделями на ринку, FLUX.1 [schnell] значно покращує візуальну якість, слідування інструкціям, зміну розмірів та пропорцій, обробку шрифтів та різноманіття вихідних даних, забезпечуючи користувачам багатший та різноманітніший творчий досвід генерації зображень."
  },
  "flux.1-schnell": {
    "description": "Виправлений потоковий трансформер з 12 мільярдами параметрів, здатний генерувати зображення на основі текстових описів."
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001 (Тюнінг) пропонує стабільну та налаштовувану продуктивність, що робить її ідеальним вибором для вирішення складних завдань."
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002 (Тюнінг) пропонує видатну підтримку багатомодальності, зосереджуючись на ефективному вирішенні складних завдань."
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Pro — це високопродуктивна модель ШІ від Google, розроблена для масштабування широкого спектру завдань."
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001 — це ефективна багатомодальна модель, що підтримує масштабування для широкого спектру застосувань."
  },
  "gemini-1.5-flash-002": {
    "description": "Gemini 1.5 Flash 002 — це ефективна мультимодальна модель, що підтримує розширені застосування."
  },
  "gemini-1.5-flash-8b": {
    "description": "Gemini 1.5 Flash 8B — це високоефективна багатомодальна модель, що підтримує широкий спектр застосувань."
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "Gemini 1.5 Flash 8B 0924 — це остання експериментальна модель, яка демонструє значне покращення продуктивності як у текстових, так і в мультимодальних завданнях."
  },
  "gemini-1.5-flash-8b-latest": {
    "description": "Gemini 1.5 Flash 8B — це ефективна мультимодальна модель, що підтримує широкий спектр застосувань."
  },
  "gemini-1.5-flash-exp-0827": {
    "description": "Gemini 1.5 Flash 0827 пропонує оптимізовані багатомодальні можливості обробки, придатні для різних складних завдань."
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flash — це остання багатомодальна модель ШІ від Google, що володіє високою швидкістю обробки та підтримує текстові, графічні та відео входи, що робить її ефективною для масштабування різних завдань."
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001 — це масштабоване рішення для багатомодального ШІ, що підтримує широкий спектр складних завдань."
  },
  "gemini-1.5-pro-002": {
    "description": "Gemini 1.5 Pro 002 — це остання модель, готова до виробництва, яка забезпечує вищу якість виведення, особливо в математичних завданнях, довгих контекстах та візуальних завданнях."
  },
  "gemini-1.5-pro-exp-0801": {
    "description": "Gemini 1.5 Pro 0801 пропонує видатні багатомодальні можливості обробки, забезпечуючи більшу гнучкість у розробці застосунків."
  },
  "gemini-1.5-pro-exp-0827": {
    "description": "Gemini 1.5 Pro 0827 поєднує останні технології оптимізації, забезпечуючи більш ефективну обробку багатомодальних даних."
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Pro підтримує до 2 мільйонів токенів та є ідеальним вибором для середніх багатомодальних моделей, забезпечуючи багатосторонню підтримку для складних завдань."
  },
  "gemini-2.0-flash": {
    "description": "Gemini 2.0 Flash пропонує функції наступного покоління та покращення, включаючи видатну швидкість, використання вбудованих інструментів, багатомодальну генерацію та контекстне вікно на 1M токенів."
  },
  "gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flash пропонує функції наступного покоління та покращення, включаючи видатну швидкість, використання вбудованих інструментів, багатомодальну генерацію та контекстне вікно на 1M токенів."
  },
  "gemini-2.0-flash-exp": {
    "description": "Модельний варіант Gemini 2.0 Flash, оптимізований для досягнення таких цілей, як економічна ефективність та низька затримка."
  },
  "gemini-2.0-flash-exp-image-generation": {
    "description": "Експериментальна модель Gemini 2.0 Flash, що підтримує генерацію зображень"
  },
  "gemini-2.0-flash-lite": {
    "description": "Модельний варіант Gemini 2.0 Flash, оптимізований для досягнення таких цілей, як економічна ефективність та низька затримка."
  },
  "gemini-2.0-flash-lite-001": {
    "description": "Модельний варіант Gemini 2.0 Flash, оптимізований для досягнення таких цілей, як економічна ефективність та низька затримка."
  },
  "gemini-2.0-flash-preview-image-generation": {
    "description": "Модель попереднього перегляду Gemini 2.0 Flash, що підтримує генерацію зображень"
  },
  "gemini-2.5-flash": {
    "description": "Gemini 2.5 Flash — найекономічніша модель Google, що надає повний набір функцій."
  },
  "gemini-2.5-flash-image": {
    "description": "Nano Banana — найновіша, найшвидша та найефективніша нативна мультимодальна модель від Google, що дозволяє створювати та редагувати зображення через діалог."
  },
  "gemini-2.5-flash-image-preview": {
    "description": "Nano Banana — найновіша, найшвидша та найефективніша нативна мультимодальна модель від Google, що дозволяє створювати та редагувати зображення через діалог."
  },
  "gemini-2.5-flash-image-preview:image": {
    "description": "Nano Banana — найновіша, найшвидша та найефективніша нативна мультимодальна модель від Google, що дозволяє створювати та редагувати зображення через діалог."
  },
  "gemini-2.5-flash-image:image": {
    "description": "Nano Banana — найновіша, найшвидша та найефективніша нативна мультимодальна модель від Google, що дозволяє створювати та редагувати зображення через діалог."
  },
  "gemini-2.5-flash-lite": {
    "description": "Gemini 2.5 Flash-Lite — це найкомпактніша та економічна модель від Google, розроблена для масштабного використання."
  },
  "gemini-2.5-flash-lite-preview-06-17": {
    "description": "Gemini 2.5 Flash-Lite Preview — найкомпактніша та економічна модель Google, розроблена для масштабного використання."
  },
  "gemini-2.5-flash-lite-preview-09-2025": {
    "description": "Попередній реліз Gemini 2.5 Flash-Lite (25 вересня 2025 року)"
  },
  "gemini-2.5-flash-preview-04-17": {
    "description": "Gemini 2.5 Flash Preview — це найбільш вигідна модель від Google, що пропонує широкий спектр можливостей."
  },
  "gemini-2.5-flash-preview-05-20": {
    "description": "Gemini 2.5 Flash Preview — найекономічніша модель Google з повним набором функцій."
  },
  "gemini-2.5-flash-preview-09-2025": {
    "description": "Попередній реліз Gemini 2.5 Flash (25 вересня 2025 року)"
  },
  "gemini-2.5-pro": {
    "description": "Gemini 2.5 Pro — найпередовіша модель мислення Google, здатна розмірковувати над складними завданнями в області коду, математики та STEM, а також аналізувати великі набори даних, кодові бази та документи з використанням довгого контексту."
  },
  "gemini-2.5-pro-preview-03-25": {
    "description": "Gemini 2.5 Pro Preview — це найсучасніша модель мислення від Google, здатна розмірковувати про складні завдання в області коду, математики та STEM, а також аналізувати великі набори даних, кодові бази та документи з використанням довгого контексту."
  },
  "gemini-2.5-pro-preview-05-06": {
    "description": "Gemini 2.5 Pro Preview — це найсучасніша модель мислення від Google, здатна розмірковувати про складні завдання в області коду, математики та STEM, а також аналізувати великі набори даних, кодові бази та документи за допомогою довгого контексту."
  },
  "gemini-2.5-pro-preview-06-05": {
    "description": "Gemini 2.5 Pro Preview — передова модель мислення від Google, здатна розмірковувати над складними завданнями в області коду, математики та STEM, а також аналізувати великі набори даних, кодові бази та документи з використанням довгого контексту."
  },
  "gemini-flash-latest": {
    "description": "Останній реліз Gemini Flash"
  },
  "gemini-flash-lite-latest": {
    "description": "Останній реліз Gemini Flash-Lite"
  },
  "gemini-pro-latest": {
    "description": "Останній реліз Gemini Pro"
  },
  "gemma-7b-it": {
    "description": "Gemma 7B підходить для обробки завдань середнього та малого масштабу, забезпечуючи економічну ефективність."
  },
  "gemma2": {
    "description": "Gemma 2 — це високоефективна модель, випущена Google, що охоплює широкий спектр застосунків від малих до складних завдань обробки даних."
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9B — це модель, оптимізована для конкретних завдань та інтеграції інструментів."
  },
  "gemma2:27b": {
    "description": "Gemma 2 — це високоефективна модель, випущена Google, що охоплює широкий спектр застосунків від малих до складних завдань обробки даних."
  },
  "gemma2:2b": {
    "description": "Gemma 2 — це високоефективна модель, випущена Google, що охоплює широкий спектр застосунків від малих до складних завдань обробки даних."
  },
  "generalv3": {
    "description": "Spark Pro — це високопродуктивна велика мовна модель, оптимізована для професійних областей, таких як математика, програмування, медицина та освіта, підтримує мережевий пошук та вбудовані плагіни для погоди, дати тощо. Оптимізована модель демонструє видатні результати та високу ефективність у складних завданнях на знання, розумінні мови та високорівневому створенні текстів, що робить її ідеальним вибором для професійних застосувань."
  },
  "generalv3.5": {
    "description": "Spark3.5 Max — це найповніша версія, що підтримує мережевий пошук та безліч вбудованих плагінів. Його повністю оптимізовані основні можливості, а також функції налаштування системних ролей та викликів функцій роблять його видатним та ефективним у різних складних застосуваннях."
  },
  "glm-4": {
    "description": "GLM-4 — це стара флагманська версія, випущена в січні 2024 року, яка була замінена більш потужною GLM-4-0520."
  },
  "glm-4-0520": {
    "description": "GLM-4-0520 — це остання версія моделі, спеціально розроблена для високо складних та різноманітних завдань, демонструючи видатні результати."
  },
  "glm-4-9b-chat": {
    "description": "GLM-4-9B-Chat демонструє високу продуктивність в області семантики, математики, логіки, програмування та знань. Підтримує веб-браузинг, виконання коду, виклик користувацьких інструментів та обробку довгих текстів. Підтримує 26 мов, включаючи японську, корейську та німецьку."
  },
  "glm-4-air": {
    "description": "GLM-4-Air — це економічно ефективна версія, продуктивність якої близька до GLM-4, забезпечуючи високу швидкість та доступну ціну."
  },
  "glm-4-air-250414": {
    "description": "GLM-4-Air — це версія з хорошим співвідношенням ціни та якості, продуктивність близька до GLM-4, забезпечуючи швидку швидкість та доступну ціну."
  },
  "glm-4-airx": {
    "description": "GLM-4-AirX пропонує ефективну версію GLM-4-Air, швидкість виведення може досягати 2.6 разів швидше."
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllTools — це багатофункціональна модель агента, оптимізована для підтримки складного планування інструкцій та викликів інструментів, таких як веб-серфінг, інтерпретація коду та генерація тексту, що підходить для виконання безлічі завдань."
  },
  "glm-4-flash": {
    "description": "GLM-4-Flash — це ідеальний вибір для обробки простих завдань, з найвищою швидкістю та найнижчою ціною."
  },
  "glm-4-flash-250414": {
    "description": "GLM-4-Flash — ідеальний вибір для обробки простих завдань, володіє найвищою швидкістю та безкоштовний."
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashX — це покращена версія Flash з ультрашвидкою швидкістю виведення."
  },
  "glm-4-long": {
    "description": "GLM-4-Long підтримує наддовгі текстові вводи, підходить для завдань, що вимагають пам'яті, та обробки великих документів."
  },
  "glm-4-plus": {
    "description": "GLM-4-Plus, як флагман з високим інтелектом, володіє потужними здібностями обробки довгих текстів та складних завдань, з повним покращенням продуктивності."
  },
  "glm-4.1v-thinking-flash": {
    "description": "Серія моделей GLM-4.1V-Thinking є найпродуктивнішою візуальною моделлю рівня 10B VLM на сьогоднішній день, об'єднуючи передові SOTA можливості в завданнях візуально-мовного розуміння, включаючи розуміння відео, питання по зображеннях, рішення предметних завдань, розпізнавання тексту OCR, інтерпретацію документів та графіків, GUI-агентів, фронтенд веб-кодінг, Grounding та інші. У багатьох завданнях її можливості перевершують Qwen2.5-VL-72B з параметрами в 8 разів більше. Завдяки передовим методам навчання з підкріпленням модель оволоділа міркуваннями через ланцюжок мислення, що значно підвищує точність та повноту відповідей, перевершуючи традиційні моделі без thinking з точки зору кінцевих результатів та інтерпретованості."
  },
  "glm-4.1v-thinking-flashx": {
    "description": "Серія моделей GLM-4.1V-Thinking є найпродуктивнішою візуальною моделлю рівня 10B VLM на сьогоднішній день, об'єднуючи передові SOTA можливості в завданнях візуально-мовного розуміння, включаючи розуміння відео, питання по зображеннях, рішення предметних завдань, розпізнавання тексту OCR, інтерпретацію документів та графіків, GUI-агентів, фронтенд веб-кодінг, Grounding та інші. У багатьох завданнях її можливості перевершують Qwen2.5-VL-72B з параметрами в 8 разів більше. Завдяки передовим методам навчання з підкріпленням модель оволоділа міркуваннями через ланцюжок мислення, що значно підвищує точність та повноту відповідей, перевершуючи традиційні моделі без thinking з точки зору кінцевих результатів та інтерпретованості."
  },
  "glm-4.5": {
    "description": "Флагманська модель Zhipu, що підтримує перемикання режимів мислення, з комплексними можливостями, що досягають рівня SOTA серед відкритих моделей, довжина контексту до 128K."
  },
  "glm-4.5-air": {
    "description": "Легка версія GLM-4.5, що поєднує продуктивність та економічність, з можливістю гнучкого перемикання між змішаними режимами міркування."
  },
  "glm-4.5-airx": {
    "description": "Прискорена версія GLM-4.5-Air з швидшою реакцією, створена для масштабних завдань з високими вимогами до швидкості."
  },
  "glm-4.5-flash": {
    "description": "Безкоштовна версія GLM-4.5, що демонструє відмінні результати в завданнях виведення, програмування та роботи з агентами."
  },
  "glm-4.5-x": {
    "description": "Прискорена версія GLM-4.5 з високою продуктивністю та швидкістю генерації до 100 токенів на секунду."
  },
  "glm-4.5v": {
    "description": "Zhipu нового покоління — модель візуального виведення на основі архітектури MOE. При загальному об'ємі параметрів 106B та 12B активованих параметрів вона досягає SOTA серед відкритих мультимодальних моделей зіставного рівня в різних бенчмарках, охоплюючи такі поширені завдання, як розуміння зображень, відео, документів та завдання графічного інтерфейсу (GUI)."
  },
  "glm-4.6": {
    "description": "Новітня флагманська модель Zhipu GLM-4.6 (355B) перевершує попередників у всіх аспектах: просунутому кодуванні, обробці довгих текстів, виведенні та можливостях інтелектуальних агентів, особливо в програмуванні, порівнянна з Claude Sonnet 4, що стала провідною моделлю кодування в країні."
  },
  "glm-4v": {
    "description": "GLM-4V пропонує потужні здібності розуміння та виведення зображень, підтримує безліч візуальних завдань."
  },
  "glm-4v-flash": {
    "description": "GLM-4V-Flash зосереджений на ефективному розумінні одного зображення, підходить для сценаріїв швидкого аналізу зображень, таких як аналіз зображень у реальному часі або пакетна обробка зображень."
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plus володіє здатністю розуміти відео-контент та безліч зображень, підходить для мультимодальних завдань."
  },
  "glm-4v-plus-0111": {
    "description": "GLM-4V-Plus володіє здібностями до розуміння відео та безлічі зображень, підходить для мультимодальних завдань."
  },
  "glm-z1-air": {
    "description": "Модель виведення: володіє потужними здібностями виведення, підходить для завдань, що вимагають глибокого виведення."
  },
  "glm-z1-airx": {
    "description": "Супершвидкий вивід: володіє надшвидкою швидкістю виведення та потужними результатами виведення."
  },
  "glm-z1-flash": {
    "description": "Серія GLM-Z1 володіє потужними можливостями складного міркування, демонструючи видатні результати в логіці, математиці та програмуванні."
  },
  "glm-z1-flashx": {
    "description": "Висока швидкість та низька ціна: покращена версія Flash з надшвидкою швидкістю виведення та підвищеною підтримкою паралельних запитів."
  },
  "glm-zero-preview": {
    "description": "GLM-Zero-Preview володіє потужними здібностями до складного висновку, демонструючи відмінні результати в області логічного висновку, математики та програмування."
  },
  "google/gemini-2.0-flash": {
    "description": "Gemini 2.0 Flash пропонує функції наступного покоління та покращені можливості, включаючи видатну швидкість, вбудоване використання інструментів, мультимодальну генерацію та контекстне вікно на 1 мільйон токенів."
  },
  "google/gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flash пропонує функції наступного покоління та покращення, включаючи видатну швидкість, використання вбудованих інструментів, багатомодальну генерацію та контекстне вікно на 1M токенів."
  },
  "google/gemini-2.0-flash-exp:free": {
    "description": "Gemini 2.0 Flash Experimental — це остання експериментальна мультимодальна AI модель від Google, яка демонструє певне покращення якості порівняно з історичними версіями, особливо в області світових знань, коду та довгого контексту."
  },
  "google/gemini-2.0-flash-lite": {
    "description": "Gemini 2.0 Flash Lite пропонує функції наступного покоління та покращені можливості, включаючи видатну швидкість, вбудоване використання інструментів, мультимодальну генерацію та контекстне вікно на 1 мільйон токенів."
  },
  "google/gemini-2.5-flash": {
    "description": "Gemini 2.5 Flash — модель для міркувань з видатними всебічними можливостями. Вона збалансована за ціною та продуктивністю, підтримує мультимодальність та контекстне вікно на 1 мільйон токенів."
  },
  "google/gemini-2.5-flash-image-preview": {
    "description": "Експериментальна модель Gemini 2.5 Flash, що підтримує генерацію зображень."
  },
  "google/gemini-2.5-flash-lite": {
    "description": "Gemini 2.5 Flash-Lite — збалансована модель з низькою затримкою, з налаштовуваним бюджетом міркувань та підключенням інструментів (наприклад, Google Search та виконання коду). Підтримує мультимодальний ввід та контекстне вікно на 1 мільйон токенів."
  },
  "google/gemini-2.5-flash-preview": {
    "description": "Gemini 2.5 Flash — це найсучасніша основна модель від Google, розроблена для складного міркування, кодування, математичних та наукових завдань. Вона включає вбудовану здатність «думати», що дозволяє їй давати відповіді з вищою точністю та деталізованою обробкою контексту.\n\nЗверніть увагу: ця модель має два варіанти: з «думанням» та без. Ціни на вивід значно відрізняються залежно від того, чи активована здатність думати. Якщо ви виберете стандартний варіант (без суфікса «:thinking»), модель явно уникає генерації токенів для роздумів.\n\nЩоб скористатися здатністю думати та отримувати токени для роздумів, ви повинні вибрати варіант «:thinking», що призведе до вищої ціни на вивід роздумів.\n\nКрім того, Gemini 2.5 Flash можна налаштувати за допомогою параметра «максимальна кількість токенів для міркування», як зазначено в документації (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  },
  "google/gemini-2.5-flash-preview:thinking": {
    "description": "Gemini 2.5 Flash — це найсучасніша основна модель від Google, розроблена для складного міркування, кодування, математичних та наукових завдань. Вона включає вбудовану здатність «думати», що дозволяє їй давати відповіді з вищою точністю та деталізованою обробкою контексту.\n\nЗверніть увагу: ця модель має два варіанти: з «думанням» та без. Ціни на вивід значно відрізняються залежно від того, чи активована здатність думати. Якщо ви виберете стандартний варіант (без суфікса «:thinking»), модель явно уникає генерації токенів для роздумів.\n\nЩоб скористатися здатністю думати та отримувати токени для роздумів, ви повинні вибрати варіант «:thinking», що призведе до вищої ціни на вивід роздумів.\n\nКрім того, Gemini 2.5 Flash можна налаштувати за допомогою параметра «максимальна кількість токенів для міркування», як зазначено в документації (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  },
  "google/gemini-2.5-pro": {
    "description": "Gemini 2.5 Pro — наш найпросунутіший модель Gemini для виведення, здатна вирішувати складні завдання. Має контекстне вікно на 2 мільйони токенів та підтримує мультимодальний ввід, включаючи текст, зображення, аудіо, відео та PDF-документи."
  },
  "google/gemini-2.5-pro-preview": {
    "description": "Gemini 2.5 Pro Preview — це найпередовіша модель мислення від Google, здатна розмірковувати над складними завданнями в області коду, математики та STEM, а також аналізувати великі набори даних, кодові бази та документи з використанням довгого контексту."
  },
  "google/gemini-embedding-001": {
    "description": "Передова модель вбудовування з відмінною продуктивністю в завданнях англійською, багатомовних та кодових завданнях."
  },
  "google/gemini-flash-1.5": {
    "description": "Gemini 1.5 Flash пропонує оптимізовані можливості багатомодальної обробки, придатні для різних складних завдань."
  },
  "google/gemini-pro-1.5": {
    "description": "Gemini 1.5 Pro поєднує в собі новітні технології оптимізації, забезпечуючи більш ефективну обробку багатомодальних даних."
  },
  "google/gemma-2-27b": {
    "description": "Gemma 2 — це ефективна модель, представлена Google, що охоплює широкий спектр застосунків від невеликих до складних завдань обробки даних."
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2 продовжує концепцію легковесного та ефективного дизайну."
  },
  "google/gemma-2-2b-it": {
    "description": "Легковесна модель налаштування інструкцій від Google."
  },
  "google/gemma-2-9b": {
    "description": "Gemma 2 — це ефективна модель, представлена Google, що охоплює широкий спектр застосунків від невеликих до складних завдань обробки даних."
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2 — це легковесна серія текстових моделей з відкритим вихідним кодом від Google."
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2 — це полегшена відкрита текстова модель від Google."
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B) пропонує базові можливості обробки команд, придатні для легковесних застосунків."
  },
  "google/gemma-3-12b-it": {
    "description": "Gemma 3 12B — відкрита мовна модель від Google, що встановила нові стандарти ефективності та продуктивності."
  },
  "google/gemma-3-1b-it": {
    "description": "Gemma 3 1B — це відкрита мовна модель від Google, що встановила нові стандарти в ефективності та продуктивності."
  },
  "google/gemma-3-27b-it": {
    "description": "Gemma 3 27B — це відкрита мовна модель від Google, яка встановила нові стандарти в області ефективності та продуктивності."
  },
  "google/text-embedding-005": {
    "description": "Оптимізована для коду та англійської мови модель текстового вбудовування з фокусом на англійську."
  },
  "google/text-multilingual-embedding-002": {
    "description": "Багатомовна модель текстового вбудовування, оптимізована для міжмовних завдань, що підтримує безліч мов."
  },
  "gpt-3.5-turbo": {
    "description": "GPT 3.5 Turbo підходить для різних завдань генерації та розуміння тексту, наразі посилається на gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-0125": {
    "description": "GPT 3.5 Turbo підходить для різних завдань генерації та розуміння тексту, наразі посилається на gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-1106": {
    "description": "GPT 3.5 Turbo підходить для різних завдань генерації та розуміння тексту, наразі посилається на gpt-3.5-turbo-0125."
  },
  "gpt-3.5-turbo-instruct": {
    "description": "GPT 3.5 Turbo підходить для різних завдань генерації та розуміння тексту, наразі посилається на gpt-3.5-turbo-0125."
  },
  "gpt-35-turbo": {
    "description": "GPT 3.5 Turbo — це ефективна модель від OpenAI, призначена для завдань чату та генерації тексту, що підтримує паралельні виклики функцій."
  },
  "gpt-35-turbo-16k": {
    "description": "GPT 3.5 Turbo 16k — модель для генерації тексту з високою ємністю, що підходить для складних завдань."
  },
  "gpt-4": {
    "description": "GPT-4 пропонує ширший контекстний діапазон, здатний обробляти довші текстові вводи, підходячи для сценаріїв, що вимагають обширної інтеграції інформації та аналізу даних."
  },
  "gpt-4-0125-preview": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4-0613": {
    "description": "GPT-4 пропонує ширший контекстний діапазон, здатний обробляти довші текстові вводи, підходячи для сценаріїв, що вимагають обширної інтеграції інформації та аналізу даних."
  },
  "gpt-4-1106-preview": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4-32k": {
    "description": "GPT-4 пропонує ширший контекстний діапазон, здатний обробляти довші текстові вводи, підходячи для сценаріїв, що вимагають обширної інтеграції інформації та аналізу даних."
  },
  "gpt-4-32k-0613": {
    "description": "GPT-4 пропонує ширший контекстний діапазон, здатний обробляти довші текстові вводи, підходячи для сценаріїв, що вимагають обширної інтеграції інформації та аналізу даних."
  },
  "gpt-4-turbo": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4-turbo-preview": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4-vision-preview": {
    "description": "Остання модель GPT-4 Turbo володіє візуальними функціями. Тепер візуальні запити можуть використовувати JSON-формат та виклики функцій. GPT-4 Turbo — це покращена версія, що забезпечує економічно ефективну підтримку для мультимодальних завдань. Вона знаходить баланс між точністю та ефективністю, підходячи для застосунків, що вимагають взаємодії в реальному часі."
  },
  "gpt-4.1": {
    "description": "GPT-4.1 — це наша флагманська модель для складних завдань. Вона відмінно підходить для вирішення міждисциплінарних проблем."
  },
  "gpt-4.1-mini": {
    "description": "GPT-4.1 mini пропонує баланс між інтелектом, швидкістю та вартістю, що робить його привабливою моделлю для багатьох випадків використання."
  },
  "gpt-4.1-nano": {
    "description": "GPT-4.1 mini пропонує баланс між інтелектом, швидкістю та вартістю, що робить його привабливою моделлю для багатьох випадків використання."
  },
  "gpt-4.5-preview": {
    "description": "GPT-4.5-preview — новітня універсальна модель, що володіє глибокими знаннями про світ та кращим розумінням намірів користувачів; відмінно підходить для творчих завдань та агентного планування. Знання цієї моделі актуальні на жовтень 2023 року."
  },
  "gpt-4o": {
    "description": "ChatGPT-4o — це динамічна модель, яка оновлюється в реальному часі, щоб залишатися актуальною. Вона поєднує в собі потужне розуміння мови та генерацію, підходячи для масштабних застосунків, включаючи обслуговування клієнтів, освіту та технічну підтримку."
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4o — це динамічна модель, яка оновлюється в реальному часі, щоб залишатися актуальною. Вона поєднує в собі потужне розуміння мови та генерацію, підходячи для масштабних застосунків, включаючи обслуговування клієнтів, освіту та технічну підтримку."
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4o — це динамічна модель, яка оновлюється в реальному часі, щоб залишатися актуальною. Вона поєднує в собі потужне розуміння мови та генерацію, підходячи для масштабних застосунків, включаючи обслуговування клієнтів, освіту та технічну підтримку."
  },
  "gpt-4o-2024-11-20": {
    "description": "ChatGPT-4o — це динамічна модель, яка оновлюється в реальному часі для підтримання актуальної версії. Вона поєднує в собі потужне розуміння мови та генерацію тексту, підходячи для широкого спектру застосунків, включаючи обслуговування клієнтів, освіту та технічну підтримку."
  },
  "gpt-4o-audio-preview": {
    "description": "Модель GPT-4o Audio Preview з підтримкою аудіовходу та аудіовиходу."
  },
  "gpt-4o-mini": {
    "description": "GPT-4o mini — це остання модель, випущена OpenAI після GPT-4 Omni, що підтримує введення зображень та текстів з виведенням тексту. Як їх найпросунутіша компактна модель, вона значно дешевша за інші нещодавні передові моделі та більш ніж на 60% дешевша за GPT-3.5 Turbo. Вона зберігає передовий рівень інтелекту при значному співвідношенні ціна-якість. GPT-4o mini набрала 82% на тесті MMLU і наразі займає вище місце в перевагах чату порівняно з GPT-4."
  },
  "gpt-4o-mini-audio-preview": {
    "description": "Модель GPT-4o mini Audio підтримує введення та виведення аудіо."
  },
  "gpt-4o-mini-realtime-preview": {
    "description": "Реальна версія GPT-4o-mini, що підтримує аудіо та текстовий ввід та вивід у реальному часі."
  },
  "gpt-4o-mini-search-preview": {
    "description": "GPT-4o mini — попередня версія моделі для пошуку, спеціально навчена для розуміння та виконання запитів веб-пошуку, що використовує Chat Completions API. Крім плати за токени, за кожен виклик інструменту веб-пошуку стягується окрема плата."
  },
  "gpt-4o-mini-transcribe": {
    "description": "GPT-4o Mini Transcribe — модель перетворення мови в текст, що використовує GPT-4o для транскрибування аудіо. Порівняно з оригінальною моделлю Whisper, вона знижує кількість помилок у словах та підвищує точність розпізнавання мови. Використовуйте її для більш точної транскрипції."
  },
  "gpt-4o-mini-tts": {
    "description": "GPT-4o mini TTS — це модель перетворення тексту в мову, заснована на GPT-4o mini, що забезпечує високу якість синтезу мови за низької вартості."
  },
  "gpt-4o-realtime-preview": {
    "description": "Реальна версія GPT-4o, що підтримує аудіо та текстовий ввід та вивід у реальному часі."
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "description": "Реальна версія GPT-4o, що підтримує аудіо та текстовий ввід та вивід у реальному часі."
  },
  "gpt-4o-realtime-preview-2025-06-03": {
    "description": "Реальний час GPT-4o, підтримує одночасний ввід та вивід аудіо та тексту."
  },
  "gpt-4o-search-preview": {
    "description": "GPT-4o — попередня версія моделі для пошуку, спеціально навчена для розуміння та виконання запитів веб-пошуку, що використовує Chat Completions API. Крім плати за токени, за кожен виклик інструменту веб-пошуку стягується окрема плата."
  },
  "gpt-4o-transcribe": {
    "description": "GPT-4o Transcribe — модель перетворення мови в текст, що використовує GPT-4o для транскрибування аудіо. Порівняно з оригінальною моделлю Whisper, вона знижує кількість помилок у словах та підвищує точність розпізнавання мови. Використовуйте її для більш точної транскрипції."
  },
  "gpt-5": {
    "description": "Найкраща модель для міждисциплінарного кодування та агентних завдань. GPT-5 здійснив прорив у точності, швидкості, міркуваннях, розпізнаванні контексту, структурному мисленні та вирішенні проблем."
  },
  "gpt-5-chat-latest": {
    "description": "Модель GPT-5, що використовується в ChatGPT. Об'єднує потужні можливості розуміння та генерації мови, ідеально підходить для діалогових застосунків."
  },
  "gpt-5-codex": {
    "description": "GPT-5 Codex — версія GPT-5, оптимізована для завдань агентського кодування в середовищах Codex або аналогічних."
  },
  "gpt-5-mini": {
    "description": "Швидша та економічніша версія GPT-5, призначена для чітко визначених завдань. Забезпечує швидший відгук при збереженні високої якості виведення."
  },
  "gpt-5-nano": {
    "description": "Найшвидша та економічніша версія GPT-5. Відмінно підходить для застосунків, що вимагають швидкого відгуку та чутливих до витрат."
  },
  "gpt-5-pro": {
    "description": "GPT-5 Pro використовує більше обчислювальних ресурсів для глибшого мислення та стабільно надає більш якісні відповіді."
  },
  "gpt-audio": {
    "description": "GPT Audio — універсальна чат-модель з підтримкою аудіовходу та аудіовиходу, доступна через API Chat Completions з аудіо I/O."
  },
  "gpt-image-1": {
    "description": "Нативна мультимодальна модель генерації зображень ChatGPT."
  },
  "gpt-image-1-mini": {
    "description": "Більш доступна версія GPT Image 1 з нативною підтримкою введення тексту та зображень, а також генерацією зображень у відповідь."
  },
  "gpt-oss-120b": {
    "description": "Для використання цієї моделі потрібно подати заявку. GPT-OSS-120B — це відкрита великомасштабна мовна модель від OpenAI з потужними можливостями генерації тексту."
  },
  "gpt-oss-20b": {
    "description": "Для використання цієї моделі потрібно подати заявку. GPT-OSS-20B — це відкрита середньорозмірна мовна модель від OpenAI з високою ефективністю генерації тексту."
  },
  "gpt-oss:120b": {
    "description": "GPT-OSS 120B — велика відкрита мовна модель від OpenAI, що використовує технологію квантування MXFP4, призначена для флагманських рішень. Вимагає багатопроцесорної GPU або високопродуктивної робочої станції для роботи, володіє видатними показниками в складних задачах міркування, генерації коду та багатомовної обробки, підтримує розширені виклики функцій та інтеграцію інструментів."
  },
  "gpt-oss:20b": {
    "description": "GPT-OSS 20B — це відкрита велика мовна модель, випущена OpenAI, що використовує технологію квантування MXFP4, підходяща для запуску на високопродуктивних споживчих GPU або Apple Silicon Mac. Модель демонструє відмінні результати в генерації діалогів, написанні коду та задачах міркування, підтримує виклики функцій та використання інструментів."
  },
  "gpt-realtime": {
    "description": "Універсальна модель реального часу з підтримкою текстового та аудіовходу/виходу, а також підтримки введення зображень."
  },
  "grok-2-image-1212": {
    "description": "Наша новітня модель генерації зображень здатна створювати живі та реалістичні зображення на основі текстових підказок. Вона відмінно підходить для маркетингу, соціальних мереж та розважальних застосунків."
  },
  "grok-2-vision-1212": {
    "description": "Модель покращена в точності, дотриманні інструкцій та багатомовних можливостях."
  },
  "grok-3": {
    "description": "Флагманська модель, що спеціалізується на вилученні даних, програмуванні та резюмуванні тексту для корпоративних застосунків, що володіє глибокими знаннями у фінансах, медицині, юриспруденції та науці."
  },
  "grok-3-mini": {
    "description": "Легковесна модель, яка спочатку обмірковує відповідь перед розмовою. Швидка та розумна, підходить для логічних завдань без глибоких галузевих знань та дозволяє простежити вихідні міркування."
  },
  "grok-4": {
    "description": "Наша новітня та найпотужніша флагманська модель, що демонструє видатні результати в обробці природної мови, математичних обчисленнях та логічному міркуванні — ідеальний універсальний інструмент."
  },
  "grok-4-0709": {
    "description": "Grok 4 від xAI з потужними можливостями міркування."
  },
  "grok-4-fast-non-reasoning": {
    "description": "Ми раді представити Grok 4 Fast — наш останній прогрес у сфері економічно ефективних моделей для виведення."
  },
  "grok-4-fast-reasoning": {
    "description": "Ми раді представити Grok 4 Fast — наш останній прогрес у сфері економічно ефективних моделей для виведення."
  },
  "grok-code-fast-1": {
    "description": "Ми раді представити grok-code-fast-1 — швидкий та економічний модель виведення, яка відмінно справляється з кодуванням агентів."
  },
  "groq/compound": {
    "description": "Compound — це комплексна AI-система, підтримувана кількома відкритими моделями, вже доступними в GroqCloud, яка інтелектуально та вибірково використовує інструменти для відповіді на запити користувачів."
  },
  "groq/compound-mini": {
    "description": "Compound-mini — це комплексна AI-система, підтримувана відкритими моделями, вже доступними в GroqCloud, яка інтелектуально та вибірково використовує інструменти для відповіді на запити користувачів."
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13B — це мовна модель, що об'єднує креативність та інтелект, заснована на кількох провідних моделях."
  },
  "hunyuan-a13b": {
    "description": "Hunyuan — перша гібридна модель міркування, оновлена версія hunyuan-standard-256K із загальним числом параметрів 80B та 13B активних параметрів. За замовчуванням працює в режимі повільного мислення, підтримує перемикання між режимами швидкого та повільного мислення через параметри або команди, перемикання здійснюється додаванням / no_think перед запитом. Загальні можливості значно покращені порівняно з попереднім поколінням, особливо в математиці, науці, розумінні довгих текстів та агентських функціях."
  },
  "hunyuan-code": {
    "description": "Остання модель генерації коду Hunyuan, навчена на базі 200B високоякісних даних коду, що пройшла півроку навчання на високоякісних даних SFT, зі збільшеною довжиною контекстного вікна до 8K, займає провідні позиції за автоматичними оціночними показниками генерації коду п'ятьма мовами; за десятьма критеріями оцінки коду п'ятьма мовами, продуктивність знаходиться в першій групі."
  },
  "hunyuan-functioncall": {
    "description": "Остання модель Hunyuan з архітектурою MOE FunctionCall, навчена на високоякісних даних FunctionCall, з контекстним вікном до 32K, займає лідируючі позиції за безліччю оціночних показників."
  },
  "hunyuan-large": {
    "description": "Модель Hunyuan-large має загальну кількість параметрів близько 389B, активних параметрів близько 52B, що робить її найбільшою та найефективнішою відкритою моделлю MoE з архітектурою Transformer в галузі."
  },
  "hunyuan-large-longcontext": {
    "description": "Спеціалізується на обробці довгих текстових завдань, таких як резюме документів та питання та відповіді по документах, а також володіє здатністю обробляти загальні завдання генерації тексту. Відмінно справляється з аналізом та генерацією довгих текстів, ефективно справляючись з вимогами до обробки складного та детального довгого контенту."
  },
  "hunyuan-large-vision": {
    "description": "Ця модель призначена для завдань розуміння зображень та тексту, заснована на змішаній моделі Hunyuan Large, підтримує введення кількох зображень з довільною роздільною здатністю та текстом, генерує текстовий контент, зосереджена на завданнях розуміння зображень та тексту, з помітним покращенням багатомовних можливостей."
  },
  "hunyuan-lite": {
    "description": "Оновлена версія з MOE-структурою, контекстне вікно становить 256k, вона випереджає безліч відкритих моделей в оцінках по NLP, коду, математиці та інших областях."
  },
  "hunyuan-lite-vision": {
    "description": "Остання багатомодальна модель Hunyuan з 7B параметрами, вікно контексту 32K, підтримує багатомодальний діалог китайською та англійською мовами, розпізнавання об'єктів на зображеннях, розуміння документів та таблиць, багатомодальну математику тощо, за багатьма вимірами перевершує моделі конкурентів з 7B параметрами."
  },
  "hunyuan-pro": {
    "description": "Модель довгого тексту з параметрами рівня трильйона MOE-32K. Вона досягає абсолютного лідерства на різних бенчмарках, володіє складними інструкціями та виведенням, має складні математичні здібності та підтримує виклики функцій, з акцентом на оптимізацію в області багатомовного перекладу, фінансів, права та медицини."
  },
  "hunyuan-role": {
    "description": "Остання версія моделі ролевої взаємодії Hunyuan, випущена з офіційним тонким налаштуванням, заснована на моделі Hunyuan та доповнена даними сценаріїв ролевої взаємодії, демонструє кращі базові результати в ролевих сценаріях."
  },
  "hunyuan-standard": {
    "description": "Використовує більш оптимальну стратегію маршрутизації, одночасно пом'якшуючи проблеми з балансуванням навантаження та збіжністю експертів. В області довгих текстів показник «знайти голку в стозі сіна» досягає 99,9%. MOE-32K пропонує вищу вартість-ефективність, забезпечуючи баланс між якістю та ціною, а також можливість обробки довгих текстових вводів."
  },
  "hunyuan-standard-256K": {
    "description": "Використовує більш оптимальну стратегію маршрутизації, одночасно пом'якшуючи проблеми з балансуванням навантаження та збіжністю експертів. В області довгих текстів показник «знайти голку в стозі сіна» досягає 99,9%. MOE-256K робить подальший прорив у довжині та якості, значно розширюючи допустиму довжину введення."
  },
  "hunyuan-standard-vision": {
    "description": "Остання багатомодальна модель Hunyuan, що підтримує багатомовні відповіді, зі збалансованими здібностями китайською та англійською мовами."
  },
  "hunyuan-t1-20250321": {
    "description": "Повноцінна модель, що володіє як гуманітарними, так і природничо-науковими здібностями, з високою здатністю до захоплення довгої текстової інформації. Підтримує міркування та відповіді на наукові питання різної складності, включаючи математику, логічні задачі, науки та код."
  },
  "hunyuan-t1-20250403": {
    "description": "Підвищення можливостей генерації коду на рівні проекту; покращення якості текстової творчості; покращення багатоходового розуміння тем, дотримання інструкцій toB та розуміння слів; оптимізація проблем з виведенням змішаних спрощених та традиційних ієрогліфів, а також змішаних китайсько-англійських текстів."
  },
  "hunyuan-t1-20250529": {
    "description": "Оптимізація створення текстів та написання творів, покращення навичок програмування, математики та логічного мислення, підвищення здатності слідувати інструкціям."
  },
  "hunyuan-t1-20250711": {
    "description": "Значне покращення здібностей у складній математиці, логіці та програмуванні, оптимізація стабільності виведення моделі та підвищення можливостей роботи з довгими текстами."
  },
  "hunyuan-t1-latest": {
    "description": "Значно покращує здібності основної моделі повільного роздуму в складній математиці, складних міркуваннях, складному кодуванні, слідуванні інструкціям та якості текстової творчості."
  },
  "hunyuan-t1-vision-20250619": {
    "description": "Остання версія моделі hunyuan t1-vision для мультимодального розуміння з глибоким ланцюжком мислення, що підтримує нативні мультимодальні ланцюжки міркувань, із суттєвим покращенням порівняно з попередньою версією за замовчуванням."
  },
  "hunyuan-t1-vision-20250916": {
    "description": "Остання версія візуальної моделі глибокого мислення Hunyuan t1-vision значно покращена порівняно з попередньою в завданнях загальної візуально-текстової відповіді, візуального позиціонування, OCR, аналізу графіків, вирішення завдань по фото та візуальної творчості. Суттєво підвищені можливості роботи з англійською та малими мовами."
  },
  "hunyuan-turbo": {
    "description": "Попередня версія нового покоління мовної моделі Hunyuan, що використовує абсолютно нову структуру змішаної експертної моделі (MoE), яка забезпечує швидшу ефективність виведення та сильніші результати порівняно з hunyuan-pro."
  },
  "hunyuan-turbo-20241223": {
    "description": "Оптимізація цієї версії: масштабування даних та інструкцій, значне підвищення загальної узагальнюючої здатності моделі; значне покращення математичних, кодових та логічних здібностей; оптимізація розуміння тексту та пов'язаних з ним здібностей розуміння слів; оптимізація якості генерації контенту при створенні тексту."
  },
  "hunyuan-turbo-latest": {
    "description": "Оптимізація загального досвіду, включаючи розуміння NLP, створення тексту, спілкування, питання та відповіді на знання, переклад, області тощо; підвищення людяності, оптимізація емоційного інтелекту моделі; покращення здатності моделі активно прояснювати неясні наміри; підвищення здатності обробки питань, пов'язаних з аналізом слів; покращення якості та інтерактивності творчості; покращення багаторазової взаємодії."
  },
  "hunyuan-turbo-vision": {
    "description": "Флагманська модель нового покоління Hunyuan в області візуальної мови, що використовує абсолютно нову структуру змішаної експертної моделі (MoE), з повним покращенням здібностей в області базового розпізнавання, створення контенту, питань та відповідей на знання, аналізу та виведення порівняно з попередньою моделлю."
  },
  "hunyuan-turbos-20250313": {
    "description": "Уніфікація стилю вирішення математичних задач, посилення багатоходових математичних питань та відповідей. Оптимізація стилю відповідей у текстовій творчості, усунення штучного відтінку, додавання виразності."
  },
  "hunyuan-turbos-20250416": {
    "description": "Оновлення попередньо навченої бази, посилення здатності бази до розуміння та дотримання інструкцій; покращення математичних, програмних, логічних та наукових навичок на етапі узгодження; підвищення якості творчого письма, розуміння тексту, точності перекладу та знань у гуманітарних областях; посилення можливостей агентів у різних сферах, з особливим акцентом на розуміння багатоходових діалогів."
  },
  "hunyuan-turbos-20250604": {
    "description": "Оновлена база попереднього навчання, покращені навички письма та розуміння прочитаного, значне підвищення можливостей у програмуванні та точних науках, постійне покращення слідування складним інструкціям."
  },
  "hunyuan-turbos-20250926": {
    "description": "Оновлення якості даних для попередньо навчальної бази. Оптимізація стратегії навчання на етапі пост-тренування, постійне покращення можливостей агента, підтримки англійської та малих мов, дотримання інструкцій, а також навичок програмування та наукових знань."
  },
  "hunyuan-turbos-latest": {
    "description": "hunyuan-TurboS — це остання версія флагманської моделі Hunyuan, що володіє сильнішими аналітичними здібностями та покращеною якістю роботи."
  },
  "hunyuan-turbos-longtext-128k-20250325": {
    "description": "Спеціалізується на обробці довгих текстів, таких як резюме документів та питання по документах, а також володіє здатністю обробляти загальні завдання генерації тексту. Вона демонструє видатні результати в аналізі та генерації довгих текстів, ефективно справляючись з вимогами до складної та деталізованої обробки довгих текстів."
  },
  "hunyuan-turbos-role-plus": {
    "description": "Остання версія моделі ролевих ігор Hunyuan, офіційно донавчена модель, заснована на Hunyuan та доповнена даними для ролевих сценаріїв, що забезпечує кращі базові результати в ролевих іграх."
  },
  "hunyuan-turbos-vision": {
    "description": "Ця модель призначена для завдань розуміння зображень та тексту, заснована на останній версії hunyuan turbos та є новим флагманським візуально-мовним великим моделлю, зосередженою на завданнях розпізнавання об'єктів на зображеннях, відповідях на питання, створенні текстів та вирішенні завдань по фотографіях, з суттєвим покращенням порівняно з попереднім поколінням."
  },
  "hunyuan-turbos-vision-20250619": {
    "description": "Остання версія флагманської візуально-мовної моделі hunyuan turbos-vision, значно покращена порівняно з попередньою версією за замовчуванням в завданнях розуміння зображень та тексту, включаючи розпізнавання об'єктів на зображеннях, відповіді на питання, створення текстів та вирішення завдань по фотографіях."
  },
  "hunyuan-vision": {
    "description": "Остання багатомодальна модель Hunyuan, що підтримує введення зображень та тексту для генерації текстового контенту."
  },
  "image-01": {
    "description": "Нова модель генерації зображень з детальним промальовуванням, що підтримує генерацію з тексту та перетворення зображень."
  },
  "image-01-live": {
    "description": "Модель генерації зображень з детальним промальовуванням, що підтримує генерацію з тексту та налаштування стилю зображення."
  },
  "imagen-4.0-fast-generate-001": {
    "description": "Imagen — серія моделей перетворення тексту в зображення 4-го покоління, швидка версія"
  },
  "imagen-4.0-generate-001": {
    "description": "Серія моделей Imagen четвертого покоління для перетворення тексту в зображення"
  },
  "imagen-4.0-generate-preview-06-06": {
    "description": "Серія моделей Imagen 4-го покоління для перетворення тексту в зображення"
  },
  "imagen-4.0-ultra-generate-001": {
    "description": "Серія моделей Imagen четвертого покоління для перетворення тексту в зображення, версія Ultra."
  },
  "imagen-4.0-ultra-generate-preview-06-06": {
    "description": "Ультра-версія серії моделей Imagen 4-го покоління для перетворення тексту в зображення"
  },
  "inception/mercury-coder-small": {
    "description": "Mercury Coder Small — ідеальний вибір для завдань генерації, відладки та рефакторингу коду з мінімальною затримкою."
  },
  "inclusionAI/Ling-1T": {
    "description": "Ling-1T — флагманська модель без міркування (non-thinking) із серії «Ling 2.0», що володіє загальним числом параметрів в 1 трильйон та близько 50 мільярдів активних параметрів на кожен токен. Побудована на архітектурі Ling 2.0, Ling-1T прагне подолати межі ефективного виведення та масштабованого когнітивного розуміння. Модель Ling-1T-base навчена на більш ніж 20 трильйонах високоякісних токенів з інтенсивним міркуванням."
  },
  "inclusionAI/Ling-flash-2.0": {
    "description": "Ling-flash-2.0 — третя модель серії Ling 2.0, випущена командою Ant Group Bailing. Це модель змішаних експертів (MoE) із загальним числом параметрів 100 мільярдів, при цьому для кожного токена активується всього 6.1 мільярда параметрів (без урахування ембедінгів — 4.8 мільярда). Як легковесна конфігурація, Ling-flash-2.0 демонструє в кількох авторитетних тестах продуктивність, зіставну або перевершуючу моделі щільного типу (Dense) з 40 мільярдами параметрів та більші MoE-моделі. Модель спрямована на дослідження ефективних шляхів при концепції «велика модель дорівнює великому числу параметрів» через продуманий дизайн архітектури та стратегії навчання."
  },
  "inclusionAI/Ling-mini-2.0": {
    "description": "Ling-mini-2.0 — компактна високопродуктивна велика мовна модель на базі архітектури MoE. Вона містить 16 мільярдів параметрів, при цьому для кожного токена активується всього 1.4 мільярда параметрів (без ембедінгів — 789 мільйонів), що забезпечує дуже високу швидкість генерації. Завдяки ефективному дизайну MoE та масштабним якісним тренувальним даним, незважаючи на низьке число активуваних параметрів, Ling-mini-2.0 демонструє в downstream-задачах продуктивність, зіставну з щільними LLM менше 10 мільярдів параметрів та більшими MoE-моделями."
  },
  "inclusionAI/Ring-1T": {
    "description": "Ring-1T — відкрита модель мислення трильйонного масштабу, випущена командою Bailing. Побудована на архітектурі Ling 2.0 та базовій моделі Ling-1T-base, містить 1 трильйон загальних параметрів та 50 мільярдів активних параметрів, підтримує контекстне вікно до 128K. Оптимізована з використанням масштабного навчання з підкріпленням та перевіряємими нагородами."
  },
  "inclusionAI/Ring-flash-2.0": {
    "description": "Ring-flash-2.0 — високопродуктивна модель для міркувань, глибоко оптимізована на базі Ling-flash-2.0-base. Вона використовує архітектуру змішаних експертів (MoE) із загальним числом параметрів 100 мільярдів, при цьому при кожному виведенні активується тільки 6.1 мільярда параметрів. Модель вирішує проблему нестабільності MoE-моделей при навчанні з підкріпленням (RL) за допомогою унікального алгоритму icepop, що дозволяє постійно покращувати складні здібності міркування в довгостроковому навчанні. Ring-flash-2.0 досягла значних проривів у складних бенчмарках, таких як математичні змагання, генерація коду та логічне міркування. Її продуктивність перевершує кращі щільні моделі з числом параметрів менше 40 мільярдів та зіставна з більшими відкритими MoE-моделями та закритими високопродуктивними моделями для міркувань. Незважаючи на фокус на складних міркуваннях, модель також відмінно справляється з творчим письмом. Завдяки ефективному дизайну архітектури Ring-flash-2.0 забезпечує високу швидкість виведення та значно знижує витрати на розгортання моделей міркувань в умовах високого навантаження."
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5 пропонує інтелектуальні рішення для діалогів у різних сценаріях."
  },
  "internlm2.5-latest": {
    "description": "Наша остання серія моделей з видатними показниками виведення, що підтримує довжину контексту до 1M та володіє покращеними можливостями слідування інструкціям та виклику інструментів."
  },
  "internlm3-latest": {
    "description": "Наша остання серія моделей з видатною продуктивністю виведення, що лідирує серед моделей відкритого коду того ж рівня. За замовчуванням вказує на нашу останню випущену серію моделей InternLM3."
  },
  "internvl2.5-latest": {
    "description": "Ми продовжуємо підтримувати версію InternVL2.5, що володіє відмінною та стабільною продуктивністю. За замовчуванням вказує на нашу останню випущену серію моделей InternVL2.5, наразі вказує на internvl2.5-78b."
  },
  "internvl3-latest": {
    "description": "Ми випустили нашу останню багатомодальну велику модель, що володіє сильнішими здібностями до розуміння текстів та зображень, а також до розуміння довгих послідовностей зображень, продуктивність якої зіставна з провідними закритими моделями. За замовчуванням вказує на нашу останню випущену серію моделей InternVL, наразі вказує на internvl3-78b."
  },
  "irag-1.0": {
    "description": "Власна технологія Baidu iRAG (image based RAG) — це метод генерації зображень із підсиленням пошуку, який об'єднує мільярдні ресурси зображень Baidu Search з потужними базовими моделями, дозволяючи створювати надреалістичні зображення, що значно перевершують традиційні системи генерації зображень. Модель відрізняється відсутністю артефактів AI, високою реалістичністю та миттєвою доступністю за низьких витрат."
  },
  "jamba-large": {
    "description": "Наша найпотужніша та найпередовіша модель, розроблена для вирішення складних завдань корпоративного рівня, що володіє видатною продуктивністю."
  },
  "jamba-mini": {
    "description": "Найефективніша модель у своєму класі, що поєднує швидкість та якість, з меншими розмірами."
  },
  "jina-deepsearch-v1": {
    "description": "Глибокий пошук поєднує в собі мережевий пошук, читання та міркування, дозволяючи проводити всебічні дослідження. Ви можете розглядати його як агента, який приймає ваші дослідницькі завдання — він проводить великий пошук і проходить через безліч ітерацій, перш ніж надати відповідь. Цей процес включає постійні дослідження, міркування та вирішення проблем з різних точок зору. Це принципово відрізняється від стандартних великих моделей, які генерують відповіді безпосередньо з попередньо навчених даних, і від традиційних систем RAG, що покладаються на одноразовий поверхневий пошук."
  },
  "kimi-k2": {
    "description": "Kimi-K2 — базова модель на архітектурі MoE з видатними можливостями в кодуванні та агентських завданнях, випущена Moonshot AI, з загальним числом параметрів 1 трильйон та 32 мільярдами активованих параметрів. У тестах на універсальне знання, програмування, математику та агентські завдання продуктивність моделі K2 перевершує інші провідні відкриті моделі."
  },
  "kimi-k2-0711-preview": {
    "description": "kimi-k2 — базова модель з архітектурою MoE, що володіє потужними можливостями коду та агента, з загальним числом параметрів 1 трильйон та 32 мільярди активних параметрів. У тестах продуктивності за основними категоріями, такими як універсальне знання, програмування, математика та агенти, модель K2 перевершує інші провідні відкриті моделі."
  },
  "kimi-k2-0905-preview": {
    "description": "Модель kimi-k2-0905-preview з довжиною контексту 256k володіє сильнішими можливостями агентного кодування, покращеною естетикою та практичністю фронтенд-коду, а також кращим розумінням контексту."
  },
  "kimi-k2-instruct": {
    "description": "Kimi K2 Instruct — це велика мовна модель від Moonshot AI, що володіє здатністю обробляти наддовгий контекст."
  },
  "kimi-k2-turbo-preview": {
    "description": "kimi-k2 — це базова модель архітектури MoE з видатними можливостями в галузі програмування та агентів. Загальний об'єм параметрів — 1 трлн, активовані параметри — 32 млрд. У бенчмарках за основними категоріями (загальне знання та міркування, програмування, математика, агенти тощо) модель K2 демонструє результати вищі, ніж у інших провідних відкритих моделей."
  },
  "kimi-k2:1t": {
    "description": "Kimi K2 — це великомасштабна змішана експертна (MoE) мовна модель, розроблена ШІ зі зворотного боку Місяця, з загальною кількістю параметрів у 1 трильйон та 32 мільярдами активних параметрів на один прохід вперед. Вона оптимізована для агентських можливостей, включаючи просунуте використання інструментів, міркування та синтез коду."
  },
  "kimi-latest": {
    "description": "Продукт Kimi Smart Assistant використовує останню модель Kimi, яка може містити нестабільні функції. Підтримує розуміння зображень та автоматично вибирає модель 8k/32k/128k як модель для виставлення рахунків залежно від довжини контексту запиту."
  },
  "kimi-thinking-preview": {
    "description": "Модель kimi-thinking-preview від Moon’s Dark Side — мультимодальна модель мислення з можливостями універсального та глибокого міркування, допомагає вирішувати складніші завдання."
  },
  "learnlm-1.5-pro-experimental": {
    "description": "LearnLM — це експериментальна мовна модель, орієнтована на конкретні завдання, навчена відповідно до принципів науки про навчання, яка може дотримуватися системних інструкцій у навчальних та освітніх сценаріях, виступаючи в ролі експерта-наставника тощо."
  },
  "learnlm-2.0-flash-experimental": {
    "description": "LearnLM — це експериментальна мовна модель, орієнтована на конкретні завдання, навчена відповідно до принципів науки про навчання, здатна дотримуватися системних інструкцій у навчальних та освітніх сценаріях, виступаючи в ролі експерта-наставника тощо."
  },
  "lite": {
    "description": "Spark Lite — це легковагова велика мовна модель з надзвичайно низькою затримкою та високою ефективністю обробки, повністю безкоштовна та відкрита, підтримує функції онлайн-пошуку в реальному часі. Її швидка реакція робить її відмінним вибором для застосування в пристроях з низькою обчислювальною потужністю та для тонкого налаштування моделей, забезпечуючи користувачам відмінне співвідношення ціни та якості, особливо в сценаріях питань та відповідей, генерації контенту та пошуку."
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70B пропонує потужніші можливості ШІ висновку, підходить для складних додатків, підтримує величезну кількість обчислювальних процесів та гарантує ефективність та точність."
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8B — це високоефективна модель, що забезпечує швидку генерацію тексту, ідеально підходить для додатків, що вимагають масштабної ефективності та економічності."
  },
  "llama-3.1-instruct": {
    "description": "Модель Llama 3.1 з тонким налаштуванням інструкцій оптимізована для діалогових сценаріїв та перевершує багато існуючих відкритих чат-моделей за стандартними галузевими тестами."
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "Відмінні здібності до візуального розуміння зображень на високій роздільній здатності, призначені для додатків візуального розуміння."
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2 призначена для обробки завдань, що поєднують візуальні та текстові дані. Вона демонструє відмінні результати в завданнях опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним висновком."
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "Досконалі можливості візуального розуміння для програми-агента."
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2 призначена для обробки завдань, що поєднують візуальні та текстові дані. Вона демонструє відмінні результати в завданнях опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним висновком."
  },
  "llama-3.2-vision-instruct": {
    "description": "Модель Llama 3.2-Vision з тонким налаштуванням команд оптимізована для візуального розпізнавання, аналізу зображень, опису зображень та відповідей на загальні питання, пов'язані із зображеннями."
  },
  "llama-3.3-70b": {
    "description": "Llama 3.3 70B: середньо-велика модель Llama, що поєднує логічні здібності та високу пропускну здатність."
  },
  "llama-3.3-70b-versatile": {
    "description": "Багатомовна велика мовна модель Meta Llama 3.3 (LLM) — це попередньо навчена та відкоригована модель генерації на 70B (текстовий ввід/текстовий вивід). Відкоригована на чистому тексті модель Llama 3.3 оптимізована для багатомовних діалогових завдань та перевершує багато доступних відкритих та закритих моделей чату за загальними промисловими стандартами."
  },
  "llama-3.3-instruct": {
    "description": "Модель Llama 3.3 з тонким налаштуванням інструкцій оптимізована для діалогових сценаріїв та перевершує багато існуючих моделей з відкритим вихідним кодом у стандартних галузевих тестах."
  },
  "llama-4-scout-17b-16e-instruct": {
    "description": "Llama 4 Scout: високопродуктивна модель серії Llama, оптимізована для сценаріїв з високою пропускною здатністю та низькою затримкою."
  },
  "llama3-70b-8192": {
    "description": "Meta Llama 3 70B пропонує неперевершені можливості обробки складності, спеціально розроблені для високих вимог проєктів."
  },
  "llama3-8b-8192": {
    "description": "Meta Llama 3 8B забезпечує високоякісну продуктивність виведення, придатну для різноманітних додатків."
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Use пропонує потужні можливості виклику інструментів, підтримуючи ефективну обробку складних завдань."
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Use — це модель, оптимізована для ефективного використання інструментів, підтримуючи швидку паралельну обробку."
  },
  "llama3.1": {
    "description": "Llama 3.1 — це передова модель, випущена Meta, що підтримує до 405B параметрів, застосовна в складних діалогах, багатомовному перекладі та аналізі даних."
  },
  "llama3.1-8b": {
    "description": "Llama 3.1 8B: компактний та низькозатримковий варіант Llama, придатний для легких онлайн-інференцій та інтерактивних сценаріїв."
  },
  "llama3.1:405b": {
    "description": "Llama 3.1 — це передова модель, випущена Meta, що підтримує до 405B параметрів, застосовна в складних діалогах, багатомовному перекладі та аналізі даних."
  },
  "llama3.1:70b": {
    "description": "Llama 3.1 — це передова модель, випущена Meta, що підтримує до 405B параметрів, застосовна в складних діалогах, багатомовному перекладі та аналізі даних."
  },
  "llava": {
    "description": "LLaVA — це мультимодальна модель, що об'єднує візуальний кодувальник та Vicuna, призначена для потужного розуміння візуальної та мовної інформації."
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7B пропонує можливості візуальної обробки, генеруючи складні вихідні дані на основі візуальної інформації."
  },
  "llava:13b": {
    "description": "LLaVA — це мультимодальна модель, що об'єднує візуальний кодувальник та Vicuna, призначена для потужного розуміння візуальної та мовної інформації."
  },
  "llava:34b": {
    "description": "LLaVA — це мультимодальна модель, що об'єднує візуальний кодувальник та Vicuna, призначена для потужного розуміння візуальної та мовної інформації."
  },
  "magistral-medium-latest": {
    "description": "Magistral Medium 1.2 — це передова модель висновку з підтримкою візуальних даних, випущена Mistral AI у вересні 2025 року."
  },
  "magistral-small-2509": {
    "description": "Magistral Small 1.2 — це відкрита компактна модель висновку з підтримкою візуальних даних, випущена Mistral AI у вересні 2025 року."
  },
  "mathstral": {
    "description": "MathΣtral спеціально розроблений для наукових досліджень та математичного висновку, забезпечуючи ефективні обчислювальні можливості та інтерпретацію результатів."
  },
  "max-32k": {
    "description": "Spark Max 32K володіє великою здатністю обробки контексту, покращеним розумінням контексту та логічним висновком, підтримує текстовий ввід до 32K токенів, підходить для читання довгих документів, приватних питань та відповідей та інших сценаріїв."
  },
  "megrez-3b-instruct": {
    "description": "Megrez 3B Instruct — це компактна та ефективна модель з малим числом параметрів, розроблена компанією Wuwen Xinqiong."
  },
  "meta-llama-3-70b-instruct": {
    "description": "Потужна модель з 70 мільярдами параметрів, що перевершує в галузі міркувань, кодування та широких мовних додатків."
  },
  "meta-llama-3-8b-instruct": {
    "description": "Універсальна модель з 8 мільярдами параметрів, оптимізована для діалогових та текстових завдань."
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "Моделі Llama 3.1, налаштовані на інструкції, оптимізовані для багатомовних діалогових випадків та перевершують багато доступних моделей відкритого та закритого чату за загальними галузевими стандартами."
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "Моделі Llama 3.1, налаштовані на інструкції, оптимізовані для багатомовних діалогових випадків та перевершують багато доступних моделей відкритого та закритого чату за загальними галузевими стандартами."
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "Моделі Llama 3.1, налаштовані на інструкції, оптимізовані для багатомовних діалогових випадків та перевершують багато доступних моделей відкритого та закритого чату за загальними галузевими стандартами."
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B) пропонує відмінні можливості обробки мови та видатний досвід взаємодії."
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "LLaMA-2 пропонує чудові здібності обробки мови та видатний користувацький досвід."
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "LLaMA-3 Chat (70B) — потужна модель для чату, що підтримує складні діалогові запити."
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "LLaMA-3 Chat (8B) пропонує багатомовну підтримку та охоплює широкий спектр областей знань."
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 призначена для виконання завдань, що об'єднують візуальні та текстові дані. Вона відмінно справляється з завданнями з опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним розумінням."
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "LLaMA 3.2 призначена для виконання завдань, що об'єднують візуальні та текстові дані. Вона відмінно справляється з завданнями з опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним розумінням."
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 призначена для виконання завдань, що об'єднують візуальні та текстові дані. Вона відмінно справляється з завданнями з опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним розумінням."
  },
  "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
    "description": "Багатомовна велика мовна модель Meta Llama 3.3 (LLM) — це попередньо навчена та налаштована на інструкції генеративна модель об'ємом 70B (вхідний/вихідний текст). Модель Llama 3.3, налаштована на інструкції, оптимізована для багатомовних діалогових випадків та перевершує багато доступних відкритих та закритих моделей чату за загальними галузевими бенчмарками."
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "LLaMA 3.2 призначена для виконання завдань, що об'єднують візуальні та текстові дані. Вона відмінно справляється з завданнями з опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним розумінням."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "Llama 3 70B Instruct Lite підходить для середовищ, що вимагають високої продуктивності та низької затримки."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "Llama 3 70B Instruct Turbo забезпечує видатні можливості розуміння та генерації мови, придатні для найвимогливіших обчислювальних завдань."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "Llama 3 8B Instruct Lite підходить для обмежених ресурсами середовищ, забезпечуючи відмінне співвідношення продуктивності."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "Llama 3 8B Instruct Turbo — це високоефективна велика мовна модель, що підтримує широкий спектр додатків."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "LLaMA 3.1 405B — це потужна модель, заснована на попередньому навчанні та налаштуванні інструкцій."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "Модель Llama 3.1 Turbo 405B пропонує величезну підтримку контексту для обробки великих даних та демонструє видатні результати в масштабних додатках штучного інтелекту."
  },
  "meta-llama/Meta-Llama-3.1-70B": {
    "description": "Llama 3.1 — це передова модель, представлена Meta, що підтримує до 405B параметрів, застосовна в складних діалогах, багатомовному перекладі та аналізі даних."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "Модель Llama 3.1 70B була ретельно налаштована для високонавантажених додатків, квантована до FP8 для підвищення обчислювальної потужності та точності, забезпечуючи видатні результати в складних сценаріях."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "Модель Llama 3.1 8B використовує FP8-квантування та підтримує до 131,072 контекстних токенів, будучи видатною серед відкритих моделей, придатних для складних завдань та перевершуючи багато галузевих стандартів."
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "Llama 3 70B Instruct оптимізований для високоякісних діалогових сцен та показує відмінні результати в різних оцінках."
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "Llama 3 8B Instruct оптимізований для високоякісних діалогових сцен, його продуктивність перевершує багато закритих моделей."
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instruct розроблений для високоякісних діалогів та показує видатні результати в оцінках, особливо в високоінтерактивних сценах."
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B Instruct — це остання версія від Meta, оптимізована для високоякісних діалогових сцен, що перевершує багато провідних закритих моделей."
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1 пропонує підтримку декількох мов та є однією з провідних генеративних моделей у галузі."
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "LLaMA 3.2 призначена для обробки завдань, що поєднують візуальні та текстові дані. Вона демонструє відмінні результати в завданнях опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним висновком."
  },
  "meta-llama/llama-3.2-3b-instruct": {
    "description": "meta-llama/llama-3.2-3b-instruct"
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "LLaMA 3.2 призначена для обробки завдань, що поєднують візуальні та текстові дані. Вона демонструє відмінні результати в завданнях опису зображень та візуальної взаємодії питання-відповідь, долаючи розрив між генерацією мови та візуальним висновком."
  },
  "meta-llama/llama-3.3-70b-instruct": {
    "description": "Llama 3.3 — це найсучасніша багатомовна відкрита мовна модель із серії Llama, яка дозволяє отримати продуктивність, порівнянну з 405B моделями, за дуже низькою ціною. Заснована на структурі Transformer та покращена за допомогою контрольованого доналаштування (SFT) та навчання з підкріпленням на основі людського зворотного зв'язку (RLHF) для підвищення корисності та безпеки. Її версія з оптимізацією під інструкції спеціально розроблена для багатомовних діалогів та показує кращі результати порівняно з безліччю відкритих та закритих моделей чату на різних галузевих бенчмарках. Дата закінчення знань — грудень 2023 року."
  },
  "meta-llama/llama-3.3-70b-instruct:free": {
    "description": "Llama 3.3 — це найсучасніша багатомовна відкрита мовна модель із серії Llama, яка дозволяє отримати продуктивність, порівнянну з 405B моделями, за дуже низькою ціною. Заснована на структурі Transformer та покращена за допомогою контрольованого доналаштування (SFT) та навчання з підкріпленням на основі людського зворотного зв'язку (RLHF) для підвищення корисності та безпеки. Її версія з оптимізацією під інструкції спеціально розроблена для багатомовних діалогів та показує кращі результати порівняно з безліччю відкритих та закритих моделей чату на різних галузевих бенчмарках. Дата закінчення знань — грудень 2023 року."
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "Meta Llama 3.1 405B Instruct — це найбільша та найпотужніша модель у лінійці Llama 3.1 Instruct, що є високорозгорнутою моделлю для діалогового висновку та генерації синтетичних даних, також може використовуватися як основа для спеціалізованого попереднього навчання або донавчання в певних областях. Багатомовні великі мовні моделі (LLMs), пропоновані Llama 3.1, є набором попередньо навчених генеративних моделей з налаштуванням на інструкції, включаючи розміри 8B, 70B та 405B (вхід/вихід тексту). Моделі тексту з налаштуванням на інструкції Llama 3.1 (8B, 70B, 405B) оптимізовані для багатомовних діалогових випадків та перевершують багато доступних відкритих моделей чату в загальноприйнятих галузевих бенчмарках. Llama 3.1 призначена для комерційного та дослідницького використання кількома мовами. Моделі тексту з налаштуванням на інструкції підходять для діалогів, схожих на помічників, тоді як попередньо навчені моделі можуть адаптуватися до різних завдань генерації природної мови. Моделі Llama 3.1 також підтримують використання їхнього виводу для покращення інших моделей, включаючи генерацію синтетичних даних та уточнення. Llama 3.1 є саморегресійною мовною моделлю, що використовує оптимізовану архітектуру трансформерів. Налаштовані версії використовують контрольоване донавчання (SFT) та навчання з підкріпленням з людським зворотним зв'язком (RLHF), щоб відповідати перевагам людей щодо корисності та безпеки."
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "Оновлена версія Meta Llama 3.1 70B Instruct, що включає розширену довжину контексту до 128K, багатомовність та покращені здібності висновку. Багатомовні великі мовні моделі (LLMs), пропоновані Llama 3.1, є набором попередньо навчених, налаштованих на інструкції генеративних моделей, включаючи розміри 8B, 70B та 405B (ввід/вивід тексту). Налаштовані на інструкції текстові моделі (8B, 70B, 405B) оптимізовані для багатомовних діалогових випадків та перевершують багато доступних відкритих моделей чату в загальних галузевих бенчмарках. Llama 3.1 призначена для комерційного та дослідницького використання кількома мовами. Налаштовані на інструкції текстові моделі підходять для діалогів, схожих на помічника, тоді як попередньо навчені моделі можуть адаптуватися до різних завдань генерації природної мови. Моделі Llama 3.1 також підтримують використання виводу своїх моделей для покращення інших моделей, включаючи генерацію синтетичних даних та уточнення. Llama 3.1 — це саморегресійна мовна модель, що використовує оптимізовану архітектуру трансформерів. Налаштовані версії використовують контрольоване донавчання (SFT) та навчання з підкріпленням з людським зворотним зв'язком (RLHF), щоб відповідати людським перевагам щодо корисності та безпеки."
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "Оновлена версія Meta Llama 3.1 8B Instruct, що включає розширену довжину контексту до 128K, багатомовність та покращені здібності висновку. Багатомовні великі мовні моделі (LLMs), пропоновані Llama 3.1, є набором попередньо навчених, налаштованих на інструкції генеративних моделей, включаючи розміри 8B, 70B та 405B (ввід/вивід тексту). Налаштовані на інструкції текстові моделі (8B, 70B, 405B) оптимізовані для багатомовних діалогових випадків та перевершують багато доступних відкритих моделей чату в загальних галузевих бенчмарках. Llama 3.1 призначена для комерційного та дослідницького використання кількома мовами. Налаштовані на інструкції текстові моделі підходять для діалогів, схожих на помічника, тоді як попередньо навчені моделі можуть адаптуватися до різних завдань генерації природної мови. Моделі Llama 3.1 також підтримують використання виводу своїх моделей для покращення інших моделей, включаючи генерацію синтетичних даних та уточнення. Llama 3.1 — це саморегресійна мовна модель, що використовує оптимізовану архітектуру трансформерів. Налаштовані версії використовують контрольоване донавчання (SFT) та навчання з підкріпленням з людським зворотним зв'язком (RLHF), щоб відповідати людським перевагам щодо корисності та безпеки."
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "Meta Llama 3 — це відкрита велика мовна модель (LLM), орієнтована на розробників, дослідників та підприємства, призначена для допомоги у створенні, експериментуванні та відповідальному масштабуванні їхніх ідей щодо генеративного ШІ. Як частина базової системи для інновацій глобальної спільноти, вона ідеально підходить для створення контенту, діалогового ШІ, розуміння мови, НДДКР та корпоративних додатків."
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "Meta Llama 3 — це відкрита велика мовна модель (LLM), орієнтована на розробників, дослідників та підприємства, призначена для допомоги у створенні, експериментуванні та відповідальному масштабуванні їхніх ідей щодо генеративного ШІ. Як частина базової системи для інновацій глобальної спільноти, вона ідеально підходить для пристроїв з обмеженими обчислювальними потужностями та ресурсами, а також для швидшого часу навчання."
  },
  "meta/Llama-3.2-11B-Vision-Instruct": {
    "description": "Відмінні здібності до міркування на основі зображень високої роздільної здатності, підходить для додатків візуального розуміння."
  },
  "meta/Llama-3.2-90B-Vision-Instruct": {
    "description": "Просунуті можливості міркування на основі зображень для додатків візуального розуміння та агентів."
  },
  "meta/Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3 — найпередовіша багатомовна відкрита велика мовна модель серії Llama, що забезпечує продуктивність, порівнянну з моделлю на 405 млрд параметрів, при дуже низьких витратах. Заснована на архітектурі Transformer та покращена за допомогою контрольованого доналаштування (SFT) та навчання з підкріпленням на основі людського зворотного зв'язку (RLHF) для підвищення корисності та безпеки. Версія з інструкціями оптимізована для багатомовного діалогу та перевершує багато відкритих та закритих чат-моделей за рядом галузевих бенчмарків. Дата відсікання знань — грудень 2023 року."
  },
  "meta/Meta-Llama-3-70B-Instruct": {
    "description": "Потужна модель з 70 млрд параметрів, що демонструє видатні здібності в міркуваннях, кодуванні та широкому спектрі мовних додатків."
  },
  "meta/Meta-Llama-3-8B-Instruct": {
    "description": "Універсальна модель з 8 млрд параметрів, оптимізована для завдань діалогу та генерації тексту."
  },
  "meta/Meta-Llama-3.1-405B-Instruct": {
    "description": "Текстова модель Llama 3.1 з доналаштуванням за інструкціями, оптимізована для багатомовних діалогів, демонструє високі результати на популярних галузевих бенчмарках серед доступних відкритих та закритих чат-моделей."
  },
  "meta/Meta-Llama-3.1-70B-Instruct": {
    "description": "Текстова модель Llama 3.1 з доналаштуванням за інструкціями, оптимізована для багатомовних діалогів, демонструє високі результати на популярних галузевих бенчмарках серед доступних відкритих та закритих чат-моделей."
  },
  "meta/Meta-Llama-3.1-8B-Instruct": {
    "description": "Текстова модель Llama 3.1 з доналаштуванням за інструкціями, оптимізована для багатомовних діалогів, демонструє високі результати на популярних галузевих бенчмарках серед доступних відкритих та закритих чат-моделей."
  },
  "meta/llama-3-70b": {
    "description": "Відкрита модель з 70 мільярдами параметрів, ретельно налаштована Meta для слідування інструкціям. Обслуговується на апаратурі Groq з використанням їхніх спеціалізованих мовних процесорних блоків (LPU) для швидкої та ефективної роботи."
  },
  "meta/llama-3-8b": {
    "description": "Відкрита модель з 8 мільярдами параметрів, ретельно налаштована Meta для слідування інструкціям. Обслуговується на апаратурі Groq з використанням їхніх спеціалізованих мовних процесорних блоків (LPU) для швидкої та ефективної роботи."
  },
  "meta/llama-3.1-405b-instruct": {
    "description": "Сучасна LLM, що підтримує генерацію синтетичних даних, дистиляцію знань та міркування, підходить для чат-ботів, програмування та спеціалізованих завдань."
  },
  "meta/llama-3.1-70b": {
    "description": "Оновлена версія Meta Llama 3 70B Instruct з розширеною довжиною контексту 128K, багатомовністю та покращеними можливостями виводу."
  },
  "meta/llama-3.1-70b-instruct": {
    "description": "Забезпечує складні діалоги, володіючи видатним розумінням контексту, здібностями до міркування та генерації тексту."
  },
  "meta/llama-3.1-8b": {
    "description": "Llama 3.1 8B підтримує вікно контексту 128K, що робить її ідеальною для інтерфейсів реального часу та аналізу даних, при цьому забезпечуючи значну економію порівняно з більшими моделями. Обслуговується на апаратурі Groq з використанням їхніх спеціалізованих мовних процесорних блоків (LPU) для швидкої та ефективної роботи."
  },
  "meta/llama-3.1-8b-instruct": {
    "description": "Сучасна передова модель, що володіє розумінням мови, видатними здібностями до міркування та генерації тексту."
  },
  "meta/llama-3.2-11b": {
    "description": "Модель генерації з виводом зображень, налаштована за інструкціями (текст + зображення на вході / текст на виході), оптимізована для візуального розпізнавання, виводу зображень, генерації заголовків та відповідей на загальні питання про зображення."
  },
  "meta/llama-3.2-11b-vision-instruct": {
    "description": "Сучасна візуально-мовна модель, що спеціалізується на високоякісному міркуванні на основі зображень."
  },
  "meta/llama-3.2-1b": {
    "description": "Тільки текстова модель, що підтримує локальні сценарії, такі як багатомовний пошук знань, узагальнення та перефразування."
  },
  "meta/llama-3.2-1b-instruct": {
    "description": "Сучасна передова компактна мовна модель, що володіє розумінням мови, видатними здібностями до міркування та генерації тексту."
  },
  "meta/llama-3.2-3b": {
    "description": "Тільки текстова модель, ретельно налаштована для підтримки локальних сценаріїв, таких як багатомовний пошук знань, узагальнення та перефразування."
  },
  "meta/llama-3.2-3b-instruct": {
    "description": "Сучасна передова компактна мовна модель, що володіє розумінням мови, видатними здібностями до міркування та генерації тексту."
  },
  "meta/llama-3.2-90b": {
    "description": "Модель генерації з виводом зображень, налаштована за інструкціями (текст + зображення на вході / текст на виході), оптимізована для візуального розпізнавання, виводу зображень, генерації заголовків та відповідей на загальні питання про зображення."
  },
  "meta/llama-3.2-90b-vision-instruct": {
    "description": "Сучасна візуально-мовна модель, що спеціалізується на високоякісному міркуванні на основі зображень."
  },
  "meta/llama-3.3-70b": {
    "description": "Ідеальне поєднання продуктивності та ефективності. Модель підтримує високопродуктивний діалоговий ШІ, розроблена для створення контенту, корпоративних додатків та досліджень, забезпечуючи передові можливості розуміння мови, включаючи узагальнення тексту, класифікацію, аналіз настроїв та генерацію коду."
  },
  "meta/llama-3.3-70b-instruct": {
    "description": "Сучасна LLM, що спеціалізується на міркуваннях, математиці, здоровому глузді та викликах функцій."
  },
  "meta/llama-4-maverick": {
    "description": "Набір моделей Llama 4 — це нативні мультимодальні ШІ-моделі, що підтримують текст та мультимодальні взаємодії. Ці моделі використовують архітектуру змішаних експертів для забезпечення лідируючої в галузі продуктивності в розумінні тексту та зображень. Llama 4 Maverick — модель з 17 мільярдами параметрів та 128 експертами. Обслуговується DeepInfra."
  },
  "meta/llama-4-scout": {
    "description": "Набір моделей Llama 4 — це нативні мультимодальні ШІ-моделі, що підтримують текст та мультимодальні взаємодії. Ці моделі використовують архітектуру змішаних експертів для забезпечення лідируючої в галузі продуктивності в розумінні тексту та зображень. Llama 4 Scout — модель з 17 мільярдами параметрів та 16 експертами. Обслуговується DeepInfra."
  },
  "microsoft/Phi-3-medium-128k-instruct": {
    "description": "Та сама модель Phi-3-medium, але зі збільшеним розміром контексту, придатна для RAG або невеликої кількості підказок."
  },
  "microsoft/Phi-3-medium-4k-instruct": {
    "description": "Модель з 14 млрд параметрів, що перевершує Phi-3-mini за якістю, орієнтована на високоякісні, інтенсивні за міркуваннями дані."
  },
  "microsoft/Phi-3-mini-128k-instruct": {
    "description": "Та сама модель Phi-3-mini, але зі збільшеним розміром контексту, придатна для RAG або невеликої кількості підказок."
  },
  "microsoft/Phi-3-mini-4k-instruct": {
    "description": "Найменший представник сімейства Phi-3, оптимізований за якістю та низькою затримкою."
  },
  "microsoft/Phi-3-small-128k-instruct": {
    "description": "Та сама модель Phi-3-small, але зі збільшеним розміром контексту, придатна для RAG або невеликої кількості підказок."
  },
  "microsoft/Phi-3-small-8k-instruct": {
    "description": "Модель з 7 млрд параметрів, що перевершує Phi-3-mini за якістю, орієнтована на високоякісні, інтенсивні за міркуваннями дані."
  },
  "microsoft/Phi-3.5-mini-instruct": {
    "description": "Оновлена версія моделі Phi-3-mini."
  },
  "microsoft/Phi-3.5-vision-instruct": {
    "description": "Оновлена версія моделі Phi-3-vision."
  },
  "microsoft/WizardLM-2-8x22B": {
    "description": "WizardLM 2 — це мовна модель від Microsoft AI, яка особливо добре справляється зі складними діалогами, багатомовністю, висновками та інтелектуальними помічниками."
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22B — це передова модель Wizard від Microsoft, що демонструє винятково конкурентоспроможні результати."
  },
  "minicpm-v": {
    "description": "MiniCPM-V — це нове покоління мультимодальної великої моделі від OpenBMB, що володіє видатними можливостями OCR та мультимодального розуміння, підтримує широкий спектр додатків."
  },
  "ministral-3b-latest": {
    "description": "Ministral 3B - це видатна модель від Mistral."
  },
  "ministral-8b-latest": {
    "description": "Ministral 8B - це економічно ефективна модель від Mistral."
  },
  "mistral": {
    "description": "Mistral — це 7B модель, випущена Mistral AI, придатна для різноманітних мовних завдань."
  },
  "mistral-ai/Mistral-Large-2411": {
    "description": "Флагманська модель Mistral, призначена для завдань, що вимагають масштабних можливостей міркування або високої спеціалізації (синтез тексту, генерація коду, RAG або агенти)."
  },
  "mistral-ai/Mistral-Nemo": {
    "description": "Mistral Nemo — передова мовна модель (LLM), що володіє найкращими у своєму класі здібностями до міркування, світових знань та кодування."
  },
  "mistral-ai/mistral-small-2503": {
    "description": "Mistral Small підходить для будь-яких мовних завдань, що вимагають високої ефективності та низької затримки."
  },
  "mistral-large": {
    "description": "Mixtral Large — це флагманська модель від Mistral, що об'єднує можливості генерації коду, математики та висновку, підтримує контекстне вікно 128k."
  },
  "mistral-large-instruct": {
    "description": "Mistral-Large-Instruct-2407 — це передова щільна велика мовна модель (LLM) з 123 мільярдами параметрів, що володіє сучасними можливостями логічного висновування, обробки знань та програмування."
  },
  "mistral-large-latest": {
    "description": "Mistral Large — це флагманська велика модель, добре підходить для багатомовних завдань, складного висновування та генерації коду, ідеальний вибір для висококласних додатків."
  },
  "mistral-medium-latest": {
    "description": "Mistral Medium 3 пропонує передові характеристики з восьмикратними витратами та значно спрощує розгортання в корпоративному середовищі."
  },
  "mistral-nemo": {
    "description": "Mistral Nemo, розроблений у співпраці між Mistral AI та NVIDIA, є високоефективною 12B моделлю."
  },
  "mistral-nemo-instruct": {
    "description": "Mistral-Nemo-Instruct-2407 — це велика мовна модель (LLM), що представляє собою версію Mistral-Nemo-Base-2407 з тонким налаштуванням для виконання інструкцій."
  },
  "mistral-small": {
    "description": "Mistral Small може використовуватися для будь-яких мовних завдань, що вимагають високої ефективності та низької затримки."
  },
  "mistral-small-latest": {
    "description": "Mistral Small — це економічно ефективний, швидкий та надійний варіант для таких випадків, як переклад, резюме та аналіз настроїв."
  },
  "mistral/codestral": {
    "description": "Mistral Codestral 25.01 — передова модель кодування, оптимізована для низької затримки та високочастотних сценаріїв. Підтримує понад 80 мов програмування, відмінно справляється із завданнями заповнення пропусків (FIM), виправлення коду та генерації тестів."
  },
  "mistral/codestral-embed": {
    "description": "Модель кодових вбудованих даних, яку можна вбудовувати в бази даних та репозиторії коду для підтримки помічників з програмування."
  },
  "mistral/devstral-small": {
    "description": "Devstral — агентна великомасштабна мовна модель для завдань програмної інженерії, відмінний вибір для агентних рішень в галузі розробки ПЗ."
  },
  "mistral/magistral-medium": {
    "description": "Складне мислення, підтримуване глибоким розумінням, з прозорим міркуванням, яке ви можете прослідкувати та перевірити. Модель зберігає високу точність міркувань багатьма мовами, навіть при зміні мови в середині завдання."
  },
  "mistral/magistral-small": {
    "description": "Складне мислення, підтримуване глибоким розумінням, з прозорим міркуванням, яке ви можете прослідкувати та перевірити. Модель зберігає високу точність міркувань багатьма мовами, навіть при зміні мови в середині завдання."
  },
  "mistral/ministral-3b": {
    "description": "Компактна та ефективна модель для завдань на пристроях, таких як інтелектуальні помічники та локальний аналіз, що забезпечує низьку затримку."
  },
  "mistral/ministral-8b": {
    "description": "Більш потужна модель з швидшою та енергоефективнішою роботою, ідеальна для складних робочих процесів та вимогливих додатків на периферії."
  },
  "mistral/mistral-embed": {
    "description": "Універсальна модель текстових вбудованих даних для семантичного пошуку, визначення схожості, кластеризації та робочих процесів RAG."
  },
  "mistral/mistral-large": {
    "description": "Mistral Large — ідеальний вибір для складних завдань, що вимагають великої обчислювальної потужності або високої спеціалізації, таких як синтез тексту, генерація коду, RAG або агентні завдання."
  },
  "mistral/mistral-small": {
    "description": "Mistral Small — ідеальний вибір для простих завдань, які можна виконувати пакетно, таких як класифікація, підтримка клієнтів або генерація тексту. Забезпечує відмінну продуктивність за доступною ціною."
  },
  "mistral/mixtral-8x22b-instruct": {
    "description": "8x22b Instruct — модель з 8 експертами по 22 мільярди параметрів, відкрита модель з архітектурою змішаних експертів, обслуговується Mistral."
  },
  "mistral/pixtral-12b": {
    "description": "Модель з 12 мільярдами параметрів, що володіє здібностями до розуміння зображень та тексту."
  },
  "mistral/pixtral-large": {
    "description": "Pixtral Large — друга модель у нашій мультимодальній родині, що демонструє передові можливості розуміння зображень. Зокрема, модель здатна розуміти документи, діаграми та природні зображення, зберігаючи при цьому лідируючі можливості розуміння тексту, притаманні Mistral Large 2."
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instruct відомий своєю високою продуктивністю та підходить для безлічі мовних завдань."
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "Mistral 7B — це модель з налаштуванням за запитом, що пропонує оптимізовані відповіді на завдання."
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3 забезпечує ефективні обчислювальні можливості та розуміння природної мови, придатні для широкого спектру додатків."
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7B - це компактна, але високопродуктивна модель, добре підходить для пакетної обробки та простих завдань, таких як класифікація та генерація тексту, з хорошими здібностями до міркування."
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B) — це супер велика мовна модель, що підтримує вкрай високі вимоги до обробки."
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral 8x7B — це попередньо навчена модель розріджених змішаних експертів, призначена для універсальних текстових завдань."
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7B - це розріджена модель експерта, що використовує багато параметрів для підвищення швидкості висновування, підходить для обробки багатомовних та генеративних завдань."
  },
  "mistralai/mistral-7b-instruct": {
    "description": "Mistral 7B Instruct — це високопродуктивна модель стандартів галузі, оптимізована для швидкості та підтримки довгого контексту."
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemo — це модель з 7.3B параметрами, що підтримує кілька мов та високопродуктивне програмування."
  },
  "mixtral": {
    "description": "Mixtral — це експертна модель від Mistral AI, що володіє відкритими вагами та підтримує генерацію коду та розуміння мови."
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7B пропонує високу відмовостійкість паралельної обробки, придатної для складних завдань."
  },
  "mixtral:8x22b": {
    "description": "Mixtral — це експертна модель від Mistral AI, що володіє відкритими вагами та підтримує генерацію коду та розуміння мови."
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128K — це модель з можливостями обробки наддовгого контексту, придатна для генерації дуже довгих текстів, що задовольняє вимогам складних завдань генерації, здатна обробляти до 128 000 токенів, ідеально підходить для наукових досліджень, академічних та великих документальних додатків."
  },
  "moonshot-v1-128k-vision-preview": {
    "description": "Модель візуалізації Kimi (включаючи moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview та ін.) може розуміти вміст зображень, включаючи текст на зображеннях, кольори зображень та форми об'єктів."
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32K пропонує можливості обробки контексту середньої довжини, здатна обробляти 32 768 токенів, особливо підходить для генерації різних довгих документів та складних діалогів, застосовується у створенні контенту, генерації звітів та діалогових систем."
  },
  "moonshot-v1-32k-vision-preview": {
    "description": "Модель візуалізації Kimi (включаючи moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview та ін.) може розуміти вміст зображень, включаючи текст на зображеннях, кольори зображень та форми об'єктів."
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8K спеціально розроблений для генерації коротких текстів, володіючи високою продуктивністю обробки, здатний обробляти 8 192 токени, ідеально підходить для коротких діалогів, стенографування та швидкої генерації контенту."
  },
  "moonshot-v1-8k-vision-preview": {
    "description": "Модель візуалізації Kimi (включаючи moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview та ін.) може розуміти вміст зображень, включаючи текст на зображеннях, кольори зображень та форми об'єктів."
  },
  "moonshot-v1-auto": {
    "description": "Moonshot V1 Auto може вибирати відповідну модель залежно від кількості токенів, що використовуються в поточному контексті."
  },
  "moonshotai/Kimi-Dev-72B": {
    "description": "Kimi-Dev-72B — це велика модель з відкритим вихідним кодом, оптимізована за допомогою масштабного навчання з підкріпленням, здатна видавати надійні патчі, готові до безпосереднього впровадження. Ця модель досягла нового рекордного результату 60,4 % на SWE-bench Verified, оновивши рекорди відкритих моделей в автоматизованих завданнях програмної інженерії, таких як виправлення помилок та код-рев'ю."
  },
  "moonshotai/Kimi-K2-Instruct-0905": {
    "description": "Kimi K2-Instruct-0905 — це остання та найпотужніша версія Kimi K2. Це передова мовна модель з архітектурою змішаних експертів (MoE), що володіє загальним числом параметрів у 1 трильйон та 32 мільярдами активних параметрів. Основні характеристики моделі включають: покращений інтелект кодуючих агентів, що демонструє значний приріст продуктивності на відкритих бенчмарках та в реальних завданнях кодування агентів; удосконалений досвід фронтенд-кодування, з покращеннями як в естетиці, так і в практичності фронтенд-програмування."
  },
  "moonshotai/kimi-k2": {
    "description": "Kimi K2 — великомасштабна змішана експертна (MoE) мовна модель з трильйоном параметрів та 32 мільярдами активних параметрів на прохід. Оптимізована для агентних можливостей, включаючи просунуте використання інструментів, міркування та синтез коду."
  },
  "moonshotai/kimi-k2-0905": {
    "description": "Модель kimi-k2-0905-preview з довжиною контексту 256k володіє сильнішими можливостями агентного кодування, покращеною естетикою та практичністю фронтенд-коду, а також кращим розумінням контексту."
  },
  "moonshotai/kimi-k2-instruct-0905": {
    "description": "Модель kimi-k2-0905-preview з довжиною контексту 256k володіє сильнішими можливостями агентного кодування, покращеною естетикою та практичністю фронтенд-коду, а також кращим розумінням контексту."
  },
  "morph/morph-v3-fast": {
    "description": "Morph пропонує спеціалізовану ШІ-модель, яка швидко застосовує зміни до вашого існуючого коду, рекомендовані передовими моделями, такими як Claude або GPT-4o — швидкість понад 4500 токенів на секунду. Є завершальним етапом у робочому процесі ШІ-кодування. Підтримує 16k вхідних та 16k вихідних токенів."
  },
  "morph/morph-v3-large": {
    "description": "Morph пропонує спеціалізовану ШІ-модель, яка застосовує зміни до вашого існуючого коду, рекомендовані передовими моделями, такими як Claude або GPT-4o — швидкість понад 2500 токенів на секунду. Є завершальним етапом у робочому процесі ШІ-кодування. Підтримує 16k вхідних та 16k вихідних токенів."
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8B — це оновлена версія Nous Hermes 2, що містить останні внутрішні розроблені набори даних."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
    "description": "Llama 3.1 Nemotron 70B — це велика мовна модель, створена NVIDIA, призначена для підвищення корисності відповідей, генерованих LLM, на запити користувачів. Ця модель показала відмінні результати в таких бенчмарках, як Arena Hard, AlpacaEval 2 LC та GPT-4-Turbo MT-Bench, і станом на 1 жовтня 2024 року займає перше місце в усіх трьох автоматичних тестах на узгодження. Модель навчалася з використанням RLHF (зокрема, REINFORCE), Llama-3.1-Nemotron-70B-Reward та HelpSteer2-Preference на основі моделі Llama-3.1-70B-Instruct."
  },
  "nvidia/llama-3.1-nemotron-51b-instruct": {
    "description": "Унікальна мовна модель, що забезпечує неперевершену точність та ефективність."
  },
  "nvidia/llama-3.1-nemotron-70b-instruct": {
    "description": "Llama-3.1-Nemotron-70B — це велика мовна модель, розроблена NVIDIA, призначена для підвищення корисності відповідей, генерованих LLM."
  },
  "o1": {
    "description": "Зосереджена на високо рівневому висновуванні та вирішенні складних завдань, включаючи математичні та наукові завдання. Ідеально підходить для додатків, що вимагають глибокого розуміння контексту та керування робочими процесами."
  },
  "o1-mini": {
    "description": "o1-mini — це швидка та економічна модель висновування, розроблена для програмування, математики та наукових додатків. Модель має контекст 128K та термін знання до жовтня 2023 року."
  },
  "o1-preview": {
    "description": "Зосереджений на просунутому міркуванні та вирішенні складних завдань, включаючи завдання з математики та природничих наук. Відмінно підходить для додатків, яким потрібне глибоке розуміння контексту та автономні робочі процеси."
  },
  "o1-pro": {
    "description": "Моделі серії o1 навчені з використанням навчання з підкріпленням, здатні розмірковувати перед відповіддю та виконувати складні завдання міркування. Модель o1-pro використовує більше обчислювальних ресурсів для глибшого мислення, забезпечуючи постійно високу якість відповідей."
  },
  "o3": {
    "description": "o3 — це універсальна потужна модель, яка демонструє відмінні результати в різних областях. Вона встановлює нові стандарти для завдань математики, науки, програмування та візуального висновування. Вона також добре справляється з технічним письмом та дотриманням інструкцій. Користувачі можуть використовувати її для аналізу тексту, коду та зображень, вирішуючи складні багатоступінчасті завдання."
  },
  "o3-2025-04-16": {
    "description": "o3 — нова модель міркування OpenAI, що підтримує ввід зображень та тексту з виводом тексту, підходить для складних завдань, що вимагають широких універсальних знань."
  },
  "o3-deep-research": {
    "description": "o3-deep-research — це наша найпередовіша модель глибокого дослідження, розроблена для обробки складних багатоетапних дослідницьких завдань. Вона може шукати та узагальнювати інформацію з інтернету, а також отримувати доступ до ваших власних даних та використовувати їх через MCP-конектор."
  },
  "o3-mini": {
    "description": "o3-mini — це наша остання компактна модель висновування, що забезпечує високий рівень інтелекту при тих же витратах та затримках, що й o1-mini."
  },
  "o3-pro": {
    "description": "Модель o3-pro використовує більше обчислювальних ресурсів для глибшого мислення та завжди надає найкращі відповіді, підтримується тільки в Responses API."
  },
  "o3-pro-2025-06-10": {
    "description": "o3 Pro — нова модель міркування OpenAI, що підтримує ввід зображень та тексту з виводом тексту, підходить для складних завдань, що вимагають широких універсальних знань."
  },
  "o4-mini": {
    "description": "o4-mini — це наша новітня компактна модель серії o. Вона оптимізована для швидкого та ефективного висновування, демонструючи високу ефективність та продуктивність у завданнях кодування та візуалізації."
  },
  "o4-mini-2025-04-16": {
    "description": "o4-mini — модель міркування OpenAI, що підтримує ввід зображень та тексту з виводом тексту, підходить для складних завдань, що вимагають широких універсальних знань. Модель має контекст довжиною 200K."
  },
  "o4-mini-deep-research": {
    "description": "o4-mini-deep-research — це швидша та доступніша модель глибокого дослідження, ідеально підходить для обробки складних багатоетапних дослідницьких завдань. Вона може шукати та узагальнювати інформацію з інтернету, а також отримувати доступ до ваших власних даних та використовувати їх через MCP-конектор."
  },
  "open-codestral-mamba": {
    "description": "Codestral Mamba — це мовна модель Mamba 2, зосереджена на генерації коду, що забезпечує потужну підтримку для складних завдань за кодом та висновуванням."
  },
  "open-mistral-7b": {
    "description": "Mistral 7B — це компактна, але високопродуктивна модель, добре підходить для пакетної обробки та простих завдань, таких як класифікація та генерація тексту, що володіє хорошими можливостями висновування."
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemo — це 12B модель, розроблена у співпраці з Nvidia, що забезпечує видатні можливості висновування та кодування, легко інтегрована та замінювана."
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22B — це більша експертна модель, зосереджена на складних завданнях, що пропонує видатні можливості висновування та вищу пропускну здатність."
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7B — це розріджена експертна модель, що використовує кілька параметрів для підвищення швидкості висновування, підходить для обробки багатомовних та кодових завдань."
  },
  "openai/gpt-3.5-turbo": {
    "description": "Найпродуктивніша та найекономічніша модель серії GPT-3.5 від OpenAI, оптимізована для чат-цілей, але також добре працює в традиційних завданнях завершення."
  },
  "openai/gpt-3.5-turbo-instruct": {
    "description": "Модель з можливостями, аналогічними моделям епохи GPT-3. Сумісна з традиційними кінцевими точками завершення, а не з чат-завершеннями."
  },
  "openai/gpt-4-turbo": {
    "description": "gpt-4-turbo від OpenAI володіє обширними універсальними знаннями та експертними областями, дозволяючи слідувати складним інструкціям на природній мові та точно вирішувати складні завдання. Дата відсікання знань — квітень 2023 року, вікно контексту — 128 000 токенів."
  },
  "openai/gpt-4.1": {
    "description": "GPT 4.1 — флагманська модель OpenAI для складних завдань. Відмінно підходить для міждисциплінарного вирішення проблем."
  },
  "openai/gpt-4.1-mini": {
    "description": "GPT 4.1 mini збалансована за інтелектом, швидкістю та вартістю, що робить її привабливою моделлю для багатьох сценаріїв."
  },
  "openai/gpt-4.1-nano": {
    "description": "GPT-4.1 nano — найшвидша та економічна модель GPT 4.1."
  },
  "openai/gpt-4o": {
    "description": "GPT-4o від OpenAI володіє обширними універсальними знаннями та експертними областями, здатний слідувати складним інструкціям на природній мові та точно вирішувати складні завдання. Забезпечує продуктивність, порівнянну з GPT-4 Turbo, при вищій швидкості та меншій вартості API."
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o mini від OpenAI — їхня найпередовіша та економічна компактна модель. Мультимодальна (приймає текст або зображення на вхід та видає текст), розумніша, ніж gpt-3.5-turbo, при такій самій швидкості."
  },
  "openai/gpt-5": {
    "description": "GPT-5 — флагманська мовна модель OpenAI, що демонструє видатні здібності в складних міркуваннях, обширних знаннях про реальний світ, завданнях з інтенсивним кодуванням та багатоступінчастих агентних завданнях."
  },
  "openai/gpt-5-mini": {
    "description": "GPT-5 mini — оптимізована за вартістю модель з відмінною продуктивністю в завданнях міркувань та діалогів. Забезпечує найкращий баланс швидкості, вартості та можливостей."
  },
  "openai/gpt-5-nano": {
    "description": "GPT-5 nano — високопродуктивна модель, що відмінно справляється з простими інструкціями та завданнями класифікації."
  },
  "openai/gpt-oss-120b": {
    "description": "Надзвичайно потужна універсальна великомасштабна мовна модель з сильними та керованими можливостями міркування."
  },
  "openai/gpt-oss-20b": {
    "description": "Компактна модель з відкритими вагами, оптимізована для низької затримки та обмежених ресурсів середовищ, включаючи локальне та периферійне розгортання."
  },
  "openai/o1": {
    "description": "o1 від OpenAI — флагманська модель висновування, розроблена для складних завдань, що вимагають глибокого аналізу. Забезпечує потужні можливості міркування та підвищену точність для багатоступінчастих завдань."
  },
  "openai/o1-mini": {
    "description": "o1-mini — це швидка та економічна модель висновування, розроблена для програмування, математики та наукових додатків. Модель має контекст 128K та термін знання до жовтня 2023 року."
  },
  "openai/o1-preview": {
    "description": "o1 — це нова модель висновування від OpenAI, придатна для складних завдань, що вимагають обширних загальних знань. Модель має контекст 128K та термін знання до жовтня 2023 року."
  },
  "openai/o3": {
    "description": "o3 від OpenAI — найпотужніша модель висновування, що встановлює нові стандарти в кодуванні, математиці, науці та візуальному сприйнятті. Відмінно справляється зі складними запитами, що вимагають багатогранного аналізу, особливо в обробці зображень, діаграм та графіків."
  },
  "openai/o3-mini": {
    "description": "o3-mini — остання компактна модель висновування OpenAI, що забезпечує високий інтелект при тих же витратах та затримках, що й o1-mini."
  },
  "openai/o3-mini-high": {
    "description": "o3-mini high — версія з високим рівнем висновування, яка забезпечує високий інтелект при тих же цілях за вартістю та затримкою, що й o1-mini."
  },
  "openai/o4-mini": {
    "description": "o4-mini від OpenAI забезпечує швидке та економічне висновування з видатною продуктивністю для свого розміру, особливо в математиці (найкращі результати в тесті AIME), кодуванні та візуальних завданнях."
  },
  "openai/o4-mini-high": {
    "description": "o4-mini версія з високим рівнем висновування, оптимізована для швидкого та ефективного висновування, демонструє високу ефективність та продуктивність у завданнях кодування та візуалізації."
  },
  "openai/text-embedding-3-large": {
    "description": "Найпродуктивніша модель вбудовування OpenAI для завдань англійською та іншими мовами."
  },
  "openai/text-embedding-3-small": {
    "description": "Покращена та більш продуктивна версія моделі вбудовування ada від OpenAI."
  },
  "openai/text-embedding-ada-002": {
    "description": "Традиційна модель текстового вбудовування OpenAI."
  },
  "openrouter/auto": {
    "description": "Залежно від довжини контексту, теми та складності ваш запит буде відправлено в Llama 3 70B Instruct, Claude 3.5 Sonnet (саморегульований) або GPT-4o."
  },
  "perplexity/sonar": {
    "description": "Легковаговий продукт Perplexity з можливістю пошуку, швидший та дешевший, ніж Sonar Pro."
  },
  "perplexity/sonar-pro": {
    "description": "Флагманський продукт Perplexity з можливістю пошуку, що підтримує розширені запити та наступні дії."
  },
  "perplexity/sonar-reasoning": {
    "description": "Модель, орієнтована на міркування, що виводить ланцюжки думок (CoT) у відповідях та надає докладні пояснення з пошуковою підтримкою."
  },
  "perplexity/sonar-reasoning-pro": {
    "description": "Просунута модель, орієнтована на міркування, що виводить ланцюжки думок (CoT) у відповідях, з покращеними можливостями пошуку та кількома пошуковими запитами на кожен запит для комплексних пояснень."
  },
  "phi3": {
    "description": "Phi-3 — це легковагова відкрита модель, випущена Microsoft, придатна для ефективної інтеграції та масштабного висновування знань."
  },
  "phi3:14b": {
    "description": "Phi-3 — це легковагова відкрита модель, випущена Microsoft, придатна для ефективної інтеграції та масштабного висновування знань."
  },
  "pixtral-12b-2409": {
    "description": "Модель Pixtral демонструє потужні здібності в завданнях графіків та розуміння зображень, питань та відповідей за документами, мультимодального висновування та дотримання інструкцій, здатна обробляти зображення в природній роздільній здатності та співвідношенні сторін, а також обробляти довільну кількість зображень у контекстному вікні довжиною до 128K токенів."
  },
  "pixtral-large-latest": {
    "description": "Pixtral Large — це відкрита мультимодальна модель з 1240 мільярдами параметрів, заснована на Mistral Large 2. Це друга модель у нашій мультимодальній родині, що демонструє передові рівні розуміння зображень."
  },
  "pro-128k": {
    "description": "Spark Pro 128K оснащений величезною здатністю обробки контексту, здатною обробляти до 128K контекстної інформації, що робить його особливо придатним для аналізу довгих текстів та обробки довгострокових логічних зв'язків, забезпечуючи плавну та послідовну логіку та різноманітну підтримку посилань у складних текстових комунікаціях."
  },
  "pro-deepseek-r1": {
    "description": "Спеціалізована модель для корпоративного обслуговування, підтримує паралельну обробку запитів."
  },
  "pro-deepseek-v3": {
    "description": "Спеціалізована модель для корпоративного обслуговування, підтримує паралельну обробку запитів."
  },
  "qvq-72b-preview": {
    "description": "Модель QVQ, розроблена командою Qwen, є експериментальною дослідницькою моделлю, зосередженою на підвищенні візуальних здібностей міркування, особливо в галузі математичного міркування."
  },
  "qvq-max": {
    "description": "Модель візуального міркування Tongyi Qianwen QVQ, що підтримує візуальний ввід та вивід ланцюжків міркувань, демонструє посилені можливості в математиці, програмуванні, візуальному аналізі, творчості та загальних завданнях."
  },
  "qvq-plus": {
    "description": "Модель візуального міркування. Підтримує візуальний ввід та вивід ланцюжків міркувань, версія plus, випущена після моделі qvq-max. Порівняно з qvq-max, серія qvq-plus забезпечує вищу швидкість міркувань та більш збалансоване співвідношення ефективності та витрат."
  },
  "qwen-3-32b": {
    "description": "Qwen 3 32B: модель серії Qwen з відмінною продуктивністю в багатомовних та програмних завданнях, придатна для середньо-масштабного промислового застосування."
  },
  "qwen-3-coder-480b": {
    "description": "Qwen 3 Coder 480B: модель з довгим контекстом, орієнтована на генерацію коду та виконання складних програмних завдань."
  },
  "qwen-coder-plus": {
    "description": "Модель коду Tongyi Qianwen."
  },
  "qwen-coder-turbo": {
    "description": "Модель коду Tongyi Qianwen."
  },
  "qwen-coder-turbo-latest": {
    "description": "Модель коду Tongyi Qwen."
  },
  "qwen-flash": {
    "description": "Серія моделей «通义千问» володіє найбільшою швидкістю та надзвичайно низькою вартістю, підходить для простих завдань."
  },
  "qwen-image": {
    "description": "Qwen-Image — це універсальна модель генерації зображень, що підтримує різні художні стилі. Вона особливо добре справляється з рендерингом складного тексту, зокрема з відображенням китайських та англійських написів. Модель підтримує багаторядкову верстку, генерацію тексту на рівні абзаців та тонку проробку деталей, що дозволяє створювати складні комбіновані макети із зображеннями та текстом."
  },
  "qwen-image-edit": {
    "description": "Qwen Image Edit — це модель перетворення зображень, що підтримує редагування та зміну зображень на основі вхідного зображення та текстових підказок, здатна точно налаштовувати та творчо перетворювати вихідне зображення відповідно до вимог користувача."
  },
  "qwen-long": {
    "description": "Qwen — це надмасштабна мовна модель, що підтримує довгий контекст тексту та діалогові функції на основі довгих документів та кількох документів."
  },
  "qwen-math-plus": {
    "description": "Модель Tongyi Qianwen, спеціально призначена для вирішення математичних завдань."
  },
  "qwen-math-plus-latest": {
    "description": "Математична модель Tongyi Qwen, спеціально розроблена для вирішення математичних завдань."
  },
  "qwen-math-turbo": {
    "description": "Модель Tongyi Qianwen, спеціально призначена для вирішення математичних завдань."
  },
  "qwen-math-turbo-latest": {
    "description": "Математична модель Tongyi Qwen, спеціально розроблена для вирішення математичних завдань."
  },
  "qwen-max": {
    "description": "Qwen-Max — це мовна модель масштабу трильйона, що підтримує вхідні дані на різних мовах, включаючи китайську та англійську. Наразі це API, яке стоїть за продуктовою версією Qwen 2.5."
  },
  "qwen-omni-turbo": {
    "description": "Серія моделей Qwen-Omni підтримує введення даних різних модальностей, включаючи відео, аудіо, зображення та текст, а також виведення аудіо та тексту."
  },
  "qwen-plus": {
    "description": "Покращена версія Qwen-Turbo, що підтримує вхідні дані на різних мовах, включаючи китайську та англійську."
  },
  "qwen-turbo": {
    "description": "Модель Tongyi Qianwen Turbo надалі не оновлюватиметься; рекомендується замінити її на Tongyi Qianwen Flash. Tongyi Qianwen — масштабна мовна модель, що підтримує ввід китайською, англійською та іншими мовами."
  },
  "qwen-vl-chat-v1": {
    "description": "Qwen VL підтримує гнучкі способи взаємодії, включаючи багаторазові зображення, багаторазові питання та відповіді, а також творчі здібності."
  },
  "qwen-vl-max": {
    "description": "Надмасштабна візуально-мовна модель Tongyi Qianwen. Порівняно з посиленою версією додатково покращено здібності візуального міркування та дотримання інструкцій, забезпечується вищий рівень візуального сприйняття та когнітивних функцій."
  },
  "qwen-vl-max-latest": {
    "description": "Супер масштабна візуально-мовна модель Tongyi Qianwen. Порівняно з покращеною версією, ще більше підвищує здібності візуального висновування та дотримання інструкцій, забезпечуючи вищий рівень візуального сприйняття та когнітивних здібностей."
  },
  "qwen-vl-ocr": {
    "description": "Спеціалізована модель OCR Tongyi Qianwen, орієнтована на вилучення тексту з документів, таблиць, тестів, рукописного тексту та інших типів зображень. Підтримує розпізнавання безлічі мов, включаючи китайську, англійську, французьку, японську, корейську, німецьку, російську, італійську, в'єтнамську та арабську."
  },
  "qwen-vl-plus": {
    "description": "Посилена версія масштабної візуально-мовної моделі Tongyi Qianwen. Значно покращено здатність розпізнавання деталей та тексту, підтримується роздільна здатність понад мільйон пікселів та зображення з довільним співвідношенням сторін."
  },
  "qwen-vl-plus-latest": {
    "description": "Покращена версія масштабної візуально-мовної моделі Tongyi Qianwen. Значно підвищує здатність розпізнавання деталей та тексту, підтримує роздільну здатність понад мільйон пікселів та зображення з довільним співвідношенням сторін."
  },
  "qwen-vl-v1": {
    "description": "Ініціалізована мовною моделлю Qwen-7B, додана модель зображення, попередньо навчена модель з роздільною здатністю вхідного зображення 448."
  },
  "qwen/qwen-2-7b-instruct": {
    "description": "Qwen2 — це нова серія великих мовних моделей Qwen. Qwen2 7B — це модель на основі трансформера, яка демонструє відмінні результати в розумінні мови, багатомовних здібностях, програмуванні, математиці та логічному міркуванні."
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2 — це нова серія великих мовних моделей з сильнішими можливостями розуміння та генерації."
  },
  "qwen/qwen-2-vl-72b-instruct": {
    "description": "Qwen2-VL — це остання ітерація моделі Qwen-VL, що досягла передових результатів у бенчмарках візуального розуміння, включаючи MathVista, DocVQA, RealWorldQA та MTVQA. Qwen2-VL може розуміти відео тривалістю понад 20 хвилин для високоякісного відеозапиту, діалогу та створення контенту. Вона також володіє складними здібностями до міркування та прийняття рішень, може інтегруватися з мобільними пристроями, роботами та виконувати автоматичні операції на основі візуального середовища та текстових інструкцій. Окрім англійської та китайської, Qwen2-VL тепер також підтримує розуміння тексту на різних мовах у зображеннях, включаючи більшість європейських мов, японську, корейську, арабську та в'єтнамську."
  },
  "qwen/qwen-2.5-72b-instruct": {
    "description": "Qwen2.5-72B-Instruct — це одна з останніх серій великих мовних моделей, випущених Alibaba Cloud. Ця модель 72B демонструє значні покращення в області кодування та математики. Модель також підтримує безліч мов, охоплюючи понад 29 мов, включаючи китайську та англійську. Вона значно покращила виконання інструкцій, розуміння структурованих даних та генерацію структурованих вихідних даних (особливо JSON)."
  },
  "qwen/qwen2.5-32b-instruct": {
    "description": "Qwen2.5-32B-Instruct — це одна з останніх серій великих мовних моделей, випущених Alibaba Cloud. Ця модель 32B демонструє значні покращення в області кодування та математики. Модель підтримує безліч мов, охоплюючи понад 29 мов, включаючи китайську та англійську. Вона значно покращила виконання інструкцій, розуміння структурованих даних та генерацію структурованих вихідних даних (особливо JSON)."
  },
  "qwen/qwen2.5-7b-instruct": {
    "description": "LLM, орієнтована на китайську та англійську мови, що охоплює області мови, програмування, математики, міркувань та ін."
  },
  "qwen/qwen2.5-coder-32b-instruct": {
    "description": "Сучасна LLM, що підтримує генерацію коду, міркування та виправлення, охоплює основні мови програмування."
  },
  "qwen/qwen2.5-coder-7b-instruct": {
    "description": "Потужна середня модель коду, що підтримує контекст довжиною 32K, спеціалізується на багатомовному програмуванні."
  },
  "qwen/qwen3-14b": {
    "description": "Qwen3-14B — це компактна мовна модель з 14 мільярдами параметрів із серії Qwen3, спеціально розроблена для складного висновування та ефективного діалогу. Вона підтримує безшовне перемикання між режимом розмірковування для завдань, таких як математика, програмування та логічний висновок, та не розмірковуючим режимом для загального діалогу. Ця модель була донавчена для виконання інструкцій, використання інструментів агентів, креативного письма та багатомовних завдань на понад 100 мовах та діалектах. Вона спочатку обробляє контекст у 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-14b:free": {
    "description": "Qwen3-14B — це компактна мовна модель з 14 мільярдами параметрів із серії Qwen3, спеціально розроблена для складного висновування та ефективного діалогу. Вона підтримує безшовне перемикання між режимом розмірковування для завдань, таких як математика, програмування та логічний висновок, та не розмірковуючим режимом для загального діалогу. Ця модель була донавчена для виконання інструкцій, використання інструментів агентів, креативного письма та багатомовних завдань на понад 100 мовах та діалектах. Вона спочатку обробляє контекст у 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-235b-a22b": {
    "description": "Qwen3-235B-A22B — це модель змішаної експертизи (MoE) з 235 мільярдами параметрів, розроблена Qwen, яка активує 22 мільярди параметрів за один прохід. Вона підтримує безшовне перемикання між режимом розмірковування для складного висновування, математики та кодування та не розмірковуючим режимом для загальної діалогової ефективності. Ця модель демонструє потужні здібності висновування, багатомовну підтримку (понад 100 мов та діалектів), високу точність виконання інструкцій та виклик інструментів агентів. Вона спочатку обробляє контекстне вікно в 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-235b-a22b:free": {
    "description": "Qwen3-235B-A22B — це модель змішаної експертизи (MoE) з 235 мільярдами параметрів, розроблена Qwen, яка активує 22 мільярди параметрів за один прохід. Вона підтримує безшовне перемикання між режимом розмірковування для складного висновування, математики та кодування та не розмірковуючим режимом для загальної діалогової ефективності. Ця модель демонструє потужні здібності висновування, багатомовну підтримку (понад 100 мов та діалектів), високу точність виконання інструкцій та виклик інструментів агентів. Вона спочатку обробляє контекстне вікно в 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-30b-a3b": {
    "description": "Qwen3 — це нове покоління серії великих мовних моделей Qwen, що володіє архітектурою змішаної експертизи (MoE), яке демонструє видатні результати в області висновування, багатомовної підтримки та складних завдань. Його унікальна здатність безшовно перемикатися між режимами розмірковування для складного висновування та не розмірковуючим режимом для ефективного діалогу забезпечує багатофункціональну та високоякісну продуктивність.\n\nQwen3 значно перевершує попередні моделі, такі як QwQ та Qwen2.5, пропонуючи видатні здібності в математиці, програмуванні, логічному висновку, креативному письмі та інтерактивному діалозі. Варіант Qwen3-30B-A3B містить 30,5 мільярда параметрів (3,3 мільярда активованих параметрів), 48 шарів, 128 експертів (по 8 активованих для кожного завдання) та підтримує контекст до 131K токенів (з використанням YaRN), встановлюючи новий стандарт для відкритих моделей."
  },
  "qwen/qwen3-30b-a3b:free": {
    "description": "Qwen3 — це нове покоління серії великих мовних моделей Qwen, що володіє архітектурою змішаної експертизи (MoE), яке демонструє видатні результати в області висновування, багатомовної підтримки та складних завдань. Його унікальна здатність безшовно перемикатися між режимами розмірковування для складного висновування та не розмірковуючим режимом для ефективного діалогу забезпечує багатофункціональну та високоякісну продуктивність.\n\nQwen3 значно перевершує попередні моделі, такі як QwQ та Qwen2.5, пропонуючи видатні здібності в математиці, програмуванні, логічному висновку, креативному письмі та інтерактивному діалозі. Варіант Qwen3-30B-A3B містить 30,5 мільярда параметрів (3,3 мільярда активованих параметрів), 48 шарів, 128 експертів (по 8 активованих для кожного завдання) та підтримує контекст до 131K токенів (з використанням YaRN), встановлюючи новий стандарт для відкритих моделей."
  },
  "qwen/qwen3-32b": {
    "description": "Qwen3-32B — це компактна мовна модель з 32 мільярдами параметрів із серії Qwen3, оптимізована для складного висновування та ефективного діалогу. Вона підтримує безшовне перемикання між режимом розмірковування для завдань, таких як математика, програмування та логічний висновок, та не розмірковуючим режимом для швидшого загального діалогу. Ця модель демонструє високу продуктивність у виконанні інструкцій, використанні інструментів агентів, креативному письмі та багатомовних завданнях на понад 100 мовах та діалектах. Вона спочатку обробляє контекст у 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-32b:free": {
    "description": "Qwen3-32B — це компактна мовна модель з 32 мільярдами параметрів із серії Qwen3, оптимізована для складного висновування та ефективного діалогу. Вона підтримує безшовне перемикання між режимом розмірковування для завдань, таких як математика, програмування та логічний висновок, та не розмірковуючим режимом для швидшого загального діалогу. Ця модель демонструє високу продуктивність у виконанні інструкцій, використанні інструментів агентів, креативному письмі та багатомовних завданнях на понад 100 мовах та діалектах. Вона спочатку обробляє контекст у 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen/qwen3-8b:free": {
    "description": "Qwen3-8B — це компактна мовна модель з 8 мільярдами параметрів із серії Qwen3, спеціально розроблена для завдань, що вимагають інтенсивного висновування, та ефективного діалогу. Вона підтримує безшовне перемикання між режимом розмірковування для математики, програмування та логічного висновку та не розмірковуючим режимом для загального діалогу. Ця модель була донавчена для виконання інструкцій, інтеграції агентів, креативного письма та багатомовного використання на понад 100 мовах та діалектах. Вона спочатку підтримує контекстне вікно в 32K токенів та може бути розширена до 131K токенів за допомогою YaRN."
  },
  "qwen2": {
    "description": "Qwen2 — це нове покоління великомасштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних додатків."
  },
  "qwen2.5": {
    "description": "Qwen2.5 — це нове покоління масштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних потреб додатків."
  },
  "qwen2.5-14b-instruct": {
    "description": "Модель Tongyi Qwen 2.5 з відкритим вихідним кодом об'ємом 14B."
  },
  "qwen2.5-14b-instruct-1m": {
    "description": "Модель Qwen2.5 з відкритим вихідним кодом об'ємом 72B."
  },
  "qwen2.5-32b-instruct": {
    "description": "Модель Tongyi Qwen 2.5 з відкритим вихідним кодом об'ємом 32B."
  },
  "qwen2.5-72b-instruct": {
    "description": "Модель Tongyi Qwen 2.5 з відкритим вихідним кодом об'ємом 72B."
  },
  "qwen2.5-7b-instruct": {
    "description": "Модель Tongyi Qwen 2.5 з відкритим вихідним кодом об'ємом 7B."
  },
  "qwen2.5-coder-1.5b-instruct": {
    "description": "Відкрита версія моделі коду Qwen."
  },
  "qwen2.5-coder-14b-instruct": {
    "description": "Відкрита версія моделі коду Tongyi Qianwen."
  },
  "qwen2.5-coder-32b-instruct": {
    "description": "Відкрита версія моделі коду Tongyi Qianwen."
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "Відкрита версія моделі коду Tongyi Qwen."
  },
  "qwen2.5-coder-instruct": {
    "description": "Qwen2.5-Coder — це новітня спеціалізована велика мовна модель для роботи з кодом у серії Qwen (раніше відома як CodeQwen)."
  },
  "qwen2.5-instruct": {
    "description": "Qwen2.5 — це новітня серія великих мовних моделей Qwen. Для Qwen2.5 ми випустили кілька базових мовних моделей та моделей з тонким налаштуванням інструкцій, з діапазоном параметрів від 500 мільйонів до 7,2 мільярда."
  },
  "qwen2.5-math-1.5b-instruct": {
    "description": "Модель Qwen-Math володіє видатними здібностями до вирішення математичних завдань."
  },
  "qwen2.5-math-72b-instruct": {
    "description": "Модель Qwen-Math з потужними здібностями вирішення математичних завдань."
  },
  "qwen2.5-math-7b-instruct": {
    "description": "Модель Qwen-Math з потужними здібностями вирішення математичних завдань."
  },
  "qwen2.5-omni-7b": {
    "description": "Моделі серії Qwen-Omni підтримують введення даних у різних модальностях, включаючи відео, аудіо, зображення та текст, та виводять аудіо та текст."
  },
  "qwen2.5-vl-32b-instruct": {
    "description": "Моделі серії Qwen2.5-VL демонструють підвищений рівень інтелекту, практичності та адаптивності, що забезпечує їхню чудову продуктивність у таких сценаріях, як природні діалоги, створення контенту, надання експертних знань та розробка коду. Версія 32B оптимізована з використанням технологій навчання з підкріпленням, що порівняно з іншими моделями серії Qwen2.5 VL забезпечує більш відповідний людським перевагам стиль виводу, здатність до вирішення складних математичних завдань, а також детальне розуміння та аналіз зображень."
  },
  "qwen2.5-vl-72b-instruct": {
    "description": "Покращення слідування інструкціям, математики, вирішення завдань та коду, покращення здатності розпізнавання об'єктів, підтримка точного позиціонування візуальних елементів у різних форматах, підтримка розуміння довгих відеофайлів (максимум 10 хвилин) та локалізація подій на рівні секунд, здатність розуміти послідовність часу та швидкість, підтримка керування агентами ОС або мобільними пристроями на основі аналітичних та позиційних можливостей, висока здатність вилучення ключової інформації та виводу у форматі Json. Ця версія є 72B, найпотужнішою в серії."
  },
  "qwen2.5-vl-7b-instruct": {
    "description": "Покращення слідування інструкціям, математики, вирішення завдань та коду, покращення здатності розпізнавання об'єктів, підтримка точного позиціонування візуальних елементів у різних форматах, підтримка розуміння довгих відеофайлів (максимум 10 хвилин) та локалізація подій на рівні секунд, здатність розуміти послідовність часу та швидкість, підтримка керування агентами ОС або мобільними пристроями на основі аналітичних та позиційних можливостей, висока здатність вилучення ключової інформації та виводу у форматі Json. Ця версія є 72B, найпотужнішою в серії."
  },
  "qwen2.5-vl-instruct": {
    "description": "Qwen2.5-VL - це остання версія візуально-мовної моделі в сімействі моделей Qwen."
  },
  "qwen2.5:0.5b": {
    "description": "Qwen2.5 — це нове покоління масштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних потреб додатків."
  },
  "qwen2.5:1.5b": {
    "description": "Qwen2.5 — це нове покоління масштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних потреб додатків."
  },
  "qwen2.5:72b": {
    "description": "Qwen2.5 — це нове покоління масштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних потреб додатків."
  },
  "qwen2:0.5b": {
    "description": "Qwen2 — це нове покоління великомасштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних додатків."
  },
  "qwen2:1.5b": {
    "description": "Qwen2 — це нове покоління великомасштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних додатків."
  },
  "qwen2:72b": {
    "description": "Qwen2 — це нове покоління великомасштабної мовної моделі від Alibaba, що забезпечує відмінні результати для різноманітних додатків."
  },
  "qwen3": {
    "description": "Qwen3 — це нове покоління масштабної мовної моделі від Alibaba, яка підтримує різноманітні потреби додатків з видатною продуктивністю."
  },
  "qwen3-0.6b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-1.7b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-14b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-235b-a22b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-235b-a22b-instruct-2507": {
    "description": "Відкрита модель на базі Qwen3 у не розмірковучому режимі, з невеликими покращеннями в творчих здібностях та безпеці порівняно з попередньою версією (Tongyi Qianwen 3-235B-A22B)."
  },
  "qwen3-235b-a22b-thinking-2507": {
    "description": "Відкрита модель на базі Qwen3 у режимі розмірковування, з суттєвими покращеннями в логічних здібностях, універсальності, розширенні знань та творчості порівняно з попередньою версією (Tongyi Qianwen 3-235B-A22B), призначена для складних завдань з інтенсивним міркуванням."
  },
  "qwen3-30b-a3b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-30b-a3b-instruct-2507": {
    "description": "Порівняно з попередньою версією (Qwen3-30B-A3B) значно покращено загальні здібності англійською, китайською та іншими мовами. Спеціальна оптимізація для суб'єктивних та відкритих завдань, що помітно краще відповідає перевагам користувачів та дозволяє надавати більш корисні відповіді."
  },
  "qwen3-30b-a3b-thinking-2507": {
    "description": "Відкрита модель у режимі розмірковувань на базі Qwen3, яка порівняно з попередньою версією (Tongyi Qianwen 3-30B-A3B) значно покращила логічні здібності, загальні навички, знання та творчі можливості. Підходить для складних завдань з інтенсивним міркуванням."
  },
  "qwen3-32b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-4b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-8b": {
    "description": "Qwen3 — це нове покоління моделі Qwen зі значно покращеними можливостями, що досягли провідних позицій у галузі висновування, універсальності, агентів та багатомовності, а також підтримує перемикання режимів розмірковування."
  },
  "qwen3-coder-30b-a3b-instruct": {
    "description": "Відкрита версія моделі програмування Tongyi Qianwen. Новітня qwen3-coder-30b-a3b-instruct — це модель генерації коду на базі Qwen3, що володіє потужними можливостями Coding Agent, добре справляється з викликом інструментів та взаємодією з оточенням, здатна до автономного програмування та демонструє видатні здібності в кодуванні при збереженні універсальності."
  },
  "qwen3-coder-480b-a35b-instruct": {
    "description": "Відкрита версія моделі коду Tongyi Qianwen. Остання модель qwen3-coder-480b-a35b-instruct заснована на Qwen3 та володіє потужними можливостями Coding Agent, добре справляється з викликом інструментів та взаємодією з оточенням, забезпечуючи автономне програмування з видатними кодовими та універсальними здібностями."
  },
  "qwen3-coder-flash": {
    "description": "Модель коду Tongyi Qianwen. Остання серія моделей Qwen3-Coder заснована на Qwen3 та представляє собою модель генерації коду з потужними можливостями Coding Agent, відмінно справляється з викликом інструментів та взаємодією з оточенням, здатна до автономного програмування, володіє видатними кодувальними та універсальними здібностями."
  },
  "qwen3-coder-plus": {
    "description": "Модель коду Tongyi Qianwen. Остання серія моделей Qwen3-Coder заснована на Qwen3 та представляє собою модель генерації коду з потужними можливостями Coding Agent, відмінно справляється з викликом інструментів та взаємодією з оточенням, здатна до автономного програмування, володіє видатними кодувальними та універсальними здібностями."
  },
  "qwen3-coder:480b": {
    "description": "Високопродуктивна модель з довгим контекстом від Alibaba, призначена для агентських та кодувальних завдань."
  },
  "qwen3-max": {
    "description": "Серія моделей Tongyi Qianwen 3 Max значно покращена порівняно з серією 2.5 у плані універсальних можливостей: значно посилені здібності розуміння тексту китайською та англійською мовами, слідування складним інструкціям, виконання суб'єктивних відкритих завдань, багатомовність та виклик інструментів; зменшено кількість помилок, пов'язаних з галюцинаціями знань. Остання версія моделі qwen3-max отримала спеціальне оновлення в області програмування агентів та виклику інструментів порівняно з версією qwen3-max-preview. Випущена офіційна версія досягла рівня SOTA у своїй області та адаптована під більш складні сценарії використання агентів."
  },
  "qwen3-next-80b-a3b-instruct": {
    "description": "Нова генерація відкритої моделі без режиму мислення на базі Qwen3, яка порівняно з попередньою версією (通义千问3-235B-A22B-Instruct-2507) володіє покращеними здібностями розуміння китайського тексту, посиленими логічними міркуваннями та кращими результатами в завданнях генерації тексту."
  },
  "qwen3-next-80b-a3b-thinking": {
    "description": "Нова генерація відкритої моделі з режимом мислення на базі Qwen3, яка порівняно з попередньою версією (通义千问3-235B-A22B-Thinking-2507) демонструє покращене слідування інструкціям та більш лаконічні відповіді моделі."
  },
  "qwen3-omni-flash": {
    "description": "Модель Qwen-Omni приймає комбінований ввід у вигляді тексту, зображень, аудіо та відео, та генерує відповіді в текстовій або голосовій формі. Підтримує різні реалістичні голосові тембри, багатомовний та діалектний вивід, підходить для завдань текстової творчості, візуального розпізнавання, голосових помічників та інших сценаріїв."
  },
  "qwen3-vl-235b-a22b-instruct": {
    "description": "Qwen3 VL 235B A22B в режимі без розмірковування (Instruct), призначений для сценаріїв з простими інструкціями, зберігаючи при цьому потужні здібності візуального розуміння."
  },
  "qwen3-vl-235b-a22b-thinking": {
    "description": "Qwen3 VL 235B A22B в режимі розмірковування (відкрита версія), призначений для складних завдань з інтенсивним виводом та розумінням довгих відео, забезпечуючи передові можливості візуального та текстового розмірковування."
  },
  "qwen3-vl-30b-a3b-instruct": {
    "description": "Qwen3 VL 30B в режимі без розмірковування (Instruct), орієнтований на стандартні сценарії слідування інструкціям, забезпечуючи високі мультимодальні здібності розуміння та генерації."
  },
  "qwen3-vl-30b-a3b-thinking": {
    "description": "Відкрита версія Qwen-VL надає можливості візуального розуміння та генерації тексту, підтримує взаємодію з агентами, візуальне кодування, просторове сприйняття, розуміння довгих відео та глибоке мислення, а також володіє покращеними можливостями розпізнавання тексту та багатомовної підтримки в складних сценаріях."
  },
  "qwen3-vl-8b-instruct": {
    "description": "Qwen3 VL 8B в режимі без розмірковування (Instruct), підходить для стандартних завдань мультимодальної генерації та розпізнавання."
  },
  "qwen3-vl-8b-thinking": {
    "description": "Qwen3 VL 8B в режимі розмірковування, призначений для легковагових мультимодальних завдань виводу та взаємодії, зберігаючи здатність до розуміння довгого контексту."
  },
  "qwen3-vl-flash": {
    "description": "Qwen3 VL Flash — легковагова версія з високою швидкістю виводу, підходить для сценаріїв з чутливістю до затримки або масовими запитами."
  },
  "qwen3-vl-plus": {
    "description": "Tongyi Qianwen VL — текстова генеративна модель з можливостями візуального (зображувального) розуміння. Вона не тільки здатна виконувати OCR (розпізнавання тексту на зображеннях), але й проводити подальше узагальнення та розмірковування, наприклад, витягувати атрибути з фотографій товарів або вирішувати завдання за зображеннями навчальних завдань."
  },
  "qwq": {
    "description": "QwQ — це експериментальна дослідницька модель, зосереджена на підвищенні можливостей виводу ШІ."
  },
  "qwq-32b": {
    "description": "Модель виводу QwQ, навчена на моделі Qwen2.5-32B, значно покращила свої здібності виводу завдяки навчанню з підкріпленням. Основні показники моделі, такі як математичний код та інші ключові метрики (AIME 24/25, LiveCodeBench), а також деякі загальні показники (IFEval, LiveBench та ін.) досягли рівня DeepSeek-R1 повною мірою, при цьому всі показники значно перевищують аналогічні показники DeepSeek-R1-Distill-Qwen-32B, також заснованої на Qwen2.5-32B."
  },
  "qwq-32b-preview": {
    "description": "Модель QwQ — це експериментальна дослідницька модель, розроблена командою Qwen, зосереджена на покращенні можливостей виводу ШІ."
  },
  "qwq-plus": {
    "description": "Модель розмірковувань QwQ, навчена на базі Qwen2.5, значно покращила здібності до розмірковування за допомогою навчання з підкріпленням. Ключові показники моделі з математики та коду (AIME 24/25, LiveCodeBench), а також деякі загальні показники (IFEval, LiveBench та ін.) досягли рівня повної версії DeepSeek-R1."
  },
  "qwq_32b": {
    "description": "Модель виводу середнього розміру із серії Qwen. На відміну від традиційних моделей, оптимізованих для інструкцій, QwQ, володіючи здібностями до розмірковування та виводу, може значно підвищити продуктивність у завданнях, особливо при вирішенні складних завдань."
  },
  "r1-1776": {
    "description": "R1-1776 — це версія моделі DeepSeek R1, що пройшла донавчання, яка надає неперевірену, неупереджену фактичну інформацію."
  },
  "solar-mini": {
    "description": "Solar Mini — це компактна LLM, яка перевершує GPT-3.5, володіє потужними багатомовними можливостями, підтримує англійську та корейську мови, пропонуючи ефективне та компактне рішення."
  },
  "solar-mini-ja": {
    "description": "Solar Mini (Ja) розширює можливості Solar Mini, зосереджуючись на японській мові, при цьому підтримуючи високу ефективність та видатні результати у використанні англійської та корейської мов."
  },
  "solar-pro": {
    "description": "Solar Pro — це високоінтелектуальна LLM, випущена Upstage, зосереджена на здатності слідувати інструкціям на одному GPU, з оцінкою IFEval понад 80. Наразі підтримує англійську мову, офіційна версія запланована на листопад 2024 року, з розширенням мовної підтримки та довжини контексту."
  },
  "sonar": {
    "description": "Легковаговий продукт пошуку на основі контексту, швидший та дешевший, ніж Sonar Pro."
  },
  "sonar-deep-research": {
    "description": "Глибоке дослідження проводить всебічні експертні дослідження та зводить їх у доступні та практичні звіти."
  },
  "sonar-pro": {
    "description": "Розширений продукт пошуку, що підтримує контекст пошуку, складні запити та наступні дії."
  },
  "sonar-reasoning": {
    "description": "Новий API продукт, підтримуваний моделлю виводу DeepSeek."
  },
  "sonar-reasoning-pro": {
    "description": "Новий API продукт, підтримуваний моделлю виводу DeepSeek."
  },
  "stable-diffusion-3-medium": {
    "description": "Остання велика модель генерації зображень з тексту від Stability AI. Ця версія зберігає переваги попередніх поколінь та значно покращує якість зображень, розуміння тексту та різноманітність стилів, дозволяючи точніше інтерпретувати складні природні мовні підказки та створювати більш точні та різноманітні зображення."
  },
  "stable-diffusion-3.5-large": {
    "description": "stable-diffusion-3.5-large — це модель генерації зображень з тексту з 800 мільйонами параметрів на основі мультимодального дифузійного трансформера (MMDiT), що володіє видатним якістю зображень та відповідністю підказкам. Підтримує генерацію зображень з роздільною здатністю до 1 мільйона пікселів та ефективно працює на звичайному споживчому обладнанні."
  },
  "stable-diffusion-3.5-large-turbo": {
    "description": "stable-diffusion-3.5-large-turbo — модель, заснована на stable-diffusion-3.5-large із застосуванням технології адверсаріального дифузійного дистиляту (ADD), що забезпечує вищу швидкість генерації."
  },
  "stable-diffusion-v1.5": {
    "description": "stable-diffusion-v1.5 ініціалізована вагами контрольної точки stable-diffusion-v1.2 та донавчена на \"laion-aesthetics v2 5+\" з роздільною здатністю 512x512 протягом 595 тисяч кроків, зі зменшенням текстової кондиційованості на 10% для покращення безкласифікаторного спрямованого семплінгу."
  },
  "stable-diffusion-xl": {
    "description": "stable-diffusion-xl значно покращена порівняно з версією v1.5 та порівнянна за якістю з поточними передовими відкритими моделями генерації зображень, такими як midjourney. Основні покращення включають: збільшений у 3 рази unet-бекбон, додавання модуля уточнення для покращення якості зображень та більш ефективні методи навчання."
  },
  "stable-diffusion-xl-base-1.0": {
    "description": "Велика модель генерації зображень з тексту, розроблена та відкрита Stability AI, що володіє передовими можливостями творчої генерації зображень. Відрізняється чудовим розумінням інструкцій та підтримкою зворотних підказок для точного створення контенту."
  },
  "step-1-128k": {
    "description": "Балансує продуктивність та вартість, підходить для загальних сценаріїв."
  },
  "step-1-256k": {
    "description": "Володіє наддовгою здатністю обробки контексту, особливо підходить для аналізу довгих документів."
  },
  "step-1-32k": {
    "description": "Підтримує діалоги середньої довжини, підходить для різних додатків."
  },
  "step-1-8k": {
    "description": "Маленька модель, що підходить для легковагих завдань."
  },
  "step-1-flash": {
    "description": "Високошвидкісна модель, що підходить для реального часу діалогів."
  },
  "step-1.5v-mini": {
    "description": "Ця модель володіє потужними можливостями розуміння відео."
  },
  "step-1o-turbo-vision": {
    "description": "Ця модель володіє потужними здібностями до розуміння зображень та перевершує 1o в області математики та коду. Модель менша, ніж 1o, і виводить результати швидше."
  },
  "step-1o-vision-32k": {
    "description": "Ця модель володіє потужними здібностями до розуміння зображень. Порівняно з серією моделей step-1v, вона має вищу візуальну продуктивність."
  },
  "step-1v-32k": {
    "description": "Підтримує візуальний ввід, покращуючи мультимодальний досвід взаємодії."
  },
  "step-1v-8k": {
    "description": "Невелика візуальна модель, що підходить для базових завдань з текстом та зображеннями."
  },
  "step-1x-edit": {
    "description": "Модель, орієнтована на завдання редагування зображень, здатна змінювати та покращувати зображення на основі наданих користувачем зображень та текстових описів. Підтримує різні формати вводу, включаючи текстові описи та приклади зображень. Модель розуміє наміри користувача та генерує відповідні результати редагування."
  },
  "step-1x-medium": {
    "description": "Модель з потужними можливостями генерації зображень, що підтримує ввід у вигляді текстових описів. Володіє нативною підтримкою китайської мови, що дозволяє краще розуміти та обробляти китайські текстові описи, точніше вловлювати семантику та перетворювати її у візуальні характеристики для більш точної генерації зображень. Модель здатна створювати зображення високої роздільної здатності та якості, а також володіє деякими можливостями перенесення стилю."
  },
  "step-2-16k": {
    "description": "Підтримує масштабні взаємодії контексту, підходить для складних діалогових сценаріїв."
  },
  "step-2-16k-exp": {
    "description": "Експериментальна версія моделі step-2, що містить останні функції, яка перебуває в процесі оновлення. Не рекомендується для використання у виробничому середовищі."
  },
  "step-2-mini": {
    "description": "Супершвидка велика модель на основі нової саморобної архітектури уваги MFA, що досягає аналогічних результатів, як step1, при дуже низьких витратах, одночасно забезпечуючи вищу пропускну здатність та швидший час відгуку. Здатна обробляти загальні завдання та володіє особливими навичками в кодуванні."
  },
  "step-2x-large": {
    "description": "Нова модель Step Star наступного покоління, орієнтована на генерацію зображень. Модель здатна створювати високоякісні зображення на основі текстових описів користувача. Нова версія забезпечує більш реалістичну текстуру зображень та покращені можливості генерації тексту китайською та англійською мовами."
  },
  "step-3": {
    "description": "Ця модель володіє потужними можливостями візуального сприйняття та складного міркування. Вона здатна з високою точністю забезпечувати міждисциплінарне розуміння складних знань, перехресний аналіз математичної та візуальної інформації, а також вирішувати різні завдання візуального аналізу в повсякденному житті."
  },
  "step-r1-v-mini": {
    "description": "Ця модель є потужною моделлю виводу з сильними здібностями до розуміння зображень, здатною обробляти інформацію із зображень та тексту, виводячи текст після глибокого розмірковування. Ця модель демонструє видатні результати в області візуального виводу, а також володіє першокласними здібностями в математиці, коді та текстовому виводі. Довжина контексту становить 100k."
  },
  "step3": {
    "description": "Step3 — це мультимодальна модель від StepStar, що володіє потужними можливостями візуального сприйняття."
  },
  "stepfun-ai/step3": {
    "description": "Step3 — передова мультимодальна модель розмірковування, випущена компанією StepFun. Вона побудована на архітектурі mixture-of-experts (MoE) з загальним числом параметрів 321 млрд та 38 млрд активних параметрів. Модель реалізована за end-to-end схемою та націлена на мінімізацію витрат на декодування при забезпеченні найвищої продуктивності в задачах візуально-мовного розмірковування. Завдяки спільному дизайну багатоматричного розкладання уваги (MFA) та декуплінгу уваги та FFN (AFD), Step3 демонструє відмінну ефективність як на флагманських, так і на бюджетних прискорювачах. На етапі попереднього навчання модель обробила понад 20 трлн текстових токенів та 4 трлн змішаних токенів «текст+зображення», охопивши понад десять мов. Step3 показує лідируючі результати серед відкритих моделей за безліччю бенчмарків, включаючи завдання з математики, коду та мультимодальні завдання."
  },
  "taichu_llm": {
    "description": "Модель мови TaiChu володіє видатними здібностями до розуміння мови, а також до створення текстів, відповідей на питання, програмування, математичних обчислень, логічного висновування, аналізу емоцій та резюмування текстів. Інноваційно поєднує попереднє навчання на великих даних з багатством багатопотокових знань, постійно вдосконалюючи алгоритмічні технології та поглинаючи нові знання про слова, структуру, граматику та семантику з величезних обсягів текстових даних, забезпечуючи користувачам більш зручну інформацію та послуги, а також більш інтелектуальний досвід."
  },
  "taichu_o1": {
    "description": "taichu_o1 — це нова генерація моделі виводу, що реалізує ланцюжок мислення, подібний до людського, через мультимодальну взаємодію та посилене навчання, підтримує складні рішення та демонструє шлях мислення, який можна моделювати, при цьому забезпечуючи високу точність виводу, підходить для аналізу стратегій та глибоких розмірковувань."
  },
  "taichu_vl": {
    "description": "Об'єднує здібності до розуміння зображень, перенесення знань та логічного висновування, демонструючи видатні результати в області питань та відповідей на основі тексту та зображень."
  },
  "tencent/Hunyuan-A13B-Instruct": {
    "description": "Hunyuan-A13B-Instruct має 80 мільярдів параметрів, при активації 13 мільярдів параметрів може конкурувати з більшими моделями, підтримує гібридне міркування «швидке мислення/повільне мислення»; стабільне розуміння довгих текстів; перевірено BFCL-v3 та τ-Bench, здібності агента на передовому рівні; поєднує GQA та безліч форматів квантизації для ефективного виводу."
  },
  "text-embedding-3-large": {
    "description": "Найпотужніша модель векторизації, придатна для англійських та неанглійських завдань."
  },
  "text-embedding-3-small": {
    "description": "Ефективна та економічна нова генерація моделі Embedding, придатна для пошуку знань, додатків RAG та інших сценаріїв."
  },
  "thudm/glm-4-32b": {
    "description": "GLM-4-32B-0414 — це двомовна (китайська та англійська) мовна модель з відкритими вагами на 32B, оптимізована для генерації коду, викликів функцій та агентських завдань. Вона була попередньо навчена на 15T високоякісних даних та даних повторного розмірковування, а також додатково покращена за допомогою узгодження людських переваг, відмовного відбору та навчання з підкріпленням. Ця модель демонструє відмінні результати у складному розмірковуванні, генерації артефактів та завданнях структурованого виводу, досягаючи продуктивності, порівнянної з GPT-4o та DeepSeek-V3-0324 у кількох бенчмарках."
  },
  "thudm/glm-4-32b:free": {
    "description": "GLM-4-32B-0414 — це двомовна (китайська та англійська) мовна модель з відкритими вагами на 32B, оптимізована для генерації коду, викликів функцій та агентських завдань. Вона була попередньо навчена на 15T високоякісних даних та даних повторного розмірковування, а також додатково покращена за допомогою узгодження людських переваг, відмовного відбору та навчання з підкріпленням. Ця модель демонструє відмінні результати у складному розмірковуванні, генерації артефактів та завданнях структурованого виводу, досягаючи продуктивності, порівнянної з GPT-4o та DeepSeek-V3-0324 у кількох бенчмарках."
  },
  "thudm/glm-4-9b-chat": {
    "description": "Відкрита версія останнього покоління попередньо навченої моделі GLM-4, випущеної Zhizhu AI."
  },
  "thudm/glm-z1-32b": {
    "description": "GLM-Z1-32B-0414 — це покращена версія GLM-4-32B, створена для глибокого математичного, логічного та кодового вирішення завдань. Вона використовує розширене навчання з підкріпленням (специфічне для завдань та засноване на загальних парних перевагах) для підвищення продуктивності у складних багатоступінчастих завданнях. Порівняно з базовою моделлю GLM-4-32B, Z1 значно покращила здібності у структурованому розмірковуванні та формальних областях.\n\nЦя модель підтримує примусове виконання кроків \"думати\" через інженерне проєктування підказок та забезпечує покращену узгодженість для довгих форматів виводу. Вона оптимізована для робочих процесів агентів та підтримує довгий контекст (через YaRN), виклики інструментів JSON та конфігурацію тонкої вибірки для стабільного розмірковування. Ідеально підходить для випадків, що вимагають вдумливого, багатоступінчастого розмірковування або формального виводу."
  },
  "thudm/glm-z1-rumination-32b": {
    "description": "THUDM: GLM Z1 Rumination 32B — це глибока модель виводу з 32B параметрами із серії GLM-4-Z1, оптимізована для складних відкритих завдань, що вимагають тривалого розмірковування. Вона заснована на glm-4-32b-0414 та включає додаткові етапи посиленого навчання та багатоступінчасту стратегію вирівнювання, вводячи здатність \"розмірковування\", призначену для імітації розширеної когнітивної обробки. Це включає ітеративний вивід, багатоступінчастий аналіз та робочі процеси, покращені інструментами, такими як пошук, вилучення та синтез з урахуванням цитат.\n\nЦя модель демонструє відмінні результати в дослідницькому письмі, порівняльному аналізі та складних питаннях. Вона підтримує виклики функцій для пошуку та навігації (\"search\", \"click\", \"open\", \"finish\"), що дозволяє використовувати її в агентських потоках. Поведінка розмірковування формується за допомогою багаторівневого контролю, заснованого на правилах винагороди та механізмах відкладеного прийняття рішень, та орієнтується на такі глибокі дослідницькі рамки, як внутрішній стек вирівнювання OpenAI. Цей варіант підходить для сценаріїв, що вимагають глибини, а не швидкості."
  },
  "tngtech/deepseek-r1t-chimera:free": {
    "description": "DeepSeek-R1T-Chimera створена шляхом об'єднання DeepSeek-R1 та DeepSeek-V3 (0324), поєднуючи здібності виводу R1 та покращення ефективності токенів V3. Вона заснована на архітектурі DeepSeek-MoE Transformer та оптимізована для загальних завдань генерації тексту.\n\nЦя модель об'єднує попередньо навчені ваги двох вихідних моделей, щоб збалансувати продуктивність у завданнях виводу, ефективності та виконання інструкцій. Вона випущена під ліцензією MIT та призначена для дослідницьких та комерційних цілей."
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B) забезпечує підвищені обчислювальні можливості завдяки ефективним стратегіям та архітектурі моделі."
  },
  "tts-1": {
    "description": "Остання модель перетворення тексту на мову, оптимізована для швидкості в реальних сценаріях."
  },
  "tts-1-hd": {
    "description": "Остання модель перетворення тексту на мову, оптимізована для якості."
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B) підходить для деталізованих командних завдань, забезпечуючи відмінні можливості обробки мови."
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet встановлює нові галузеві стандарти, перевершуючи моделі конкурентів та Claude 3 Opus, демонструючи відмінні результати в широкому спектрі оцінок, при цьому володіючи швидкістю та вартістю наших моделей середнього рівня."
  },
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "description": "Claude 3.7 sonnet — це найшвидша модель наступного покоління від Anthropic. Порівняно з Claude 3 Haiku, Claude 3.7 Sonnet продемонструвала покращення в усіх навичках та перевершила попередню найбільшу модель Claude 3 Opus за багатьма інтелектуальними бенчмарками."
  },
  "v0-1.0-md": {
    "description": "Модель v0-1.0-md — це застаріла модель, що надається через API v0"
  },
  "v0-1.5-lg": {
    "description": "Модель v0-1.5-lg підходить для складних розумових або логічних завдань"
  },
  "v0-1.5-md": {
    "description": "Модель v0-1.5-md підходить для повсякденних завдань та генерації користувацького інтерфейсу (UI)"
  },
  "vercel/v0-1.0-md": {
    "description": "Доступ до моделі v0 для генерації, виправлення та оптимізації сучасних веб-додатків з міркуваннями, специфічними для фреймворків, та актуальними знаннями."
  },
  "vercel/v0-1.5-md": {
    "description": "Доступ до моделі v0 для генерації, виправлення та оптимізації сучасних веб-додатків з міркуваннями, специфічними для фреймворків, та актуальними знаннями."
  },
  "wan2.2-t2i-flash": {
    "description": "Експрес-версія Wanxiang 2.2 — найновіша модель на даний момент. Повне оновлення в креативності, стабільності та реалістичності, висока швидкість генерації та відмінне співвідношення ціна-якість."
  },
  "wan2.2-t2i-plus": {
    "description": "Професійна версія Wanxiang 2.2 — найновіша модель на даний момент. Повне оновлення в креативності, стабільності та реалістичності, з більш детальною проробкою зображень."
  },
  "wanx-v1": {
    "description": "Базова модель генерації зображень з тексту. Відповідає універсальній моделі версії 1.0 на офіційному сайті Tongyi Wanxiang."
  },
  "wanx2.0-t2i-turbo": {
    "description": "Спеціалізована на реалістичних портретах, середня швидкість та низька вартість. Відповідає експрес-моделі версії 2.0 на офіційному сайті Tongyi Wanxiang."
  },
  "wanx2.1-t2i-plus": {
    "description": "Повністю оновлена версія з більш детальною проробкою зображень, трохи повільніша швидкість. Відповідає професійній моделі версії 2.1 на офіційному сайті Tongyi Wanxiang."
  },
  "wanx2.1-t2i-turbo": {
    "description": "Повністю оновлена версія з високою швидкістю генерації, всебічною якістю та відмінним співвідношенням ціна-якість. Відповідає експрес-моделі версії 2.1 на офіційному сайті Tongyi Wanxiang."
  },
  "whisper-1": {
    "description": "Універсальна модель розпізнавання мовлення, що підтримує багатомовне розпізнавання мовлення, переклад мовлення та ідентифікацію мови."
  },
  "wizardlm2": {
    "description": "WizardLM 2 — це мовна модель, що надається Microsoft AI, яка особливо добре проявляє себе у складних діалогах, багатомовних завданнях, висновуванні та інтелектуальних помічниках."
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2 — це мовна модель, що надається Microsoft AI, яка особливо добре проявляє себе у складних діалогах, багатомовних завданнях, висновуванні та інтелектуальних помічниках."
  },
  "x1": {
    "description": "Модель Spark X1 буде додатково оновлена, і на основі вже існуючих лідерських позицій у математичних завданнях, досягне порівнянних результатів у загальних завданнях, таких як міркування, генерація тексту та розуміння мови, з OpenAI o1 та DeepSeek R1."
  },
  "xai/grok-2": {
    "description": "Grok 2 — передова мовна модель з видатними можливостями міркування. Володіє просунутими навичками в чатах, кодуванні та міркуваннях, перевершуючи Claude 3.5 Sonnet та GPT-4-Turbo в рейтингу LMSYS."
  },
  "xai/grok-2-vision": {
    "description": "Візуальна модель Grok 2 демонструє видатні результати в завданнях, заснованих на візуальній інформації, забезпечуючи передові показники у візуальній математиці (MathVista) та питаннях за документами (DocVQA). Здатна обробляти різноманітну візуальну інформацію, включаючи документи, діаграми, графіки, скріншоти та фотографії."
  },
  "xai/grok-3": {
    "description": "Флагманська модель xAI, відмінно підходить для корпоративних сценаріїв, таких як вилучення даних, кодування та узагальнення тексту. Володіє глибокими знаннями у фінансах, охороні здоров'я, юриспруденції та науці."
  },
  "xai/grok-3-fast": {
    "description": "Флагманська модель xAI для корпоративних завдань, таких як вилучення даних, кодування та узагальнення тексту. Швидка версія моделі працює на більш продуктивній інфраструктурі, забезпечуючи значно швидший час відгуку. Збільшення швидкості досягається за рахунок вищої вартості на кожен вихідний токен."
  },
  "xai/grok-3-mini": {
    "description": "Легковагова модель xAI, що розмірковує перед відповіддю. Відмінно підходить для простих або логічних завдань без необхідності глибоких знань у предметній області. Вихідні ланцюжки думок доступні."
  },
  "xai/grok-3-mini-fast": {
    "description": "Легковагова модель xAI, що розмірковує перед відповіддю. Відмінно підходить для простих або логічних завдань без необхідності глибоких знань у предметній області. Вихідні ланцюжки думок доступні. Швидка версія моделі працює на більш продуктивній інфраструктурі, забезпечуючи значно швидший час відгуку. Збільшення швидкості досягається за рахунок вищої вартості на кожен вихідний токен."
  },
  "xai/grok-4": {
    "description": "Новітня та найкраща флагманська модель xAI, що забезпечує неперевершену продуктивність у природній мові, математиці та міркуваннях — ідеальний універсал."
  },
  "yi-large": {
    "description": "Абсолютно нова модель з трильйоном параметрів, що забезпечує видатні можливості для питань та відповідей, а також генерації тексту."
  },
  "yi-large-fc": {
    "description": "На основі моделі yi-large підтримує та посилює можливості виклику інструментів, підходить для різних бізнес-сценаріїв, що вимагають створення агентів або робочих процесів."
  },
  "yi-large-preview": {
    "description": "Початкова версія, рекомендується використовувати yi-large (нову версію)."
  },
  "yi-large-rag": {
    "description": "Висококласний сервіс на основі моделі yi-large, що об'єднує технології пошуку та генерації для надання точних відповідей та послуг з пошуку інформації в реальному часі."
  },
  "yi-large-turbo": {
    "description": "Висока вартість та видатна продуктивність. Балансування високої точності на основі продуктивності, швидкості виводу та витрат."
  },
  "yi-lightning": {
    "description": "Нова високопродуктивна модель, що забезпечує високу якість виводу при значно підвищеній швидкості виводу."
  },
  "yi-lightning-lite": {
    "description": "Спрощена версія, рекомендується використовувати yi-lightning."
  },
  "yi-medium": {
    "description": "Модель середнього розміру з покращеним налаштуванням, збалансована за можливостями та вартістю. Глибока оптимізація здатності слідувати вказівкам."
  },
  "yi-medium-200k": {
    "description": "200K наддовге вікно контексту, що забезпечує глибоке розуміння та генерацію довгих текстів."
  },
  "yi-spark": {
    "description": "Маленька та потужна, легковагова та швидка модель. Забезпечує покращені математичні обчислення та можливості написання коду."
  },
  "yi-vision": {
    "description": "Модель для складних візуальних завдань, що забезпечує високу продуктивність у розумінні та аналізі зображень."
  },
  "yi-vision-v2": {
    "description": "Модель для складних візуальних завдань, що забезпечує високопродуктивне розуміння та аналіз на основі кількох зображень."
  },
  "zai-org/GLM-4.5": {
    "description": "GLM-4.5 — базова модель, спеціально створена для додатків з агентами, що використовує архітектуру змішаних експертів (Mixture-of-Experts). Модель глибоко оптимізована для виклику інструментів, веб-браузингу, програмної інженерії та фронтенд-розробки, підтримує безшовну інтеграцію з кодовими агентами, такими як Claude Code та Roo Code. GLM-4.5 використовує змішаний режим виводу, адаптуючись до складних міркувань та повсякденних завдань."
  },
  "zai-org/GLM-4.5-Air": {
    "description": "GLM-4.5-Air — базова модель, спеціально створена для додатків з агентами, що використовує архітектуру змішаних експертів (Mixture-of-Experts). Модель глибоко оптимізована для виклику інструментів, веб-браузингу, програмної інженерії та фронтенд-розробки, підтримує безшовну інтеграцію з кодовими агентами, такими як Claude Code та Roo Code. GLM-4.5 використовує змішаний режим виводу, адаптуючись до складних міркувань та повсякденних завдань."
  },
  "zai-org/GLM-4.5V": {
    "description": "GLM-4.5V — це нове покоління візуально-мовної моделі (VLM), випущеної Zhipu AI (智谱 AI). Модель побудована на флагманській текстовій моделі GLM-4.5-Air з загальним числом параметрів 106B та 12B активних параметрів, використовує архітектуру змішаних експертів (MoE) та покликана забезпечувати видатну продуктивність при нижчій вартості виводу. Технічно GLM-4.5V продовжує лінію GLM-4.1V-Thinking та вводить такі новації, як тривимірна обертальна позиційна кодування (3D-RoPE), значно посилюючи сприйняття та висновки про тривимірні просторові відносини. Завдяки оптимізаціям на етапах попереднього навчання, контрольованого доналаштування та навчання з підкріпленням модель здатна обробляти різні візуальні дані — зображення, відео та довгі документи — і в 41 відкритому мультимодальному бенчмарку досягла рівня найкращих у своєму класі відкритих моделей. Крім того, в моделі додано перемикач «режим розмірковування», що дозволяє користувачу гнучко вибирати між швидкою віддачею та глибокою аналітикою, балансуючи ефективність та якість."
  },
  "zai-org/GLM-4.6": {
    "description": "Порівняно з GLM-4.5, GLM-4.6 включає безліч ключових покращень. Контекстне вікно розширено з 128K до 200K токенів, що дозволяє моделі справлятися з більш складними завданнями агентів. Модель досягла вищих результатів у тестах з програмування та продемонструвала покращену продуктивність у реальних додатках, таких як Claude Code, Cline, Roo Code та Kilo Code, включаючи покращене створення візуально привабливих фронтенд-сторінок. GLM-4.6 помітно покращила продуктивність виводу та підтримує використання інструментів під час виводу, що посилює її комплексні можливості. Модель краще справляється з використанням інструментів та пошуковими агентами, а також ефективніше інтегрується в агентські фреймворки. В області написання текстів модель більше відповідає людським перевагам за стилем та читабельністю та поводиться природніше в рольових сценаріях."
  },
  "zai/glm-4.5": {
    "description": "Серія моделей GLM-4.5 — базові моделі, спеціально розроблені для агентів. Флагман GLM-4.5 включає 355 мільярдів параметрів (32 мільярди активних), об'єднуючи можливості виводу, кодування та агентування для вирішення складних прикладних завдань. Як гібридна система виводу, вона пропонує подвійний режим роботи."
  },
  "zai/glm-4.5-air": {
    "description": "GLM-4.5 та GLM-4.5-Air — наші новітні флагманські моделі, спеціально розроблені як базові моделі для агентних додатків. Обидві використовують архітектуру змішаних експертів (MoE). GLM-4.5 має 355 мільярдів параметрів з 32 мільярдами активних на прохід, а GLM-4.5-Air — більш спрощену конструкцію з 106 мільярдами параметрів та 12 мільярдами активних."
  },
  "zai/glm-4.5v": {
    "description": "GLM-4.5V побудована на базі GLM-4.5-Air, успадковуючи перевірені технології GLM-4.1V-Thinking та забезпечуючи ефективне масштабування завдяки потужній архітектурі MoE з 106 мільярдами параметрів."
  }
}
